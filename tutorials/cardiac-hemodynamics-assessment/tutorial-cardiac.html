
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Cardiothoracic Abnormality Assessment &#8212; PyKale</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tutorials/cardiac-hemodynamics-assessment/tutorial-cardiac';</script>
    <link rel="icon" href="../../_static/icon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../overview.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/BioMedMMAI_logo.png" class="logo__image only-light" alt="PyKale - Home"/>
    <script>document.write(`<img src="../../_static/BioMedMMAI_logo.png" class="logo__image only-dark" alt="PyKale - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../overview.html">
                    Overview
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Workshop</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../workshop/intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../workshop/schedule.html">Schedule</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../setup-config/tutorial-0.html">Setup &amp; Configuration</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../brain-disorder-diagnosis/tutorial-brain.html">Brain Disorder Diagnosis</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../brain-disorder-diagnosis/extend-reading/extension-tasks.html">Extension Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../brain-disorder-diagnosis/extend-reading/helper-functions.html">Helper Functions (optional)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../brain-disorder-diagnosis/extend-reading/data-config.html">Data &amp; Config (optional)</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../drug-target-interaction/tutorial-drug.html">Drug–Target Interaction Prediction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../multiomics-cancer-classification/tutorial-cancer.html">Multiomics Cancer Classification</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../multiomics-cancer-classification/extend-reading/data.html">Data (optional)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../multiomics-cancer-classification/extend-reading/helper-functions.html">Helper Functions &amp; Model Details (optional)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../multiomics-cancer-classification/extend-reading/interpretation-study.html">Interpretation Study (optional)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../multiomics-cancer-classification/extend-reading/extension-tasks.html">Extension Tasks</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/pykale/mmai-tutorials/blob/main/tutorials/cardiac-hemodynamics-assessment/tutorial-cardiac.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pykale/mmai-tutorials" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pykale/mmai-tutorials/issues/new?title=Issue%20on%20page%20%2Ftutorials/cardiac-hemodynamics-assessment/tutorial-cardiac.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/tutorials/cardiac-hemodynamics-assessment/tutorial-cardiac.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Cardiothoracic Abnormality Assessment</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-0-environment-preparation">Step 0: Environment Preparation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#package-installation">Package installation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#configuration">Configuration</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-training-configuration">Pre-training Configuration</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning-configuration">Fine-tuning Configuration</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-data-loading-and-preparation">Step 1: Data Loading and Preparation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-training-data-loading">Pre-training Data Loading</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning-data-loading">Fine-tuning Data Loading</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-model-definition">Step 2: Model Definition</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#embed">Embed</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#signal-encoder">Signal Encoder</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#image-encoder">Image Encoder</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-fusion">️ Feature Fusion</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predict">Predict</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#reconstruction-pre-training">Reconstruction (Pre-training)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-fine-tuning">Classification (Fine-tuning)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-model-training">Step 3: Model Training</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multimodal-pretraining">Multimodal Pretraining</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multimodal-fine-tuning">Multimodal Fine-tuning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-evaluation">Step 4: Evaluation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-interpretation">Step 5: Interpretation</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="cardiothoracic-abnormality-assessment">
<h1>Cardiothoracic Abnormality Assessment<a class="headerlink" href="#cardiothoracic-abnormality-assessment" title="Link to this heading">#</a></h1>
<p><img alt="" src="../../_images/embc_heart_tutorial_fig.png" /></p>
<p>In this tutorial, we demonstrate how to use <code class="docutils literal notranslate"><span class="pre">PyKale</span></code> to pretrain, fine-tune, evaluate, and interpret deep learning models on two low-cost, non-invasive modalities: <strong>Chest X-ray (CXR)</strong> and <strong>12-lead Electrocardiogram (ECG)</strong>, for assessing <strong>cardiothoracic abnormalities</strong>.</p>
<p><strong>Estimated runtime:</strong> Completing the steps in this tutorial will take approximately 10 minutes.</p>
<p>We will use a multimodal dataset derived from MIMIC-CXR and MIMIC-IV-ECG, which contains approximately 50K paired CXR and ECG samples. In this tutorial, we pretrain a multimodal <strong>CardioVAE</strong> model using ~49K CXR-ECG pairs via a tri-stream pretraining method. We then fine-tune this pretrained CardioVAE model on a smaller subset (~1K paired samples) with binary labels: <strong>Healthy</strong> and <strong>Cardiothoracic Abnormality</strong>. Lastly, we demonstrate how to interpret the trained CardioVAE model on both the CXR and ECG modalities.</p>
<p>This notebook is based on the work of <a class="reference external" href="https://link.springer.com/chapter/10.1007/978-3-031-72378-0_28">Suvon et al. (MICCAI 2024)</a>, which introduced a tri-stream pretraining strategy using a <strong>Multimodal Variational Autoencoder (VAE)</strong> to learn both modality-shared and modality-specific representations for assessing <strong>Pulmonary Arterial Wedge Pressure (PAWP)</strong>—a critical indicator of cardiac hemodynamics. The resulting model, <strong>CardioVAE</strong>, is implemented in the <a class="reference external" href="https://github.com/pykale/pykale"><code class="docutils literal notranslate"><span class="pre">PyKale</span></code></a> library. Here, we provide a concise example of how to use this model through <code class="docutils literal notranslate"><span class="pre">PyKale</span></code>’s APIs—from pretraining and fine-tuning to model interpretation.</p>
<section id="step-0-environment-preparation">
<h2>Step 0: Environment Preparation<a class="headerlink" href="#step-0-environment-preparation" title="Link to this heading">#</a></h2>
<section id="package-installation">
<h3>Package installation<a class="headerlink" href="#package-installation" title="Link to this heading">#</a></h3>
<p>The main packages required (excluding <code class="docutils literal notranslate"><span class="pre">PyKale</span></code>) for this tutorial are:</p>
<ul class="simple">
<li><p><strong>wfdb</strong>: A toolkit for reading, writing, and processing physiological signal data, especially useful for ECG waveform analysis.</p></li>
<li><p><strong>yacs</strong>: A lightweight configuration management library that helps organize experimental settings in a structured, readable format.</p></li>
<li><p><strong>pytorch-lightning</strong>: A high-level framework built on PyTorch that simplifies training workflows, making code cleaner and easier to scale.</p></li>
<li><p><strong>tabulate</strong>: Used to print tabular data in a readable format, helpful for summarizing results or configuration parameters.</p></li>
</ul>
<p><strong>Additional Notes for Colab</strong>
Some non-critical dependencies (e.g., <code class="docutils literal notranslate"><span class="pre">torch-geometric</span></code>) may face version conflicts when installing <code class="docutils literal notranslate"><span class="pre">pykale</span></code> on Colab. These are handled manually in the installation step below. An automatic crash and reset have also been added, as the session needs to be restarted after installing these dependencies. <strong>Do not run this block again if you have already run it once.</strong></p>
<p>In addition, when using Google Colab, please select the <strong>T4 GPU</strong> hardware accelerator to ensure the tutorial runs smoothly. To do this, click the <strong>“Runtime”</strong> option in the top-left menu, then select <strong>“Change runtime type”</strong> and choose <strong>T4 GPU</strong> as the hardware accelerator.</p>
<p><strong>Estimated runtime:</strong> 4 minutes</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="err">!</span><span class="n">pip</span> <span class="n">uninstall</span> <span class="o">--</span><span class="n">quiet</span> <span class="o">-</span><span class="n">y</span> <span class="n">torch</span> <span class="n">torchvision</span> <span class="n">torchaudio</span> <span class="n">torchdata</span>

<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">--</span><span class="n">quiet</span> <span class="n">torch</span><span class="o">==</span><span class="mf">2.3.0</span> <span class="n">torchvision</span> <span class="n">torchaudio</span> <span class="o">--</span><span class="n">index</span><span class="o">-</span><span class="n">url</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">download</span><span class="o">.</span><span class="n">pytorch</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">whl</span><span class="o">/</span><span class="n">cu121</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">torch</span><span class="o">-</span><span class="n">scatter</span> <span class="n">torch</span><span class="o">-</span><span class="n">sparse</span> <span class="n">torch</span><span class="o">-</span><span class="n">cluster</span> <span class="n">torch</span><span class="o">-</span><span class="n">spline</span><span class="o">-</span><span class="n">conv</span> <span class="n">torch</span><span class="o">-</span><span class="n">geometric</span> <span class="o">-</span><span class="n">f</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">data</span><span class="o">.</span><span class="n">pyg</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">whl</span><span class="o">/</span><span class="n">torch</span><span class="o">-</span><span class="mf">2.3.0</span><span class="o">+</span><span class="n">cu121</span><span class="o">.</span><span class="n">html</span>

<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">--</span><span class="n">quiet</span> <span class="o">--</span><span class="n">user</span> \
    <span class="n">git</span><span class="o">+</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">pykale</span><span class="o">/</span><span class="n">pykale</span><span class="nd">@main</span> \
    <span class="n">yacs</span><span class="o">==</span><span class="mf">0.1.8</span> <span class="n">wfdb</span> <span class="n">pytorch</span><span class="o">-</span><span class="n">lightning</span> <span class="n">tabulate</span> <span class="n">captum</span> <span class="n">neurokit2</span>\
    <span class="o">&amp;&amp;</span> <span class="n">echo</span> <span class="s2">&quot;pykale,yacs and wfdb installed successfully ✅&quot;</span> \
    <span class="o">||</span> <span class="n">echo</span> <span class="s2">&quot;Failed to install pykale,yacs and wfdb ❌&quot;</span>

<span class="c1"># This code crashes the Colab runtime, triggering an automatic reset.</span>
<span class="n">os</span><span class="o">.</span><span class="n">kill</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">(),</span> <span class="mi">9</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="setup">
<h3>Setup<a class="headerlink" href="#setup" title="Link to this heading">#</a></h3>
<p>As a starting point, we will mount Google Drive in Colab so that the data can be accessed directly. You might be prompted to grant permission to access your Google account—please proceed with the authorisation when asked.</p>
<p>Next, we will install the required packages and load a set of helper functions to support the tutorial workflow. To keep the output clean and focused on interpretation, we also suppress unnecessary warnings.</p>
<p><strong>Estimated runtime:</strong> 25 seconds</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Connect with your google drive for data and model loading</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">google.colab</span><span class="w"> </span><span class="kn">import</span> <span class="n">drive</span>

<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s2">&quot;/content/drive&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">site</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>


<span class="c1"># Disable warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;PYTHONWARNINGS&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;ignore&quot;</span>

<span class="c1"># Suppress PyTorch Lightning logs</span>
<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;pytorch_lightning&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;pytorch_lightning.utilities.rank_zero&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;pytorch_lightning.accelerators.cuda&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>


<span class="k">if</span> <span class="s2">&quot;google.colab&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">get_ipython</span><span class="p">()):</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">site</span><span class="o">.</span><span class="n">getusersitepackages</span><span class="p">())</span>
    <span class="err">!</span><span class="n">git</span> <span class="n">clone</span> <span class="o">--</span><span class="n">single</span><span class="o">-</span><span class="n">branch</span> <span class="o">-</span><span class="n">b</span> <span class="n">main</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">pykale</span><span class="o">/</span><span class="n">mmai</span><span class="o">-</span><span class="n">tutorials</span>
    <span class="o">%</span><span class="n">cp</span> <span class="o">-</span><span class="n">r</span> <span class="o">/</span><span class="n">content</span><span class="o">/</span><span class="n">mmai</span><span class="o">-</span><span class="n">tutorials</span><span class="o">/</span><span class="n">tutorials</span><span class="o">/</span><span class="n">cardiac</span><span class="o">-</span><span class="n">hemodynamics</span><span class="o">-</span><span class="n">assessment</span><span class="o">/*</span> <span class="o">/</span><span class="n">content</span><span class="o">/</span>

    <span class="o">%</span><span class="n">rm</span> <span class="o">-</span><span class="n">r</span> <span class="o">/</span><span class="n">content</span><span class="o">/</span><span class="n">mmai</span><span class="o">-</span><span class="n">tutorials</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="configuration">
<h3>Configuration<a class="headerlink" href="#configuration" title="Link to this heading">#</a></h3>
<p>To maintain a clean and modular notebook design, <strong>CardioVAE</strong> uses dedicated configuration files for both pre-training and fine-tuning. This setup ensures a clear separation between code and experimental settings, enhancing reproducibility and flexibility across different tasks and datasets.</p>
<p>Configuration parameters can be overridden using external YAML files (e.g., <code class="docutils literal notranslate"><span class="pre">experiments/pretraining_base.yml</span></code>, <code class="docutils literal notranslate"><span class="pre">experiments/finetune_base.yml</span></code>).</p>
<section id="pre-training-configuration">
<h4>Pre-training Configuration<a class="headerlink" href="#pre-training-configuration" title="Link to this heading">#</a></h4>
<p>Default settings for the pre-training stage are defined in <code class="docutils literal notranslate"><span class="pre">config_pretrain.py</span></code>. These include data paths, model architecture, and optimizer parameters.
This modular structure allows easy experiment tracking and customisation by simply editing the associated <code class="docutils literal notranslate"><span class="pre">.yml</span></code> file.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">config_pretrain</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_cfg_defaults</span>

<span class="n">cfg_PT</span> <span class="o">=</span> <span class="n">get_cfg_defaults</span><span class="p">()</span>
<span class="n">cfg_PT</span><span class="o">.</span><span class="n">merge_from_file</span><span class="p">(</span><span class="s2">&quot;configs/pretraining_base.yml&quot;</span><span class="p">)</span>

<span class="c1"># ------ Hyperparameters to play with -----</span>
<span class="n">cfg_PT</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">LATENT_DIM</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">cfg_PT</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">cfg_PT</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">LAMBDA_IMAGE</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">cfg_PT</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">LAMBDA_SIGNAL</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1"># User can change this to try different batch size.</span>
<span class="n">cfg_PT</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">128</span>

<span class="nb">print</span><span class="p">(</span><span class="n">cfg_PT</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="fine-tuning-configuration">
<h4>Fine-tuning Configuration<a class="headerlink" href="#fine-tuning-configuration" title="Link to this heading">#</a></h4>
<p>Fine-tuning parameters are managed in <code class="docutils literal notranslate"><span class="pre">config_finetune.py</span></code>. These include learning rate, loss weights, number of epochs, model checkpoint paths, and other task-specific options.
External YAML files like <code class="docutils literal notranslate"><span class="pre">experiments/finetune_base.yml</span></code> enable flexible adjustments for different downstream tasks or datasets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">config_finetune</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_cfg_defaults</span>

<span class="n">cfg_FT</span> <span class="o">=</span> <span class="n">get_cfg_defaults</span><span class="p">()</span>
<span class="n">cfg_FT</span><span class="o">.</span><span class="n">merge_from_file</span><span class="p">(</span><span class="s2">&quot;configs/finetune_base.yml&quot;</span><span class="p">)</span>

<span class="c1"># ------ Hyperparameters to play with -----</span>
<span class="n">cfg_FT</span><span class="o">.</span><span class="n">FT</span><span class="o">.</span><span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">cfg_FT</span><span class="o">.</span><span class="n">FT</span><span class="o">.</span><span class="n">HIDDEN_DIM</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># User can change this to try different batch size.</span>
<span class="n">cfg_FT</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">32</span>

<span class="nb">print</span><span class="p">(</span><span class="n">cfg_FT</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="step-1-data-loading-and-preparation">
<h2>Step 1: Data Loading and Preparation<a class="headerlink" href="#step-1-data-loading-and-preparation" title="Link to this heading">#</a></h2>
<p>This tutorial uses separate data pipelines for <strong>pre-training</strong> and <strong>fine-tuning</strong>, both based on paired chest X-ray (CXR) and ECG signal features. Each stage follows standard preprocessing steps—such as resizing, normalization, interpolation, and tensor conversion—tailored for resource-constrained environments like <strong>Google Colab</strong>.</p>
<p>PyKale API for Data preparation:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">kale.loaddata.signal_access.load_ecg_from_folder</span></code> provides a convenient function for loading ECG waveform data stored in a directory structure. It supports automatic parsing and conversion of ECG signal files into PyTorch tensors, with options for standard preprocessing such as normalisation, resize, interpolation, and resampling. This enables streamlined integration with deep learning pipelines.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kale.loaddata.image_access.load_images_from_dir</span></code> offers an easy-to-use utility for loading image datasets from directory hierarchies. It supports standard image formats and returns PyTorch tensors, performing essential preprocessing steps such as resizing and normalisation. This function is suitable for image classification, computer vision, and multimodal learning tasks.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kale.loaddata.signal_image_access.SignalImageDataset</span></code> defines a unified dataset class designed for paired signal (e.g., ECG) and image (e.g., CXR) modalities. It facilitates synchronized access to multi-source data, providing ready-to-use PyTorch datasets that can be directly utilised for multimodal training, evaluation, and downstream applications.</p></li>
</ul>
<p><strong>Note:</strong> Please create a shortcut to the following Google Drive folder in your <strong>MyDrive</strong>.<br />
To create a shortcut:<br />
(i) Click the link to open the Google Drive folder.<br />
(ii) Click the folder name at the top to reveal a <strong>drop-down menu</strong>.<br />
(iii) From the drop-down menu, select <strong>Organise &gt; Add shortcut</strong>.<br />
(iv) A dialog box titled <em>“Add shortcut to ‘EMBC_workshop_data’”</em> will appear — click the <strong>“All locations”</strong> tab, then select <strong>“My Drive”</strong>.<br />
(v) A shortcut to <strong>EMBC_workshop_data</strong> should now be visible at <a class="reference external" href="https://drive.google.com/drive/my-drive">https://drive.google.com/drive/my-drive</a>.</p>
<p><a class="reference external" href="https://drive.google.com/drive/folders/1N7-fMWsdK-tuB76SdC-GF1njYYGx0Z-i?usp=sharing">Google Drive Link</a></p>
<p>There’s no need to download the data manually. After mounting your Google Drive in the setup section, you will be able to directly access all datasets and pretrained models.</p>
<section id="pre-training-data-loading">
<h3>Pre-training Data Loading<a class="headerlink" href="#pre-training-data-loading" title="Link to this heading">#</a></h3>
<p>To accommodate the resource constraints of platforms like <strong>Google Colab</strong>, this tutorial uses a lightweight version of the dataset consisting of the <strong>first 1,000 preprocessed samples</strong> from the full 50K paired CXR and ECG dataset. This significantly reduces runtime and memory requirements, allowing for rapid experimentation without the overhead of full-scale data loading and transformation.</p>
<p>The complete preprocessing pipeline, implemented using the PyKale API, is provided for reference. Additionally, CSV files containing subject IDs for the full dataset are provided. Users interested in training on the complete 50K dataset can leverage the <strong>PyKale API</strong>, which supports direct loading of raw CXR and ECG features with integrated preprocessing.</p>
<p><strong>Note:</strong></p>
<ul class="simple">
<li><p>For ease of use in Colab, the full data loading functionality is <strong>commented out by default</strong>. It can be re-enabled for local or high-resource environments. To load the full 50K paired CXR-ECG data, you need to download the <a class="reference external" href="https://physionet.org/content/mimic-cxr/2.1.0/">MIMIC-CXR</a> and <a class="reference external" href="https://physionet.org/content/mimic-iv-ecg/1.0/">MIMIC-IV-ECG</a> datasets, then <strong>uncomment</strong> the optional code cell and run it.</p></li>
<li><p>To access the required files for dataloading, ensure that the shared folder <strong><code class="docutils literal notranslate"><span class="pre">EMBC_workshop_data</span></code></strong> is added as a <strong>shortcut to your Google Drive (under “My Drive”)</strong>.</p></li>
</ul>
<p><strong>Estimated runtime:</strong> 12 seconds</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># (OPTIONAL)</span>
<span class="c1"># from kale.loaddata.signal_access import load_ecg_from_folder</span>
<span class="c1"># from kale.loaddata.image_access import load_images_from_dir</span>

<span class="c1"># ecg_tensor = load_ecg_from_folder(&quot;/mimic-iv-ecg-diagnostic-electrocardiogram-matched-subset-1.0/&quot;, &quot;mimic_ecg_50K.csv&quot;)</span>
<span class="c1"># cxr_tensor = load_images_from_dir(&quot;/physionet.org/files/mimic-cxr-jpg/2.0.0/&quot;, &quot;mimic_cxr_50K.csv&quot;)</span>

<span class="c1"># train_dataset_PT, val_dataset_PT = SignalImageDataset.prepare_data_loaders( ecg_tensor, cxr_tensor)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kale.loaddata.signal_image_access</span><span class="w"> </span><span class="kn">import</span> <span class="n">SignalImageDataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kale.utils.seed</span><span class="w"> </span><span class="kn">import</span> <span class="n">set_seed</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="n">set_seed</span><span class="p">(</span><span class="n">cfg_PT</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">ecg_tensor_PT</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">cfg_PT</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">ECG_PATH</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">cfg_PT</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">DATA_DEVICE</span><span class="p">)</span>
<span class="n">cxr_tensor_PT</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">cfg_PT</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">CXR_PATH</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">cfg_PT</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">DATA_DEVICE</span><span class="p">)</span>

<span class="n">train_dataset_PT</span><span class="p">,</span> <span class="n">val_dataset_PT</span> <span class="o">=</span> <span class="n">SignalImageDataset</span><span class="o">.</span><span class="n">prepare_data_loaders</span><span class="p">(</span>
    <span class="n">ecg_tensor_PT</span><span class="p">,</span> <span class="n">cxr_tensor_PT</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="fine-tuning-data-loading">
<h3>Fine-tuning Data Loading<a class="headerlink" href="#fine-tuning-data-loading" title="Link to this heading">#</a></h3>
<p>For the fine-tuning stage, we use the <strong>last 1,000 paired CXR and ECG samples</strong> from the full 50K dataset derived from <strong>MIMIC-CXR</strong> and <strong>MIMIC-IV-ECG</strong>. Corresponding disease labels are obtained from MIMIC-CXR, which includes 12 cardiothoracic abnormality classes along with a “No Finding” label representing healthy cases.</p>
<p>To formulate a binary classification task, all abnormality classes are grouped into a single <strong>Cardiothoracic Abnormality</strong> category, while the “No Finding” label is treated as <strong>Healthy</strong>. The resulting label mapping is as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">0</span></code> → <strong>Healthy</strong></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">1</span></code> → <strong>Cardiothoracic Abnormality</strong></p></li>
</ul>
<p>This fine-tuning subset is explicitly selected to ensure no overlap with the samples used during pre-training, thereby simulating a realistic downstream evaluation setting.</p>
<p>Unlike the fine-tuning strategy reported in <em>Suvon et al., MICCAI 2024</em>, which relied on a private in-house dataset, this approach is fully reproducible using publicly available data from MIMIC-CXR and MIMIC-IV-ECG.</p>
<p><strong>Estimated runtime:</strong> 10 seconds</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">random_split</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Set seed for reproducibility</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">FT</span><span class="o">.</span><span class="n">SEED</span><span class="p">)</span>

<span class="c1"># Load data</span>
<span class="n">ecg_tensor_FT</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">ECG_PATH</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">DATA_DEVICE</span><span class="p">)</span>
<span class="n">cxr_tensor_FT</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">CXR_PATH</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">DATA_DEVICE</span><span class="p">)</span>
<span class="n">label_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">CSV_PATH</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">label_df</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

<span class="c1"># Combine tensors into a single dataset</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">cxr_tensor_FT</span><span class="p">,</span> <span class="n">ecg_tensor_FT</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<span class="c1"># Split into train/val</span>
<span class="n">val_ratio</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">num_val</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">val_ratio</span> <span class="o">*</span> <span class="n">num_samples</span><span class="p">)</span>
<span class="n">num_train</span> <span class="o">=</span> <span class="n">num_samples</span> <span class="o">-</span> <span class="n">num_val</span>

<span class="n">train_dataset_FT</span><span class="p">,</span> <span class="n">val_dataset_FT</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">,</span>
    <span class="p">[</span><span class="n">num_train</span><span class="p">,</span> <span class="n">num_val</span><span class="p">],</span>
    <span class="n">generator</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">FT</span><span class="o">.</span><span class="n">SEED</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># DataLoaders</span>
<span class="n">train_loader_FT</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">train_dataset_FT</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">NUM_WORKERS</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">val_loader_FT</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">val_dataset_FT</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">NUM_WORKERS</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="step-2-model-definition">
<h2>Step 2: Model Definition<a class="headerlink" href="#step-2-model-definition" title="Link to this heading">#</a></h2>
<p>We use the <strong>PyKale</strong> library to implement a modular multimodal variational autoencoder (VAE) for learning joint representations from <strong>ECG</strong> and <strong>CXR</strong> data. The architecture includes modality-specific encoders and decoders, a PoE-based fusion mechanism, and task-specific heads for reconstruction and classification.</p>
<section id="embed">
<h3>Embed<a class="headerlink" href="#embed" title="Link to this heading">#</a></h3>
<p>The embedding module is composed of independent encoders for each modality and a fusion mechanism to obtain a shared latent representation.</p>
<section id="signal-encoder">
<h4>Signal Encoder<a class="headerlink" href="#signal-encoder" title="Link to this heading">#</a></h4>
<p>The ECG signal pathway uses <code class="docutils literal notranslate"><span class="pre">SignalVAEEncoder</span></code> from <code class="docutils literal notranslate"><span class="pre">kale.embed.signal_cnn</span></code>.<br />
This encoder captures high-level temporal features from preprocessed ECG waveforms and maps them to a latent space suitable for downstream fusion and representation learning.</p>
</section>
<section id="image-encoder">
<h4>Image Encoder<a class="headerlink" href="#image-encoder" title="Link to this heading">#</a></h4>
<p>The image pathway uses <code class="docutils literal notranslate"><span class="pre">ImageVAEEncoder</span></code> from <code class="docutils literal notranslate"><span class="pre">kale.embed.image_cnn</span></code>.<br />
This encoder captures high-level spatial features from preprocessed CXR’s and maps them to a latent space suitable for downstream fusion and representation learning.</p>
</section>
<section id="feature-fusion">
<h4>️ Feature Fusion<a class="headerlink" href="#feature-fusion" title="Link to this heading">#</a></h4>
<p>Encoded modality-specific features are combined using a <strong>Product-of-Experts (PoE)</strong> approach, implemented in <code class="docutils literal notranslate"><span class="pre">kale.embed.feature_fusion</span></code>.<br />
The PoE fusion computes a joint posterior over the latent space by aggregating information from each modality, enabling coherent multimodal representation.</p>
</section>
</section>
<hr class="docutils" />
<section id="predict">
<h3>Predict<a class="headerlink" href="#predict" title="Link to this heading">#</a></h3>
<section id="reconstruction-pre-training">
<h4>Reconstruction (Pre-training)<a class="headerlink" href="#reconstruction-pre-training" title="Link to this heading">#</a></h4>
<p>During pre-training, the model reconstructs both modalities using decoders from the shared latent representation:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ImageVAEDecoder</span></code> from <code class="docutils literal notranslate"><span class="pre">kale.embed.vae_decoder</span></code> for CXR reconstruction</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SignalVAEDecoder</span></code> from <code class="docutils literal notranslate"><span class="pre">kale.embed.signal_cnn_vae</span></code> for ECG waveform reconstruction</p></li>
</ul>
<p>The model is trained to minimise the <strong>Evidence Lower Bound (ELBO)</strong>, encouraging informative and disentangled latent representations.</p>
</section>
<section id="classification-fine-tuning">
<h4>Classification (Fine-tuning)<a class="headerlink" href="#classification-fine-tuning" title="Link to this heading">#</a></h4>
<p>For downstream classification tasks, we reuse the pretrained encoders as feature extractors.<br />
The <code class="docutils literal notranslate"><span class="pre">SignalImageFineTuningClassifier</span></code> from <a class="reference external" href="https://github.com/pykale/pykale/blob/main/kale/pipeline/finetune.py"><code class="docutils literal notranslate"><span class="pre">kale.pipeline.finetune</span></code></a> adds a lightweight classification head on top of the shared latent space for supervised learning.<br />
This setup is optimised for clinical prediction tasks, such as binary or multi-label disease classification.</p>
</section>
</section>
</section>
<section id="step-3-model-training">
<h2>Step 3: Model Training<a class="headerlink" href="#step-3-model-training" title="Link to this heading">#</a></h2>
<section id="multimodal-pretraining">
<h3>Multimodal Pretraining<a class="headerlink" href="#multimodal-pretraining" title="Link to this heading">#</a></h3>
<p>We pretraind a CardioVAE model using the <code class="docutils literal notranslate"><span class="pre">SignalImageVAE</span></code> class from <strong>PyKale</strong> to jointly model paired CXR and ECG data. The goal is to learn <strong>shared and modality-specific representations</strong> in an <strong>unsupervised</strong> manner via reconstruction.</p>
<p>We instantiate <code class="docutils literal notranslate"><span class="pre">SignalImageVAE</span></code> from <a class="reference external" href="https://github.com/pykale/pykale/blob/main/kale/embed/multimodal_encoder.py"><code class="docutils literal notranslate"><span class="pre">kale.embed.multimodal_encoder</span></code></a>, which includes:</p>
<ul class="simple">
<li><p>A <strong>signal encoder-decoder</strong> built on <code class="docutils literal notranslate"><span class="pre">SignalVAEEncoder</span></code> for ECG waveforms</p></li>
<li><p>An <strong>image encoder-decoder</strong> built on <code class="docutils literal notranslate"><span class="pre">ImageVAEEncoder</span></code> for CXR images</p></li>
<li><p>A <strong>Product-of-Experts (PoE)</strong> fusion module for combining modality-specific latent vectors into a shared latent representation</p></li>
</ul>
<p>To pretrain, we use <code class="docutils literal notranslate"><span class="pre">SignalImageTriStreamVAETrainer</span></code> from <a class="reference external" href="https://github.com/pykale/pykale/blob/main/kale/pipeline/multimodal_trainer.py"><code class="docutils literal notranslate"><span class="pre">kale.pipeline.multimodal_trainer</span></code></a> to:</p>
<ul class="simple">
<li><p>Perform <strong>joint and single-modality reconstructions</strong></p></li>
<li><p>Optimise the <strong>ELBO loss</strong>, balancing image and signal modalities</p></li>
<li><p>Manage logging, and reconstruction-based validation</p></li>
</ul>
<p><strong>Estimated runtime:</strong> 2 minutes with 1 epoch</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pytorch_lightning</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pl</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kale.pipeline.multimodal_trainer</span><span class="w"> </span><span class="kn">import</span> <span class="n">SignalImageTriStreamVAETrainer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kale.embed.multimodal_encoder</span><span class="w"> </span><span class="kn">import</span> <span class="n">SignalImageVAE</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SignalImageVAE</span><span class="p">(</span>
    <span class="n">image_input_channels</span><span class="o">=</span><span class="n">cfg_PT</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">INPUT_DIM_CXR</span><span class="p">,</span>
    <span class="n">signal_input_dim</span><span class="o">=</span><span class="n">cfg_PT</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">INPUT_DIM_ECG</span><span class="p">,</span>
    <span class="n">latent_dim</span><span class="o">=</span><span class="n">cfg_PT</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">LATENT_DIM</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># PyKale trainer instance (all from config)</span>
<span class="n">pl_trainer</span> <span class="o">=</span> <span class="n">SignalImageTriStreamVAETrainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset_PT</span><span class="p">,</span>
    <span class="n">val_dataset</span><span class="o">=</span><span class="n">val_dataset_PT</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">cfg_PT</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">cfg_PT</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">NUM_WORKERS</span><span class="p">,</span>
    <span class="n">lambda_image</span><span class="o">=</span><span class="n">cfg_PT</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">LAMBDA_IMAGE</span><span class="p">,</span>
    <span class="n">lambda_signal</span><span class="o">=</span><span class="n">cfg_PT</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">LAMBDA_SIGNAL</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="n">cfg_PT</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">LR</span><span class="p">,</span>
    <span class="n">annealing_epochs</span><span class="o">=</span><span class="n">cfg_PT</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">EPOCHS</span><span class="p">,</span>
    <span class="n">scale_factor</span><span class="o">=</span><span class="n">cfg_PT</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">SCALE_FACTOR</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="n">cfg_PT</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">EPOCHS</span><span class="p">,</span>
    <span class="n">accelerator</span><span class="o">=</span><span class="n">cfg_PT</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">ACCELERATOR</span><span class="p">,</span>
    <span class="n">devices</span><span class="o">=</span><span class="n">cfg_PT</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">DEVICES</span><span class="p">,</span>
    <span class="n">log_every_n_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">pl_trainer</span><span class="p">)</span>

<span class="c1"># Save model state dict</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">cfg_PT</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">SAVE_PATH</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saved model state dictionary to &#39;</span><span class="si">{</span><span class="n">cfg_PT</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">SAVE_PATH</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="multimodal-fine-tuning">
<h3>Multimodal Fine-tuning<a class="headerlink" href="#multimodal-fine-tuning" title="Link to this heading">#</a></h3>
<p>For downstream classification, we fine-tune a shallow classifier on top of a <strong>pretrained CardioVAE encoder</strong>. The encoder is loaded from <code class="docutils literal notranslate"><span class="pre">SignalImageVAE</span></code>, pretrained with reconstruction loss, and used as a fixed or partially trainable <strong>feature extractor</strong>.</p>
<p>We use <code class="docutils literal notranslate"><span class="pre">SignalImageFineTuningClassifier</span></code> from <a class="reference external" href="https://github.com/pykale/pykale/blob/main/kale/pipeline/finetune.py"><code class="docutils literal notranslate"><span class="pre">kale.pipeline.finetune</span></code></a>, which wraps:</p>
<ul class="simple">
<li><p>A <strong>pretrained encoder</strong> from <code class="docutils literal notranslate"><span class="pre">SignalImageVAE</span></code></p></li>
<li><p>A <strong>classification head</strong> (single or multi-layer MLP)</p></li>
<li><p>A <strong>training step</strong> that supports standard supervised learning with cross-entropy loss</p></li>
</ul>
<p><strong>Estimated runtime:</strong> 2 minute with 10 epoch</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pytorch_lightning</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pl</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kale.embed.multimodal_encoder</span><span class="w"> </span><span class="kn">import</span> <span class="n">SignalImageVAE</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kale.pipeline.multimodal_trainer</span><span class="w"> </span><span class="kn">import</span> <span class="n">SignalImageFineTuningTrainer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kale.utils.remap_model_parameters</span><span class="w"> </span><span class="kn">import</span> <span class="n">remap_state_dict_keys</span>

<span class="c1"># Load and remap checkpoint</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">FT</span><span class="o">.</span><span class="n">CKPT_PATH</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">FT</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">remap_state_dict_keys</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>

<span class="n">pretrained_mvae</span> <span class="o">=</span> <span class="n">SignalImageVAE</span><span class="p">(</span>
    <span class="n">image_input_channels</span><span class="o">=</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">INPUT_IMAGE_CHANNELS</span><span class="p">,</span>
    <span class="n">signal_input_dim</span><span class="o">=</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">INPUT_DIM_ECG</span><span class="p">,</span>
    <span class="n">latent_dim</span><span class="o">=</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">LATENT_DIM</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">pretrained_mvae</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">pretrained_mvae</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">FT</span><span class="o">.</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">pretrained_mvae</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">model_pl</span> <span class="o">=</span> <span class="n">SignalImageFineTuningTrainer</span><span class="p">(</span>
    <span class="n">pretrained_model</span><span class="o">=</span><span class="n">pretrained_mvae</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">FT</span><span class="o">.</span><span class="n">NUM_CLASSES</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">FT</span><span class="o">.</span><span class="n">LR</span><span class="p">,</span>
    <span class="n">hidden_dim</span><span class="o">=</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">FT</span><span class="o">.</span><span class="n">HIDDEN_DIM</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">FT</span><span class="o">.</span><span class="n">EPOCHS</span><span class="p">,</span>
    <span class="n">accelerator</span><span class="o">=</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">FT</span><span class="o">.</span><span class="n">ACCELERATOR</span><span class="p">,</span>
    <span class="n">devices</span><span class="o">=</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">FT</span><span class="o">.</span><span class="n">DEVICES</span><span class="p">,</span>
    <span class="n">log_every_n_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">enable_checkpointing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">logger</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model_pl</span><span class="p">,</span> <span class="n">train_dataloaders</span><span class="o">=</span><span class="n">train_loader_FT</span><span class="p">,</span> <span class="n">val_dataloaders</span><span class="o">=</span><span class="n">val_loader_FT</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="step-4-evaluation">
<h2>Step 4: Evaluation<a class="headerlink" href="#step-4-evaluation" title="Link to this heading">#</a></h2>
<p>After training, we extract key validation metrics using PyTorch Lightning’s built-in <code class="docutils literal notranslate"><span class="pre">callback_metrics</span></code>. These metrics provide a quantitative summary of model performance on the validation set.</p>
<p>We report the following:</p>
<ul class="simple">
<li><p><strong>Accuracy</strong>: Proportion of correct predictions</p></li>
<li><p><strong>AUROC</strong>: Area under the Receiver Operating Characteristic curve, measuring ranking quality</p></li>
<li><p><strong>MCC</strong>: Matthews Correlation Coefficient, a balanced metric even for imbalanced classes</p></li>
</ul>
<p>The metrics are printed in a tabulated format using the <code class="docutils literal notranslate"><span class="pre">tabulate</span></code> library for clear presentation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tabulate</span><span class="w"> </span><span class="kn">import</span> <span class="n">tabulate</span>

<span class="c1"># Get validation metrics</span>
<span class="n">val_metrics</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">callback_metrics</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">val_metrics</span><span class="p">[</span><span class="s2">&quot;val_acc&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">if</span> <span class="s2">&quot;val_acc&quot;</span> <span class="ow">in</span> <span class="n">val_metrics</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;nan&quot;</span><span class="p">)</span>
<span class="n">auc</span> <span class="o">=</span> <span class="n">val_metrics</span><span class="p">[</span><span class="s2">&quot;val_auroc&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">if</span> <span class="s2">&quot;val_auroc&quot;</span> <span class="ow">in</span> <span class="n">val_metrics</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;nan&quot;</span><span class="p">)</span>
<span class="n">mcc</span> <span class="o">=</span> <span class="n">val_metrics</span><span class="p">[</span><span class="s2">&quot;val_mcc&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">if</span> <span class="s2">&quot;val_mcc&quot;</span> <span class="ow">in</span> <span class="n">val_metrics</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;nan&quot;</span><span class="p">)</span>

<span class="c1"># Print metrics</span>
<span class="n">table_data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;AUROC&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">auc</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;MCC&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">mcc</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">],</span>
<span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Validation Summary ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">table_data</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Metric&quot;</span><span class="p">,</span> <span class="s2">&quot;Value&quot;</span><span class="p">],</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;fancy_grid&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Validation Summary ===
╒══════════╤═════════╕
│ Metric   │   Value │
╞══════════╪═════════╡
│ Accuracy │   0.663 │
├──────────┼─────────┤
│ AUROC    │   0.726 │
├──────────┼─────────┤
│ MCC      │   0.326 │
╘══════════╧═════════╛
</pre></div>
</div>
</div>
</div>
</section>
<section id="step-5-interpretation">
<h2>Step 5: Interpretation<a class="headerlink" href="#step-5-interpretation" title="Link to this heading">#</a></h2>
<p>We interpret the fine-tuned model using the multimodal_signal_image_attribution interpretation method from PyKale, which builds on Captum’s Integrated Gradients to generate visual explanations for both CXR and ECG inputs.
This method helps identify which regions in each modality, such as specific waveform segments in ECG and spatial regions in CXR, contributed most to the model’s prediction. This improves both transparency and clinical interpretability.</p>
<p><strong>Estimated runtime:</strong> 10 seconds</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">kale.interpret.signal_image_attribution</span><span class="w"> </span><span class="kn">import</span> <span class="n">multimodal_signal_image_attribution</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># User can change this to try different ECG and CXR interpretation configaration to play with</span>
<span class="n">cfg_FT</span><span class="o">.</span><span class="n">INTERPRET</span><span class="o">.</span><span class="n">ECG_THRESHOLD</span> <span class="o">=</span> <span class="mf">0.75</span>
<span class="n">cfg_FT</span><span class="o">.</span><span class="n">INTERPRET</span><span class="o">.</span><span class="n">SAMPLE_IDX</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">cfg_FT</span><span class="o">.</span><span class="n">INTERPRET</span><span class="o">.</span><span class="n">ZOOM_RANGE</span> <span class="o">=</span> <span class="p">[</span><span class="mf">3.5</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">cfg_FT</span><span class="o">.</span><span class="n">INTERPRET</span><span class="o">.</span><span class="n">CXR_THRESHOLD</span> <span class="o">=</span> <span class="mf">0.75</span>


<span class="n">sample_idx</span> <span class="o">=</span> <span class="n">cfg_FT</span><span class="o">.</span><span class="n">INTERPRET</span><span class="o">.</span><span class="n">SAMPLE_IDX</span>
<span class="n">zoom_range</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">cfg_FT</span><span class="o">.</span><span class="n">INTERPRET</span><span class="o">.</span><span class="n">ZOOM_RANGE</span><span class="p">)</span>
<span class="n">ecg_threshold</span> <span class="o">=</span> <span class="n">cfg_FT</span><span class="o">.</span><span class="n">INTERPRET</span><span class="o">.</span><span class="n">ECG_THRESHOLD</span>
<span class="n">cxr_threshold</span> <span class="o">=</span> <span class="n">cfg_FT</span><span class="o">.</span><span class="n">INTERPRET</span><span class="o">.</span><span class="n">CXR_THRESHOLD</span>
<span class="n">lead_number</span> <span class="o">=</span> <span class="n">cfg_FT</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">NUM_LEADS</span>
<span class="n">sampling_rate</span> <span class="o">=</span> <span class="n">cfg_FT</span><span class="o">.</span><span class="n">INTERPRET</span><span class="o">.</span><span class="n">SAMPLING_RATE</span>


<span class="c1"># Run interpretation</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">multimodal_signal_image_attribution</span><span class="p">(</span>
    <span class="n">last_fold_model</span><span class="o">=</span><span class="n">model_pl</span><span class="p">,</span>
    <span class="n">last_val_loader</span><span class="o">=</span><span class="n">val_loader_FT</span><span class="p">,</span>
    <span class="n">sample_idx</span><span class="o">=</span><span class="n">sample_idx</span><span class="p">,</span>
    <span class="n">signal_threshold</span><span class="o">=</span><span class="n">ecg_threshold</span><span class="p">,</span>
    <span class="n">image_threshold</span><span class="o">=</span><span class="n">cxr_threshold</span><span class="p">,</span>
    <span class="n">zoom_range</span><span class="o">=</span><span class="n">zoom_range</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Full ECG View:</strong> Displays attribution across the full 12-lead ECG signal. A percentile-based threshold (e.g., top 25%) is applied to highlight segments with the highest contribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">patch</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>

<span class="c1"># Plot the full ECG waveform</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">result</span><span class="p">[</span><span class="s2">&quot;full_time&quot;</span><span class="p">],</span>
    <span class="n">result</span><span class="p">[</span><span class="s2">&quot;signal_waveform_np&quot;</span><span class="p">][:</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;full_length&quot;</span><span class="p">]],</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;ECG Waveform&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;important_indices_full&quot;</span><span class="p">]:</span>
    <span class="n">stretch_start</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">idx</span> <span class="o">-</span> <span class="mi">6</span><span class="p">)</span>
    <span class="n">stretch_end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s2">&quot;full_length&quot;</span><span class="p">],</span> <span class="n">idx</span> <span class="o">+</span> <span class="mi">6</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">result</span><span class="p">[</span><span class="s2">&quot;full_time&quot;</span><span class="p">][</span><span class="n">stretch_start</span><span class="p">:</span><span class="n">stretch_end</span><span class="p">],</span>
        <span class="n">result</span><span class="p">[</span><span class="s2">&quot;signal_waveform_np&quot;</span><span class="p">][</span><span class="n">stretch_start</span><span class="p">:</span><span class="n">stretch_end</span><span class="p">],</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span>
        <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Time (seconds)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s2">&quot;x-large&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Amplitude&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s2">&quot;x-large&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Full ECG with Important Regions&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s2">&quot;x-large&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="s2">&quot;large&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="s2">&quot;large&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;ECG Waveform&quot;</span><span class="p">,</span> <span class="s2">&quot;Important Regions&quot;</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="s2">&quot;medium&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4eceee9f036697bc7c320d8f448b1a507bfbf964620460029e87e3737a7e0f67.png" src="../../_images/4eceee9f036697bc7c320d8f448b1a507bfbf964620460029e87e3737a7e0f67.png" />
</div>
</div>
<p><strong>Zoomed-In ECG Segment:</strong> Focuses on a specific time window (e.g., 3 to 4 seconds) for fine-grained inspection of high-attribution waveform regions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">patch</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>

<span class="c1"># Plot zoomed-in ECG segment</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">result</span><span class="p">[</span><span class="s2">&quot;zoom_time&quot;</span><span class="p">],</span>
    <span class="n">result</span><span class="p">[</span><span class="s2">&quot;segment_signal_waveform&quot;</span><span class="p">],</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;ECG Waveform&quot;</span><span class="p">,</span>
<span class="p">)</span>


<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;important_indices_zoom&quot;</span><span class="p">]:</span>
    <span class="n">stretch_start</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">idx</span> <span class="o">-</span> <span class="mi">6</span><span class="p">)</span>
    <span class="n">stretch_end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s2">&quot;segment_signal_waveform&quot;</span><span class="p">]),</span> <span class="n">idx</span> <span class="o">+</span> <span class="mi">6</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">result</span><span class="p">[</span><span class="s2">&quot;zoom_time&quot;</span><span class="p">][</span><span class="n">stretch_start</span><span class="p">:</span><span class="n">stretch_end</span><span class="p">],</span>
        <span class="n">result</span><span class="p">[</span><span class="s2">&quot;segment_signal_waveform&quot;</span><span class="p">][</span><span class="n">stretch_start</span><span class="p">:</span><span class="n">stretch_end</span><span class="p">],</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span>
        <span class="n">linewidth</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
    <span class="p">)</span>


<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s2">&quot;zoom_start_sec&quot;</span><span class="p">],</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;zoom_end_sec&quot;</span><span class="p">],</span> <span class="mi">11</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="n">result</span><span class="p">[</span><span class="s2">&quot;zoom_start_sec&quot;</span><span class="p">],</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;zoom_end_sec&quot;</span><span class="p">]])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Time (seconds)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s2">&quot;x-large&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span>
    <span class="sa">f</span><span class="s1">&#39;Zoomed-In ECG Segment (</span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s2">&quot;zoom_start_sec&quot;</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">s – </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s2">&quot;zoom_end_sec&quot;</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">s)&#39;</span><span class="p">,</span>
    <span class="n">fontsize</span><span class="o">=</span><span class="s2">&quot;x-large&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/a7ac3b8c739d6cd265f297dc2fe00a7e01d31e333b84c6d9b44d9b6869581893.png" src="../../_images/a7ac3b8c739d6cd265f297dc2fe00a7e01d31e333b84c6d9b44d9b6869581893.png" />
</div>
</div>
<p><strong>CXR Attribution Map:</strong> Shows a heatmap over the input CXR image, with highlighted areas corresponding to regions above a configurable percentile threshold (e.g., top 25%). This helps reveal where the model focused attention in the spatial domain.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x_pts</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;x_pts&quot;</span><span class="p">]</span>
<span class="n">y_pts</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;y_pts&quot;</span><span class="p">]</span>
<span class="n">importance_pts</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;importance_pts&quot;</span><span class="p">]</span>
<span class="n">cxr_thresh</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;image_threshold&quot;</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">patch</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>

<span class="c1"># Show base CXR image</span>
<span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s2">&quot;image_np&quot;</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Overlay attribution points</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">x_pts</span><span class="p">,</span>
    <span class="n">y_pts</span><span class="p">,</span>
    <span class="n">c</span><span class="o">=</span><span class="n">importance_pts</span><span class="p">,</span>
    <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;summer&quot;</span><span class="p">,</span>
    <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span>
    <span class="n">s</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span>
    <span class="n">vmin</span><span class="o">=</span><span class="n">cxr_thresh</span><span class="p">,</span>
    <span class="n">vmax</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
    <span class="n">edgecolor</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Add colorbar for importance</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">fraction</span><span class="o">=</span><span class="mf">0.04</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.04</span><span class="p">)</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Importance (</span><span class="si">{</span><span class="n">cxr_thresh</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">–1.00)&quot;</span><span class="p">)</span>

<span class="c1"># Final formatting</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;CXR: Important Regions&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s2">&quot;x-large&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4303f2a108def85e2bd9ba6c24db8b949044c8a573e81468599331e71068b487.png" src="../../_images/4303f2a108def85e2bd9ba6c24db8b949044c8a573e81468599331e71068b487.png" />
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./tutorials/cardiac-hemodynamics-assessment"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-0-environment-preparation">Step 0: Environment Preparation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#package-installation">Package installation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#configuration">Configuration</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-training-configuration">Pre-training Configuration</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning-configuration">Fine-tuning Configuration</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-data-loading-and-preparation">Step 1: Data Loading and Preparation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-training-data-loading">Pre-training Data Loading</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning-data-loading">Fine-tuning Data Loading</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-model-definition">Step 2: Model Definition</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#embed">Embed</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#signal-encoder">Signal Encoder</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#image-encoder">Image Encoder</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-fusion">️ Feature Fusion</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predict">Predict</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#reconstruction-pre-training">Reconstruction (Pre-training)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-fine-tuning">Classification (Fine-tuning)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-model-training">Step 3: Model Training</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multimodal-pretraining">Multimodal Pretraining</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multimodal-fine-tuning">Multimodal Fine-tuning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-evaluation">Step 4: Evaluation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-interpretation">Step 5: Interpretation</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By PyKale Contributors
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>