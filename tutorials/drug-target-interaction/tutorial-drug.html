
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Drug–Target Interaction Prediction &#8212; PyKale</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tutorials/drug-target-interaction/tutorial-drug';</script>
    <link rel="icon" href="../../_static/icon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Multiomics Cancer Classification" href="../multiomics-cancer-classification/tutorial-cancer.html" />
    <link rel="prev" title="Extension Tasks" href="../cardiac-hemodynamics-assessment/extend-reading/extension-tasks.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../overview.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/embc_logo.png" class="logo__image only-light" alt="PyKale - Home"/>
    <script>document.write(`<img src="../../_static/embc_logo.png" class="logo__image only-dark" alt="PyKale - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../overview.html">
                    Overview
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Workshop</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../workshop/intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../workshop/schedule.html">Program</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../setup-config/tutorial-0.html">Setup &amp; Configuration</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../brain-disorder-diagnosis/tutorial-brain.html">Brain Disorder Diagnosis</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../brain-disorder-diagnosis/extend-reading/extension-tasks.html">Extension Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../brain-disorder-diagnosis/extend-reading/data-config.html">Data &amp; Config (optional)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../brain-disorder-diagnosis/extend-reading/helper-functions.html">Helper Functions (optional)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cardiac-hemodynamics-assessment/tutorial-heart.html">Cardiothoracic Abnormality Assessment</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../cardiac-hemodynamics-assessment/extend-reading/extension-tasks.html">Extension Tasks</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Drug–Target Interaction Prediction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../multiomics-cancer-classification/tutorial-cancer.html">Multiomics Cancer Classification</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../multiomics-cancer-classification/extend-reading/extension-tasks.html">Extension Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../multiomics-cancer-classification/extend-reading/data.html">Data (optional)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../multiomics-cancer-classification/extend-reading/helper-functions.html">Helper Functions &amp; Model Details (optional)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../multiomics-cancer-classification/extend-reading/interpretation-study.html">Interpretation Study (optional)</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/pykale/mmai-tutorials/blob/main/tutorials/drug-target-interaction/tutorial-drug.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pykale/mmai-tutorials" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pykale/mmai-tutorials/issues/new?title=Issue%20on%20page%20%2Ftutorials/drug-target-interaction/tutorial-drug.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/tutorials/drug-target-interaction/tutorial-drug.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Drug–Target Interaction Prediction</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-0-environment-preparation">Step 0: Environment Preparation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#package-installation">Package Installation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#configuration">Configuration</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-data-loading-and-preparation">Step 1: Data Loading and Preparation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-downloading">Data Downloading</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-loading">Data Loading</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preprocessing">Data Preprocessing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-dataset-inspection">Exercise: Dataset Inspection</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-model-definition">Step 2: Model Definition</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#embed">Embed</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predict">Predict</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-model-training">Step 3: Model Training</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train">Train</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#what-happens-here">What Happens Here?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-evaluation">Step 4: Evaluation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-included-in-this-step">What is included in this step?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-comparison">Performance Comparison</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-interpretation">Step 5: Interpretation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#extracting-attention-weights">Extracting Attention Weights</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-attention-maps-and-molecule-images">Visualize Attention Maps and Molecule Images</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extension-tasks">Extension Tasks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#task-1">Task 1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#task-2">Task 2</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="drugtarget-interaction-prediction">
<h1>Drug–Target Interaction Prediction<a class="headerlink" href="#drugtarget-interaction-prediction" title="Link to this heading">#</a></h1>
<p><img alt="" src="https://github.com/pykale/mmai-tutorials/blob/main/tutorials/drug-target-interaction/images/drugban-pyakle-api.png?raw=1" /></p>
<p>In this tutorial, we will train models to predict the interaction between <strong>two data modalities</strong>: <strong>molecules (drug)</strong> and <strong>proteins (target)</strong> using <a class="reference external" href="https://github.com/pykale/pykale"><code class="docutils literal notranslate"><span class="pre">PyKale</span></code></a> [1]. Drug-target interaction (DTI) plays a key role in drug discovery and identifying potential therapeutic targets. The DTI prediction problem is formulated as a <strong>binary classification task</strong>, where the goal is to predict whether a given <strong>drug–protein pair interacts or not</strong>.</p>
<p>Two datasets are provided for this tutorial: <a class="reference external" href="https://snap.stanford.edu/biodata/"><strong>BioSNAP</strong></a> [2] or <a class="reference external" href="https://www.bindingdb.org/rwd/bind/index.jsp"><strong>BindingDB</strong></a> [3], where the main content is demonstrated using the BioSNAP dataset.</p>
<p>The tutorial is based on the <strong>DrugBAN</strong> framework by <a class="reference external" href="https://www.nature.com/articles/s42256-022-00605-1"><strong>Bai et al. (<em>Nature Machine Intelligence</em>, 2023)</strong></a> [4], with the following key features:</p>
<ul class="simple">
<li><p><strong>Bilinear Attention Network (BAN)</strong>, which learns detailed feature representations for both drugs and proteins and captures local interaction patterns between them.</p></li>
<li><p><strong>Adversarial Domain Adaptation</strong>, which helps the model generalise to out-of-distribution datasets, i.e., in <strong><em>clustering-based cross-validation</em></strong> instead of <strong><em>random splits</em></strong>, improving its ability to predict interactions on unseen drug–target pairs.</p></li>
</ul>
<p>The main tasks of this tutorial are:</p>
<ul class="simple">
<li><p>Load molecule and protein data</p></li>
<li><p>Train and evaluate a DTI prediction model</p></li>
<li><p>Visualise the model’s attention on the drug and protein features</p></li>
</ul>
<p>With <code class="docutils literal notranslate"><span class="pre">PyKale</span></code>, implementing such a multimodal DTI prediction pipeline is straightforward. The library provides ready-to-use modules and configuration support, making it easy to apply advanced techniques with minimal custom coding.</p>
<section id="step-0-environment-preparation">
<h2>Step 0: Environment Preparation<a class="headerlink" href="#step-0-environment-preparation" title="Link to this heading">#</a></h2>
<p>As a starting point, we will install the required packages and load a set of helper functions to assist throughout this tutorial.</p>
<p>To prepare the helper functions and necessary materials, we download them from the GitHub repository.</p>
<p>Moreover, we provide helper functions that can be inspected directly in the <code class="docutils literal notranslate"><span class="pre">.py</span></code> files located in the notebook’s current directory. The additional helper script is:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/pykale/embc-mmai25/blob/main/tutorials/drug-target-interaction/configs.py"><code class="docutils literal notranslate"><span class="pre">config.py</span></code></a>: Defines the base configuration settings, which can be overridden using a custom <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> file.</p></li>
</ul>
<div class="cell tag_hide-input docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import sys
import site

if &quot;google.colab&quot; in str(get_ipython()):
    sys.path.insert(0, site.getusersitepackages())
    !git clone -q --single-branch -b main https://github.com/pykale/mmai-tutorials
    %cp -rf /content/mmai-tutorials/tutorials/drug-target-interaction/* /content/
    %rm -r /content/mmai-tutorials
</pre></div>
</div>
</div>
</details>
</div>
<section id="package-installation">
<h3>Package Installation<a class="headerlink" href="#package-installation" title="Link to this heading">#</a></h3>
<p>The main package required for this tutorial is <code class="docutils literal notranslate"><span class="pre">PyKale</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">PyKale</span></code> is an open-source interdisciplinary machine learning library developed at the University of Sheffield, with a focus on applications in biomedical and scientific domains.</p>
<p>Then, we install <code class="docutils literal notranslate"><span class="pre">PyG</span></code> (PyTorch Geometric) and related packages.</p>
<!-- Please **do not** re-run this session after installation completed. Runing this installation multiple times will trigger issues related to `PyG`. If you want to re-run this installation, please click the `Runtime` on the top menu and choose `Disconnect and delete runtime` before installing. --><div class="cell tag_hide-input tag_hide-output docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>%%capture
!pip install --quiet \
    &quot;pykale[example]@git+https://github.com/pykale/pykale@main&quot; \
    gdown==5.2.0 torch-geometric==2.6.0 torch_sparse torch_scatter \
    -f https://data.pyg.org/whl/torch-2.6.0+cu124.html
</pre></div>
</div>
</div>
</details>
</div>
<p>We then hide the warnings messages to get a clear output.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import os
import warnings

warnings.filterwarnings(&quot;ignore&quot;)
os.environ[&quot;PYTHONWARNINGS&quot;] = &quot;ignore&quot;
</pre></div>
</div>
</div>
</div>
<p>Exercise: Check NumPy Version</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import numpy as np

print(&quot;NumPy version:&quot;, np.__version__)  # numpy should be 2.0.0 or higher
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>NumPy version: 2.0.2
</pre></div>
</div>
</div>
</div>
</section>
<section id="configuration">
<h3>Configuration<a class="headerlink" href="#configuration" title="Link to this heading">#</a></h3>
<p>To minimize the footprint of the notebook when specifying configurations, we provide a <a class="reference external" href="https://github.com/pykale/embc-mmai25/blob/main/tutorials/drug-target-interaction/configs.py"><code class="docutils literal notranslate"><span class="pre">config.py</span></code></a> file that defines default parameters. These can be customized by supplying a <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> configuration file, such as <a class="reference external" href="https://github.com/pykale/embc-mmai25/blob/main/tutorials/drug-target-interaction/configs/DA_cross_domain.yaml"><code class="docutils literal notranslate"><span class="pre">configs/DA_cross_domain.yaml</span></code></a> as an example.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>from configs import get_cfg_defaults

cfg = get_cfg_defaults()  # Load the default settings from config.py
cfg.merge_from_file(
    &quot;configs/DA_cross_domain.yaml&quot;
)  # Update (or override) some of those settings using a custom YAML file
</pre></div>
</div>
</div>
</div>
<p>In this tutorial, we list the hyperparameters we would like users to play with outside the <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> file:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">cfg.SOLVER.MAX_EPOCH</span></code>: Number of epochs in training stage. You can reduce the number of training epochs to shorten runtime.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cfg.DATA.DATASET</span></code>: The dataset used in the study. This can be <a class="reference external" href="https://www.bindingdb.org/rwd/bind/index.jsp"><code class="docutils literal notranslate"><span class="pre">bindingdb</span></code></a> or <a class="reference external" href="https://snap.stanford.edu/biodata/"><code class="docutils literal notranslate"><span class="pre">biosnap</span></code></a>.</p></li>
</ul>
<p>As a quick exercise, please take a moment to review and understand the parameters in <a class="reference external" href="https://github.com/pykale/embc-mmai25/blob/main/tutorials/drug-target-interaction/configs.py"><code class="docutils literal notranslate"><span class="pre">config.py</span></code></a>.</p>
<p>To save time, we set the maximum number of epochs to 5. You can increase this value later to improve model performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cfg.SOLVER.MAX_EPOCH = 5
</pre></div>
</div>
</div>
</div>
<p>You can also switch to a different dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cfg.DATA.DATASET = &quot;biosnap&quot;
</pre></div>
</div>
</div>
</div>
<p>Exercise: Now print the full configuration to check all current hyperparameter and dataset settings.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>print(cfg)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>BCN:
  HEADS: 2
COMET:
  API_KEY: 
  EXPERIMENT_NAME: DA_cross_domain
  PROJECT_NAME: drugban-23-May
  TAG: DrugBAN_CDAN
  USE: False
DA:
  INIT_EPOCH: 10
  LAMB_DA: 1
  METHOD: CDAN
  ORIGINAL_RANDOM: True
  RANDOM_DIM: 256
  RANDOM_LAYER: True
  TASK: True
  USE: True
  USE_ENTROPY: False
DATA:
  DATASET: biosnap
  SPLIT: cluster
DECODER:
  BINARY: 2
  HIDDEN_DIM: 512
  IN_DIM: 256
  NAME: MLP
  OUT_DIM: 128
DRUG:
  HIDDEN_LAYERS: [128, 128, 128]
  MAX_NODES: 290
  NODE_IN_EMBEDDING: 128
  NODE_IN_FEATS: 7
  PADDING: True
PROTEIN:
  EMBEDDING_DIM: 128
  KERNEL_SIZE: [3, 6, 9]
  NUM_FILTERS: [128, 128, 128]
  PADDING: True
RESULT:
  SAVE_MODEL: True
SOLVER:
  BATCH_SIZE: 32
  DA_LEARNING_RATE: 5e-05
  LEARNING_RATE: 0.0001
  MAX_EPOCH: 2
  NUM_WORKERS: 0
  SEED: 20
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="step-1-data-loading-and-preparation">
<h2>Step 1: Data Loading and Preparation<a class="headerlink" href="#step-1-data-loading-and-preparation" title="Link to this heading">#</a></h2>
<section id="data-downloading">
<h3>Data Downloading<a class="headerlink" href="#data-downloading" title="Link to this heading">#</a></h3>
<p>Please run the following cell to download necessary datasets.</p>
<div class="cell tag_hide-input tag_hide-output docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>!rm -rf data checkpoint &amp;&amp; mkdir data
!gdown 1ogOcxZn-1q418LOT-gQ94aHQV0Y1sOmk --output data/drug-target-interaction.zip
!unzip -qo data/drug-target-interaction.zip -d data/
!mv data/drug-target-interaction/checkpoint ./
</pre></div>
</div>
</div>
</details>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading...
From (original): https://drive.google.com/uc?id=1ogOcxZn-1q418LOT-gQ94aHQV0Y1sOmk
From (redirected): https://drive.google.com/uc?id=1ogOcxZn-1q418LOT-gQ94aHQV0Y1sOmk&amp;confirm=t&amp;uuid=2840f509-90c2-4c19-9458-dd54256f6088
To: /content/data/drug-target-interaction.zip
100% 78.4M/78.4M [00:00&lt;00:00, 168MB/s]
</pre></div>
</div>
</div>
</details>
</div>
<p>Exercise: Check the data is ready</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import os
import shutil

print(&quot;Contents of the data folder:&quot;)
for item in os.listdir(&quot;data/drug-target-interaction&quot;):
    print(item)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Contents of the data folder:
biosnap
bindingdb
</pre></div>
</div>
</div>
</div>
<p>The data content is structured as follows:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="w">    </span>├───data
<span class="w">    </span>│<span class="w">   </span>├───checkpoint
<span class="w">    </span>│<span class="w">   </span>├───bindingdb
<span class="w">    </span>│<span class="w">   </span>├───biosnap
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">data</span></code> folder contains two datasets: <code class="docutils literal notranslate"><span class="pre">bindingdb</span></code> and <code class="docutils literal notranslate"><span class="pre">biosnap</span></code>. Each dataset folder contains the following files. The <code class="docutils literal notranslate"><span class="pre">checkpoint</span></code> folder contains the saved model checkpoint, which are used later in the interpretation section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>print(&quot;Contents of bindingdb folder:&quot;)
for item in os.listdir(&quot;data/drug-target-interaction/bindingdb&quot;):
    print(item)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Contents of bindingdb folder:
random
interpretation_samples.csv
cluster
full.csv
</pre></div>
</div>
</div>
</div>
<p>Each dataset folder follows the structure:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="w">    </span>├───dataset_name
<span class="w">    </span>│<span class="w">   </span>├───cluster
<span class="w">    </span>│<span class="w">   </span>│<span class="w">   </span>├───source_train.csv
<span class="w">    </span>│<span class="w">   </span>│<span class="w">   </span>├───target_train.csv
<span class="w">    </span>│<span class="w">   </span>│<span class="w">   </span>├───target_test.csv
<span class="w">    </span>│<span class="w">   </span>├───random
<span class="w">    </span>│<span class="w">   </span>│<span class="w">   </span>├───test.csv
<span class="w">    </span>│<span class="w">   </span>│<span class="w">   </span>├───train.csv
<span class="w">    </span>│<span class="w">   </span>│<span class="w">   </span>├───val.csv
<span class="w">    </span>│<span class="w">   </span>├───full.csv
</pre></div>
</div>
<p>We use the cluster dataset folder for cross-domain prediction, containing three parts:</p>
<ul class="simple">
<li><p>Train samples from the source domain: Drug–protein pairs the model learns from.</p></li>
<li><p>Train samples from the target domain: Additional training data from a different distribution to improve generalisation.</p></li>
<li><p>Test samples from the target domain: Unseen drug–protein pairs used to evaluate model performance on new data.</p></li>
</ul>
<p>The source and target sets are defined based on the clustering results.</p>
</section>
<section id="data-loading">
<h3>Data Loading<a class="headerlink" href="#data-loading" title="Link to this heading">#</a></h3>
<p>Here’s what each csv file looks like in a table format:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>SMILES</p></th>
<th class="head"><p>Protein Sequence</p></th>
<th class="head"><p>Y</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Fc1ccc(C2(COC…)</p></td>
<td><p>MDNVLPVDSDLS…</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>O=c1oc2c(O)c(…)</p></td>
<td><p>MMYSKLLTLTTL…</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>CC(C)Oc1cc(N…)</p></td>
<td><p>MGMACLTMTEME…</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
</div>
<p>Each row of the dataset contains three key pieces of information:</p>
<p><strong>Drugs</strong>:<br />
Drugs are often written as SMILES strings, which are like chemical formulas in text format (for example, <code class="docutils literal notranslate"><span class="pre">&quot;CC(=O)OC1=CC=CC=C1C(=O)O&quot;</span></code> is aspirin).</p>
<p><strong>Protein Sequence</strong><br />
This is a string of letters where each letter stands for an amino acid, the building blocks of proteins. For example, <code class="docutils literal notranslate"><span class="pre">MGYTSLLT...</span></code> is a short protein sequence.</p>
<p><strong>Y (Labels)</strong>:<br />
Each drug–protein pair is given a label:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">1</span></code> if they interact</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">0</span></code> if they do not</p></li>
</ul>
<p>Each row shows one drug–protein pair. The goal of our machine learning model is to predict the last column (<strong>Y</strong>) — whether or not the drug and protein interact.</p>
<p>You can load CSV files into Python using tools like <code class="docutils literal notranslate"><span class="pre">pandas</span></code>. The output shows a sample of the data, including the SMILES string for the drug, the protein sequence, the interaction label (Y) and the cluster ID.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import pandas as pd

dataFolder = os.path.join(
    f&quot;data/drug-target-interaction/{cfg.DATA.DATASET}&quot;, str(cfg.DATA.SPLIT)
)

df_train_source = pd.read_csv(os.path.join(dataFolder, &quot;source_train.csv&quot;))
df_train_target = pd.read_csv(os.path.join(dataFolder, &quot;target_train.csv&quot;))
df_test_target = pd.read_csv(os.path.join(dataFolder, &quot;target_test.csv&quot;))

print(&quot;Sample example:&quot;, df_train_source.iloc[0])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sample example: SMILES                              CC1=CN=C2N1C=CN=C2NCC1=CC=NC=C1
Protein           MARSLLLPLQILLLSLALETAGEEAQGDKIIDGAPCARGSHPWQVA...
Y                                                               0.0
drug_cluster                                                   1904
target_cluster                                                 1528
Name: 0, dtype: object
</pre></div>
</div>
</div>
</div>
</section>
<section id="data-preprocessing">
<h3>Data Preprocessing<a class="headerlink" href="#data-preprocessing" title="Link to this heading">#</a></h3>
<p>We convert drug SMILES strings into molecular graphs using <code class="docutils literal notranslate"><span class="pre">kale.loaddata.molecular_datasets.smiles_to_graph</span></code>, encoding atom-level features as node attributes and bond types as edges.</p>
<p>Protein sequences are transformed into fixed-length integer arrays using <code class="docutils literal notranslate"><span class="pre">kale.prepdata.chem_transform.integer_label_protein</span></code>, with each amino acid mapped to an integer and sequences padded or truncated to a uniform length.</p>
<p>Finally, the <code class="docutils literal notranslate"><span class="pre">kale.loaddata.molecular_datasets.DTIDataset</span></code> class packages drugs, proteins, and labels into a PyTorch-ready dataset.</p>
<p><strong>Note:</strong> If you encounter an error related to requiring numpy <code class="docutils literal notranslate"><span class="pre">&lt;2.0</span></code>, simply ignore it and re-run this block until it completes successfully.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>from kale.loaddata.molecular_datasets import DTIDataset

# Create preprocessed datasets
train_dataset = DTIDataset(df_train_source.index.values, df_train_source)
train_target_dataset = DTIDataset(df_train_target.index.values, df_train_target)
test_target_dataset = DTIDataset(df_test_target.index.values, df_test_target)
</pre></div>
</div>
</div>
</div>
<p>We load data in small, manageable pieces called batches to save memory and speed up training. We use <code class="docutils literal notranslate"><span class="pre">kale.loaddata.sampler.MultiDataLoader</span></code> from PyKale to load one batch from the source domain and one from the target domain at each training step.</p>
<p>First, we specify a few DataLoader parameters:</p>
<ul class="simple">
<li><p>Batch size: Number of samples per batch</p></li>
<li><p>Shuffle: Randomly shuffle data</p></li>
<li><p>Number of workers: Parallel data loading</p></li>
<li><p>Drop last: Discard the last incomplete batch for consistent batch sizes</p></li>
<li><p>Collate function: Use graph_collate_func to batch variable-sized molecular graphs</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>from torch.utils.data import DataLoader
from kale.loaddata.molecular_datasets import graph_collate_func
from kale.loaddata.sampler import MultiDataLoader

params = {
    &quot;batch_size&quot;: cfg.SOLVER.BATCH_SIZE,
    &quot;shuffle&quot;: True,
    &quot;num_workers&quot;: cfg.SOLVER.NUM_WORKERS,
    &quot;drop_last&quot;: True,
    &quot;collate_fn&quot;: graph_collate_func,
}

params
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;batch_size&#39;: 32,
 &#39;shuffle&#39;: True,
 &#39;num_workers&#39;: 0,
 &#39;drop_last&#39;: True,
 &#39;collate_fn&#39;: &lt;function kale.loaddata.molecular_datasets.graph_collate_func(x)&gt;}
</pre></div>
</div>
</div>
</div>
<p>Then, we create a DataLoader from both the source and target datasets for training.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>print(&quot;Using domain adaptation:&quot;, cfg.DA.USE)

if not cfg.DA.USE:
    training_generator = DataLoader(train_dataset, **params)
else:
    source_generator = DataLoader(train_dataset, **params)
    target_generator = DataLoader(train_target_dataset, **params)

    # Get the number of batches in the longer dataset to align both
    n_batches = max(len(source_generator), len(target_generator))

    # Combine the source and target data loaders using MultiDataLoader
    training_generator = MultiDataLoader(
        dataloaders=[source_generator, target_generator], n_batches=n_batches
    )
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Using domain adaptation: True
</pre></div>
</div>
</div>
</div>
<p>Lastly, we set up DataLoaders for validation and testing. Since we don’t want to shuffle or drop any samples, we adjust the parameters accordingly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># Update parameters for validation/testing (no shuffling, keep all data)
params.update({&quot;shuffle&quot;: False, &quot;drop_last&quot;: False})

# Create validation and test data loaders
valid_generator = DataLoader(test_target_dataset, **params)
test_generator = DataLoader(test_target_dataset, **params)
</pre></div>
</div>
</div>
</div>
</section>
<section id="exercise-dataset-inspection">
<h3>Exercise: Dataset Inspection<a class="headerlink" href="#exercise-dataset-inspection" title="Link to this heading">#</a></h3>
<p>Once the dataset is ready, let’s inspect one sample from the training data to check the input graph, protein sequence, and label format.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># Get the first batch (contains one batch from source and one from target)
first_batch = next(iter(training_generator))

# Unpack source and target batches
source_batch, target_batch = first_batch

# Inspect the first sample from the source batch
print(&quot;First sample from source batch:&quot;)
print(&quot;Drug graph:&quot;, source_batch[0][0])
print(&quot;Protein sequence:&quot;, source_batch[1][0])
print(&quot;Label:&quot;, source_batch[2][0])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>First sample from source batch:
Drug graph: Data(x=[290, 7], edge_index=[2, 91], edge_attr=[91, 1], num_nodes=290)
Protein sequence: tensor([11., 14., 16.,  ...,  0.,  0.,  0.], dtype=torch.float64)
Label: tensor(0., dtype=torch.float64)
</pre></div>
</div>
</div>
</div>
<p>This sample is a tuple with three parts:</p>
<ol class="arabic simple">
<li><p><strong>Drug Graph</strong></p></li>
</ol>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">x=[290,</span> <span class="pre">7]</span></code>: Feature matrix with 290 atoms (nodes) and 7 features per atom.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">edge_index=[2,</span> <span class="pre">58]</span></code>: Shows 146 edges, with source and target node indices.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">edge_attr=[58,</span> <span class="pre">1]</span></code>: Each edge has 1 bond feature, such as bond type.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">num_nodes=290</span></code>: Confirms the graph has 290 nodes.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p><strong>Protein Features (array)</strong></p></li>
</ol>
<ul class="simple">
<li><p>Example values: <code class="docutils literal notranslate"><span class="pre">[11.,</span>&#160; <span class="pre">1.,</span> <span class="pre">18.,</span> <span class="pre">...,</span>&#160; <span class="pre">0.,</span>&#160; <span class="pre">0.,</span>&#160; <span class="pre">0.]</span></code>: A fixed-length numeric array representing the protein sequence. Each position holds an integer-encoded amino acid, with zeros for padding.</p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p><strong>Label (float)</strong></p></li>
</ol>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">0.0</span></code>; The ground-truth interaction label indicating no interaction.</p></li>
</ul>
</section>
</section>
<section id="step-2-model-definition">
<h2>Step 2: Model Definition<a class="headerlink" href="#step-2-model-definition" title="Link to this heading">#</a></h2>
<section id="embed">
<h3>Embed<a class="headerlink" href="#embed" title="Link to this heading">#</a></h3>
<p>DrugBAN consists of three main components: a Graph Convolutional Network (GCN) for extracting structural features from drug molecular graphs, a Convolutional Neural Network (CNN) for encoding protein sequences, and a Bilinear Attention Network (BAN) for fusing drug and protein features. The fused representation is then passed through a Multi-Layer Perceptron (MLP) classifier to predict interaction scores.</p>
<p>We define the DrugBAN class in <code class="docutils literal notranslate"><span class="pre">kale.embed.ban</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>from kale.embed.ban import DrugBAN

model = DrugBAN(**cfg)
print(model)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DrugBAN(
  (drug_extractor): MolecularGCN(
    (init_transform): Linear(in_features=7, out_features=128, bias=False)
    (gcn_layers): ModuleList(
      (0-2): 3 x GCNConv(128, 128)
    )
  )
  (protein_extractor): ProteinCNN(
    (embedding): Embedding(26, 128, padding_idx=0)
    (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,))
    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv1d(128, 128, kernel_size=(6,), stride=(1,))
    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv1d(128, 128, kernel_size=(9,), stride=(1,))
    (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bcn): BANLayer(
    (v_net): FCNet(
      (main): Sequential(
        (0): Dropout(p=0.2, inplace=False)
        (1): Linear(in_features=128, out_features=768, bias=True)
        (2): ReLU()
      )
    )
    (q_net): FCNet(
      (main): Sequential(
        (0): Dropout(p=0.2, inplace=False)
        (1): Linear(in_features=128, out_features=768, bias=True)
        (2): ReLU()
      )
    )
    (p_net): AvgPool1d(kernel_size=(3,), stride=(3,), padding=(0,))
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp_classifier): MLPDecoder(
    (fc1): Linear(in_features=256, out_features=512, bias=True)
    (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fc2): Linear(in_features=512, out_features=512, bias=True)
    (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fc3): Linear(in_features=512, out_features=128, bias=True)
    (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fc4): Linear(in_features=128, out_features=2, bias=True)
  )
)
</pre></div>
</div>
</div>
</div>
</section>
<section id="predict">
<h3>Predict<a class="headerlink" href="#predict" title="Link to this heading">#</a></h3>
<p>We use the PyKale pipeline API <code class="docutils literal notranslate"><span class="pre">kale.pipeline.drugban_trainer</span></code> to connect dataloaders, encoders and outcoders for model training and evaluation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>from kale.pipeline.drugban_trainer import DrugbanTrainer

drugban_trainer = DrugbanTrainer(
    model=DrugBAN(**cfg),
    solver_lr=cfg.SOLVER.LEARNING_RATE,
    num_classes=cfg.DECODER.BINARY,
    batch_size=cfg.SOLVER.BATCH_SIZE,
    is_da=cfg.DA.USE,
    solver_da_lr=cfg.SOLVER.DA_LEARNING_RATE,
    da_init_epoch=cfg.DA.INIT_EPOCH,
    da_method=cfg.DA.METHOD,
    original_random=cfg.DA.ORIGINAL_RANDOM,
    use_da_entropy=cfg.DA.USE_ENTROPY,
    da_random_layer=cfg.DA.RANDOM_LAYER,
    da_random_dim=cfg.DA.RANDOM_DIM,
    decoder_in_dim=cfg.DECODER.IN_DIM,
)
</pre></div>
</div>
</div>
</div>
<p>We want to save the best model during training so we can reuse it later without needing to retrain. PyTorch Lightning’s <code class="docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> does this by automatically saving the model whenever it achieves a new best validation AUROC score.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint

checkpoint_cb = ModelCheckpoint(
    filename=&quot;{epoch}-{step}-{val_BinaryAUROC:.4f}&quot;,
    monitor=&quot;val_BinaryAUROC&quot;,
    mode=&quot;max&quot;,
)
</pre></div>
</div>
</div>
</div>
<p>We now create the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import torch

trainer = pl.Trainer(
    callbacks=[checkpoint_cb],
    devices=&quot;auto&quot;,
    accelerator=&quot;auto&quot;,
    max_epochs=cfg.SOLVER.MAX_EPOCH,
    deterministic=True,
)
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True
INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores
INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<section id="step-3-model-training">
<h2>Step 3: Model Training<a class="headerlink" href="#step-3-model-training" title="Link to this heading">#</a></h2>
<section id="train">
<h3>Train<a class="headerlink" href="#train" title="Link to this heading">#</a></h3>
<p>After setting up the model and data loaders, we now start training the full DrugBAN model using the PyTorch Lightning Trainer via calling <code class="docutils literal notranslate"><span class="pre">trainer.fit()</span></code>.</p>
<section id="what-happens-here">
<h4>What Happens Here?<a class="headerlink" href="#what-happens-here" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>The model receives batches of drug-protein pairs from the training data loader.</p></li>
<li><p>During each step, the GCN, CNN, BAN layer, and MLP classifier are updated to improve interaction prediction.</p></li>
<li><p>Validation is automatically run at the end of each epoch to track performance and save the best model based on AUROC.</p></li>
</ul>
<p>This code block takes approximately 5 minutes to complete.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>trainer.fit(
    drugban_trainer,
    train_dataloaders=training_generator,
    val_dataloaders=valid_generator,
)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
INFO:pytorch_lightning.callbacks.model_summary:
  | Name                 | Type                | Params | Mode 
---------------------------------------------------------------------
0 | model                | DrugBAN             | 1.0 M  | train
1 | domain_discriminator | DomainNetSmallImage | 133 K  | train
2 | random_layer         | RandomLayer         | 66.0 K | train
3 | valid_metrics        | MetricCollection    | 0      | train
4 | test_metrics         | MetricCollection    | 0      | train
---------------------------------------------------------------------
1.2 M     Trainable params
0         Non-trainable params
1.2 M     Total params
4.847     Total estimated model params size (MB)
64        Modules in train mode
0         Modules in eval mode
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "9901815e548947d8b664a7be70ed0fe9", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "c93c19136b484821926f59888165e195", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[17:56:37] Unusual charge on atom 0 number of radical electrons set to zero
[17:56:52] Unusual charge on atom 0 number of radical electrons set to zero
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "96b7d503fbca4094ac847a36d3c50a2d", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[17:57:26] Unusual charge on atom 0 number of radical electrons set to zero
[17:57:48] Unusual charge on atom 0 number of radical electrons set to zero
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "1d02467474a149a2892e78dc35f08742", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=2` reached.
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="step-4-evaluation">
<h2>Step 4: Evaluation<a class="headerlink" href="#step-4-evaluation" title="Link to this heading">#</a></h2>
<p>Once training is complete, we evaluate the model on the test set using <code class="docutils literal notranslate"><span class="pre">trainer.test()</span></code>.</p>
<section id="what-is-included-in-this-step">
<h3>What is included in this step?<a class="headerlink" href="#what-is-included-in-this-step" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>The best model checkpoint (based on validation AUROC) is automatically loaded.</p></li>
<li><p>The model runs on the test data to generate predictions.</p></li>
<li><p>Final classification metrics, including AUROC, F1 score, accuracy, sensitivity, and specificity, are calculated and logged.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>trainer.test(drugban_trainer, dataloaders=test_generator, ckpt_path=&quot;best&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>INFO:pytorch_lightning.utilities.rank_zero:Restoring states from the checkpoint path at /content/lightning_logs/version_3/checkpoints/epoch=1-step=1220-val_BinaryAUROC=0.5209.ckpt
INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
INFO:pytorch_lightning.utilities.rank_zero:Loaded model weights from the checkpoint at /content/lightning_logs/version_3/checkpoints/epoch=1-step=1220-val_BinaryAUROC=0.5209.ckpt
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "40c354c897b74e07b50023a18c57b134", "version_major": 2, "version_minor": 0}</script><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold">        Test metric        </span>┃<span style="font-weight: bold">       DataLoader 0        </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│<span style="color: #008080; text-decoration-color: #008080">     test_BinaryAUROC      </span>│<span style="color: #800080; text-decoration-color: #800080">    0.5208548307418823     </span>│
│<span style="color: #008080; text-decoration-color: #008080">    test_BinaryAccuracy    </span>│<span style="color: #800080; text-decoration-color: #800080">    0.49503859877586365    </span>│
│<span style="color: #008080; text-decoration-color: #008080">    test_BinaryF1Score     </span>│<span style="color: #800080; text-decoration-color: #800080">   0.008658008649945259    </span>│
│<span style="color: #008080; text-decoration-color: #008080">     test_BinaryRecall     </span>│<span style="color: #800080; text-decoration-color: #800080">   0.004395604599267244    </span>│
│<span style="color: #008080; text-decoration-color: #008080">  test_BinarySpecificity   </span>│<span style="color: #800080; text-decoration-color: #800080">     0.98893803358078      </span>│
│<span style="color: #008080; text-decoration-color: #008080">   test_accuracy_sklearn   </span>│<span style="color: #800080; text-decoration-color: #800080">    0.5148842334747314     </span>│
│<span style="color: #008080; text-decoration-color: #008080">    test_auroc_sklearn     </span>│<span style="color: #800080; text-decoration-color: #800080">    0.5208548307418823     </span>│
│<span style="color: #008080; text-decoration-color: #008080">      test_f1_sklearn      </span>│<span style="color: #800080; text-decoration-color: #800080">    0.6687231063842773     </span>│
│<span style="color: #008080; text-decoration-color: #008080">         test_loss         </span>│<span style="color: #800080; text-decoration-color: #800080">     1.135701298713684     </span>│
│<span style="color: #008080; text-decoration-color: #008080">   test_optim_threshold    </span>│<span style="color: #800080; text-decoration-color: #800080">   0.048901185393333435    </span>│
│<span style="color: #008080; text-decoration-color: #008080">     test_sensitivity      </span>│<span style="color: #800080; text-decoration-color: #800080">   0.044247787445783615    </span>│
│<span style="color: #008080; text-decoration-color: #008080">     test_specificity      </span>│<span style="color: #800080; text-decoration-color: #800080">    0.9824175834655762     </span>│
└───────────────────────────┴───────────────────────────┘
</pre>
</div><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[{&#39;test_loss&#39;: 1.135701298713684,
  &#39;test_auroc_sklearn&#39;: 0.5208548307418823,
  &#39;test_accuracy_sklearn&#39;: 0.5148842334747314,
  &#39;test_f1_sklearn&#39;: 0.6687231063842773,
  &#39;test_optim_threshold&#39;: 0.048901185393333435,
  &#39;test_sensitivity&#39;: 0.044247787445783615,
  &#39;test_specificity&#39;: 0.9824175834655762,
  &#39;test_BinaryAUROC&#39;: 0.5208548307418823,
  &#39;test_BinaryF1Score&#39;: 0.008658008649945259,
  &#39;test_BinaryRecall&#39;: 0.004395604599267244,
  &#39;test_BinarySpecificity&#39;: 0.98893803358078,
  &#39;test_BinaryAccuracy&#39;: 0.49503859877586365}]
</pre></div>
</div>
</div>
</div>
</section>
<section id="performance-comparison">
<h3>Performance Comparison<a class="headerlink" href="#performance-comparison" title="Link to this heading">#</a></h3>
<p>The earlier example was a simple demonstration. To properly evaluate DrugBAN against baseline models, we train it for 100 epochs across multiple random seeds.</p>
<p>We provide a checkpoint trained for 100 epochs in the <code class="docutils literal notranslate"><span class="pre">checkpoint</span></code> for your test after the tutorial. We will also use the provided checkpoint for the interpretation section for a better visualization.</p>
<p>The figure below shows the performance of different models on the BioSNAP and BindingDB datasets:</p>
<ul class="simple">
<li><p>Left plot: AUROC (Area Under the ROC Curve)</p></li>
<li><p>Right plot: AUPRC (Area Under the Precision–Recall Curve)</p></li>
</ul>
<p><img alt="" src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs42256-022-00605-1/MediaObjects/42256_2022_605_Fig3_HTML.png?as=webp" /></p>
<p>The box plots show the median as the centre lines and the mean as green triangles. The minima and lower percentile represent the worst and second-worst scores. The maxima and upper percentile indicate the best and second-best scores. Supplementary Table 2 provides the data statistics of the BindingDB and BioSNAP datasets.</p>
</section>
</section>
<section id="step-5-interpretation">
<h2>Step 5: Interpretation<a class="headerlink" href="#step-5-interpretation" title="Link to this heading">#</a></h2>
<p>We interpret the trained models by analyzing the learned attention weights. In this step, we will use PyKale’s API to</p>
<ol class="arabic simple">
<li><p>draw the attention maps of the Bilinear Attention Network (BAN) layer, and</p></li>
<li><p>generate molecule images with attention highlights.</p></li>
</ol>
<p>This helps us understand which parts of the drug contribute to the interaction with the target protein.</p>
<section id="extracting-attention-weights">
<h3>Extracting Attention Weights<a class="headerlink" href="#extracting-attention-weights" title="Link to this heading">#</a></h3>
<p>First, we need to load the test dataset and create a DataLoader for it. This will allow us to process the test samples in batches. We define functions to create the test dataset and DataLoader.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>def get_test_dataset(dataFolder):
    df_test_target = pd.read_csv(dataFolder)
    test_target_dataset = DTIDataset(df_test_target.index.values, df_test_target)
    return test_target_dataset


def get_test_dataloader(dataset, batchsize, num_workers, collate_fn):
    test_dataloader = DataLoader(
        dataset,
        batch_size=batchsize,
        num_workers=num_workers,
        collate_fn=collate_fn,
        shuffle=False,
        drop_last=True,
    )
    return test_dataloader
</pre></div>
</div>
</div>
</div>
<p>We load a small subset of samples for testing from the provided <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file. You can create your own <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file with the same format to test your drug–protein pairs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>test_dataFolder = &quot;data/drug-target-interaction/bindingdb/interpretation_samples.csv&quot;
</pre></div>
</div>
</div>
</div>
<p>We then build the test dataset and DataLoader using the functions defined above. The <code class="docutils literal notranslate"><span class="pre">batchsize</span></code> is set to 1 to ensure we process one sample at a time for attention visualization later.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>test_dataset = get_test_dataset(test_dataFolder)
test_dataloader = get_test_dataloader(
    test_dataset,
    batchsize=1,
    num_workers=cfg.SOLVER.NUM_WORKERS,
    collate_fn=graph_collate_func,
)
</pre></div>
</div>
</div>
</div>
<p>Then, we use the following function to load the trained model with the PyKale API.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>def get_model_from_ckpt(ckpt_path, config):
    return DrugbanTrainer.load_from_checkpoint(
        checkpoint_path=ckpt_path,
        model=DrugBAN(**config),
        solver_lr=config.SOLVER.LEARNING_RATE,
        num_classes=config.DECODER.BINARY,
        batch_size=config.SOLVER.BATCH_SIZE,
        # --- domain adaptation parameters ---
        is_da=config.DA.USE,
        solver_da_lr=config.SOLVER.DA_LEARNING_RATE,
        da_init_epoch=config.DA.INIT_EPOCH,
        da_method=config.DA.METHOD,
        original_random=config.DA.ORIGINAL_RANDOM,
        use_da_entropy=config.DA.USE_ENTROPY,
        da_random_layer=config.DA.RANDOM_LAYER,
        # --- discriminator parameters ---
        da_random_dim=config.DA.RANDOM_DIM,
        decoder_in_dim=config.DECODER.IN_DIM,
    )
</pre></div>
</div>
</div>
</div>
<p>Once the model and test data are prepared, we extract attention maps from the trained model. We set the directory to the provided checkpoint file, load the trained model, and set it to evaluation mode.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>checkpoint_path = &quot;checkpoint/best.ckpt&quot;
model = get_model_from_ckpt(checkpoint_path, cfg)
model.model.eval()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DrugBAN(
  (drug_extractor): MolecularGCN(
    (init_transform): Linear(in_features=7, out_features=128, bias=False)
    (gcn_layers): ModuleList(
      (0-2): 3 x GCNConv(128, 128)
    )
  )
  (protein_extractor): ProteinCNN(
    (embedding): Embedding(26, 128, padding_idx=0)
    (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,))
    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv1d(128, 128, kernel_size=(6,), stride=(1,))
    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv3): Conv1d(128, 128, kernel_size=(9,), stride=(1,))
    (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bcn): BANLayer(
    (v_net): FCNet(
      (main): Sequential(
        (0): Dropout(p=0.2, inplace=False)
        (1): Linear(in_features=128, out_features=768, bias=True)
        (2): ReLU()
      )
    )
    (q_net): FCNet(
      (main): Sequential(
        (0): Dropout(p=0.2, inplace=False)
        (1): Linear(in_features=128, out_features=768, bias=True)
        (2): ReLU()
      )
    )
    (p_net): AvgPool1d(kernel_size=(3,), stride=(3,), padding=(0,))
    (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (mlp_classifier): MLPDecoder(
    (fc1): Linear(in_features=256, out_features=512, bias=True)
    (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fc2): Linear(in_features=512, out_features=512, bias=True)
    (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fc3): Linear(in_features=512, out_features=128, bias=True)
    (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fc4): Linear(in_features=128, out_features=2, bias=True)
  )
)
</pre></div>
</div>
</div>
</div>
<p>We then iterate through the test DataLoader, passing each batch of drug and protein pairs to the model. The model’s forward method returns the attention weights. After processing all batches, we concatenate the attention tensors into a single tensor.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>from tqdm import tqdm

all_attentions = []
for batch in tqdm(test_dataloader):
    drug, protein, _ = batch
    drug, protein = drug.to(model.device), protein.to(model.device)

    _, _, _, _, attention = model.model.forward(
        drug, protein, mode=&quot;eval&quot;
    )  # [B, H, V, Q]

    attention = attention.detach().cpu()
    all_attentions.append(attention)

# Concatenate into one tensor: [N, H, V, Q]
all_attentions = torch.cat(all_attentions, dim=0)
torch.save(all_attentions, &quot;attention_maps.pt&quot;)

all_attentions.shape
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 6/6 [00:00&lt;00:00, 44.70it/s]
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([6, 2, 290, 1185])
</pre></div>
</div>
</div>
</div>
<p>The attention has shape [B, H, V, Q] (Number of drug-target pairs, Heads of attentions, Drug tokens, Protein tokens).</p>
</section>
<section id="visualize-attention-maps-and-molecule-images">
<h3>Visualize Attention Maps and Molecule Images<a class="headerlink" href="#visualize-attention-maps-and-molecule-images" title="Link to this heading">#</a></h3>
<p>Once attention maps are saved, run the visualization script:</p>
<p>This script will:</p>
<ol class="arabic">
<li><p>Load the attention weights and the corresponding SMILES + protein data.</p></li>
<li><p>Plot:</p>
<p>a) A heatmap of attention over drug–protein tokens.</p>
<p>b) Molecular structures with atoms highlighted by attention values.</p>
</li>
</ol>
<p>The output images are saved in the <code class="docutils literal notranslate"><span class="pre">visualization</span></code> directory. You can also modify the <code class="docutils literal notranslate"><span class="pre">data_file</span></code> to use your own input in the same format as <code class="docutils literal notranslate"><span class="pre">target_test.csv</span></code>.</p>
<p>We first import the necessary PyKale APIs and set the output directory.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>from kale.interpret.visualize import draw_attention_map, draw_mol_with_attention
from kale.prepdata.tensor_reshape import normalize_tensor

out_dir = &quot;./visualization&quot;
os.makedirs(out_dir, exist_ok=True)
</pre></div>
</div>
</div>
</div>
<p>We then load the attention maps, data, and SMILES strings from the test dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>attention = torch.load(&quot;attention_maps.pt&quot;, map_location=&quot;cpu&quot;)
data_df = pd.read_csv(test_dataFolder)
smiles = data_df[&quot;SMILES&quot;]
proteins = data_df[&quot;Protein&quot;]
</pre></div>
</div>
</div>
</div>
<p>We select the first sample from the attention maps and corresponding SMILES and protein sequence for visualization.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>index = 0
att_path = os.path.join(out_dir, f&quot;att_map_{index}.png&quot;)
mol_path = os.path.join(out_dir, f&quot;mol_{index}.svg&quot;)
</pre></div>
</div>
</div>
</div>
<p>We crop the attention map to the actual lengths of the drug and protein sequences. This is important because the attention map may include padding tokens.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>from rdkit import Chem


def get_real_length(smile, protein_sequence):
    &quot;&quot;&quot;Get the real length of the drug and protein sequences.&quot;&quot;&quot;
    mol = Chem.MolFromSmiles(smile)
    return mol.GetNumAtoms(), len(protein_sequence)


att = attention[index]  # [H, V, Q]
smile = smiles[index]
protein = proteins[index]
real_drug_len, real_prot_len = get_real_length(smile, protein)
att = att[:, :real_drug_len, :real_prot_len].mean(0)  # [V, Q]

# Normalize
att = normalize_tensor(att)
</pre></div>
</div>
</div>
</div>
<p>Finally, we save the attention map and the molecule image with attention highlights.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>draw_attention_map(
    att,
    att_path,
    title=f&quot;Drug {index} Attention&quot;,
    xlabel=&quot;Drug Tokens&quot;,
    ylabel=&quot;Protein Tokens&quot;,
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>draw_mol_with_attention(att.mean(dim=1), smile, mol_path)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>from IPython.display import Image, SVG

attention_plot = Image(att_path)
molecular_img = SVG(mol_path)
display(attention_plot)
display(molecular_img)
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/7aef2419b368e38ef8b35f1671353b143c874dfdf1efe4e0f8d214ee2c0d6b25.png" src="../../_images/7aef2419b368e38ef8b35f1671353b143c874dfdf1efe4e0f8d214ee2c0d6b25.png" />
<img alt="../../_images/5e13ad8feab0b288d86960abf7217e7f7d66fc7a8df3b19bdf3bae5a05387960.svg" src="../../_images/5e13ad8feab0b288d86960abf7217e7f7d66fc7a8df3b19bdf3bae5a05387960.svg" />
</div>
</div>
<p>The output images are saved in the <code class="docutils literal notranslate"><span class="pre">visualization</span></code> directory. The attention map shows how much each drug token attends to each protein token, while the molecule image highlights the atoms based on their attention values.</p>
</section>
</section>
<section id="extension-tasks">
<h2>Extension Tasks<a class="headerlink" href="#extension-tasks" title="Link to this heading">#</a></h2>
<section id="task-1">
<h3>Task 1<a class="headerlink" href="#task-1" title="Link to this heading">#</a></h3>
<p>To use the BindingDB dataset, modify the relevant line in the Configuration section of Step 0 as shown below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cfg</span><span class="o">.</span><span class="n">DATA</span><span class="o">.</span><span class="n">DATASET</span> <span class="o">=</span> <span class="s2">&quot;bindingdb&quot;</span>
</pre></div>
</div>
<p>Reload the dataset and re-run training and testing.</p>
<blockquote>
<div><p>Tip: See if the model struggles more or less with the new dataset. It can reveal how generalisable DrugBAN is.</p>
</div></blockquote>
</section>
<section id="task-2">
<h3>Task 2<a class="headerlink" href="#task-2" title="Link to this heading">#</a></h3>
<p>Turn off domain adaptation by updating the config file and re-running training and testing.</p>
<p>Replace <code class="docutils literal notranslate"><span class="pre">configs/DA_cross_domain.yaml</span></code> with <code class="docutils literal notranslate"><span class="pre">configs/non_DA_cross_domain.yaml</span></code> in the Configuration section of Step 0 as shown below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cfg</span><span class="o">.</span><span class="n">merge_from_file</span><span class="p">(</span><span class="s2">&quot;configs/non_DA_cross_domain.yaml&quot;</span><span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><p>Tip: Compare the results with and without domain adaptation to see how it affects model performance.</p>
</div></blockquote>
</section>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<p>[1] Lu, H., Liu, X., Zhou, S., Turner, R., Bai, P., Koot, R. E., … &amp; Xu, H. (2022, October). PyKale: Knowledge-aware machine learning from multiple sources in Python. In <em>Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management</em> (pp. 4274-4278).</p>
<p>[2] Zitnik, M., Sosič, R., Maheshwari, S. &amp; Leskovec, J. (2018). BioSNAP datasets: Stanford biomedical network dataset collection. <a class="reference external" href="https://snap.stanford.edu/biodata">https://snap.stanford.edu/biodata</a>.</p>
<p>[3] Gilson, M. K., Liu, T., Baitaluk, M., Nicola, G., Hwang, L., &amp; Chong, J. (2016). BindingDB in 2015: a public database for medicinal chemistry, computational chemistry and systems pharmacology. Nucleic acids research, 44(D1), D1045-D1053.</p>
<p>[4] Bai, P., Miljković, F., John, B., &amp; Lu, H. (2023). Interpretable bilinear attention network with domain adaptation improves drug–target prediction. Nature Machine Intelligence, 5(2), 126-136.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./tutorials/drug-target-interaction"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../cardiac-hemodynamics-assessment/extend-reading/extension-tasks.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Extension Tasks</p>
      </div>
    </a>
    <a class="right-next"
       href="../multiomics-cancer-classification/tutorial-cancer.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Multiomics Cancer Classification</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-0-environment-preparation">Step 0: Environment Preparation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#package-installation">Package Installation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#configuration">Configuration</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-data-loading-and-preparation">Step 1: Data Loading and Preparation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-downloading">Data Downloading</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-loading">Data Loading</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preprocessing">Data Preprocessing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-dataset-inspection">Exercise: Dataset Inspection</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-model-definition">Step 2: Model Definition</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#embed">Embed</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#predict">Predict</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-model-training">Step 3: Model Training</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train">Train</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#what-happens-here">What Happens Here?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-evaluation">Step 4: Evaluation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-included-in-this-step">What is included in this step?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-comparison">Performance Comparison</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-interpretation">Step 5: Interpretation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#extracting-attention-weights">Extracting Attention Weights</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-attention-maps-and-molecule-images">Visualize Attention Maps and Molecule Images</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extension-tasks">Extension Tasks</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#task-1">Task 1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#task-2">Task 2</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By PyKale Contributors
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>