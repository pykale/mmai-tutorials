{
  "cells": [
    {
      "metadata": {},
      "source": [
        "# Drug\u2013Target Interaction Prediction\n",
        "\n",
        "![](images/drugban-pyakle-api.png)\n",
        "\n",
        "\n",
        "In this tutorial, we will train models to predict the interaction between **two data modalities**: **molecules (drug)** and **proteins (target)** using `PyKale`. Drug-target interaction (DTI) plays a key role in drug discovery and identifying potential therapeutic targets. This example is based on the **DrugBAN** framework by [**Bai et al. (_Nature Machine Intelligence_, 2023)**](https://www.nature.com/articles/s42256-022-00605-1).\n",
        "\n",
        "The DTI prediction problem is formulated as a **binary classification task**, where the goal is to predict whether a given **drug\u2013protein pair interacts or not**. The DrugBAN framework tackles this problem using two key ideas:\n",
        "\n",
        "- **Bilinear Attention Network (BAN)**, which learns detailed feature representations for both drugs and proteins and captures local interaction patterns between them.\n",
        "\n",
        "- **Adversarial Domain Adaptation**, which helps the model generalise to out-of-distribution datasets, i.e., in clustering-based cross-validation instead of random splits, improving its ability to predict interactions on unseen drug\u2013target pairs.\n",
        "\n",
        "With `PyKale`, implementing such a multimodal DTI prediction pipeline is straightforward. The library provides ready-to-use modules and configuration support, making it easy to apply advanced techniques with minimal custom coding."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Step 0: Environment Preparation\n",
        "\n",
        "As a starting point, we will install the required packages and load a set of helper functions to assist throughout this tutorial.\n",
        "\n",
        "To prepare the helper functions and necessary materials, we download them from the GitHub repository.\n",
        "\n",
        "Moreover, we provide helper functions that can be inspected directly in the `.py` files located in the notebook's current directory. The additional helper script is:\n",
        "- [`config.py`](https://github.com/pykale/embc-mmai25/blob/main/tutorials/drug-target-interaction/configs.py): Defines the base configuration settings, which can be overridden using a custom `.yaml` file."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "import os\n",
        "\n",
        "!rm -rf /content/mmai-tutorials\n",
        "!git clone --single-branch -b main https://github.com/pykale/mmai-tutorials.git\n",
        "%cd /content/mmai-tutorials/tutorials/drug-target-interaction\n",
        "\n",
        "print(\"Changed working directory to:\", os.getcwd())"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Package Installation\n",
        "\n",
        "The main package required for this tutorial is `PyKale`.\n",
        "\n",
        "`PyKale` is an open-source interdisciplinary machine learning library developed at the University of Sheffield, with a focus on applications in biomedical and scientific domains.\n",
        "\n",
        "Then, we install `PyG` (PyTorch Geometric) and related packages.\n",
        "\n",
        "Please **do not** re-run this session after installation completed. Runing this installation multiple times will trigger issues related to `PyG`. If you want to re-run this installation, please click the `Runtime` on the top menu and choose `Disconnect and delete runtime` before installing."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "!pip install --quiet \\\n",
        "    git+https://github.com/pykale/pykale@main \\\n",
        "    yacs==0.1.8 \\\n",
        "    torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric \\\n",
        "    -f https://data.pyg.org/whl/torch-2.6.0+cu124.html \\\n",
        "    && echo \"pykale,yacs and wfdb installed successfully \u2705\" \\\n",
        "    || echo \"Failed to install pykale,yacs \u274c\""
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "We then hide the warnings messages to get a clear output."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "import os\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Exercise: Check NumPy Version"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"NumPy version:\", np.__version__)  # numpy should be 2.0.0"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Configuration\n",
        "\n",
        "To minimize the footprint of the notebook when specifying configurations, we provide a [`config.py`](https://github.com/pykale/embc-mmai25/blob/main/tutorials/drug-target-interaction/configs.py) file that defines default parameters. These can be customized by supplying a `.yaml` configuration file, such as [`configs/DA_cross_domain.yaml`](https://github.com/pykale/embc-mmai25/blob/main/tutorials/drug-target-interaction/configs/DA_cross_domain.yaml) as an example."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "from configs import get_cfg_defaults\n",
        "\n",
        "%cd /content/mmai-tutorials/tutorials/drug-target-interaction\n",
        "\n",
        "cfg = get_cfg_defaults()  # Load the default settings from config.py\n",
        "cfg.merge_from_file(\n",
        "    \"configs/DA_cross_domain.yaml\"\n",
        ")  # Update (or override) some of those settings using a custom YAML file"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "In this tutorial, we list the hyperparameters we would like users to play with outside the `.yaml` file:\n",
        "- `cfg.SOLVER.MAX_EPOCH`: Number of epochs in training stage. You can reduce the number of training epochs to shorten runtime.\n",
        "- `cfg.DATA.DATASET`: The dataset used in the study. This can be `bindingdb` or `biosnap`.\n",
        "\n",
        "As a quick exercise, please take a moment to review and understand the parameters in [`config.py`](https://github.com/pykale/embc-mmai25/blob/main/tutorials/drug-target-interaction/configs.py)."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "cfg.SOLVER.MAX_EPOCH = 2"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "You can also switch to a different dataset."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "cfg.DATA.DATASET = \"biosnap\""
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Exercise: Now print the full configuration to check all current hyperparameter and dataset settings."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "print(cfg)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 1: Data Loading and Preparation\n",
        "\n",
        "In this tutorial, we use the **Biosnap** dataset for the main demonstration and the **BindingDB** dataset for the exercise at the end."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Data downloading\n",
        "\n",
        "Please run the following cell to download necessary datasets."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "!rm -rf data\n",
        "!mkdir data\n",
        "!cd data\n",
        "\n",
        "!pip install -q gdown\n",
        "!gdown --id 1ogOcxZn-1q418LOT-gQ94aHQV0Y1sOmk --output data/drug-target-interaction.zip\n",
        "!unzip data/drug-target-interaction.zip -d data/"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Exercise: Check the data is ready"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "print(\"Contents of the folder:\")\n",
        "for item in os.listdir(\"data/drug-target-interaction\"):\n",
        "    print(item)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Each dataset folder follows the structure:\n",
        "\n",
        "```sh\n",
        "    \u251c\u2500\u2500\u2500dataset_name\n",
        "    \u2502   \u251c\u2500\u2500\u2500cluster\n",
        "    \u2502   \u2502   \u251c\u2500\u2500\u2500source_train.csv\n",
        "    \u2502   \u2502   \u251c\u2500\u2500\u2500target_train.csv\n",
        "    \u2502   \u2502   \u251c\u2500\u2500\u2500target_test.csv\n",
        "    \u2502   \u251c\u2500\u2500\u2500random\n",
        "    \u2502   \u2502   \u251c\u2500\u2500\u2500test.csv\n",
        "    \u2502   \u2502   \u251c\u2500\u2500\u2500train.csv\n",
        "    \u2502   \u2502   \u251c\u2500\u2500\u2500val.csv\n",
        "    \u2502   \u251c\u2500\u2500\u2500full.csv\n",
        "```"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "We use the cluster dataset folder for cross-domain prediction, containing three parts:\n",
        "\n",
        "- Train samples from the source domain: Drug\u2013protein pairs the model learns from.\n",
        "\n",
        "- Train samples from the target domain: Additional training data from a different distribution to improve generalisation.\n",
        "\n",
        "- Test samples from the target domain: Unseen drug\u2013protein pairs used to evaluate model performance on new data.\n",
        "\n",
        "The source and target sets are defined based on the clustering results."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Data loading"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "Here\u2019s what each csv file looks like in a table format:\n",
        "\n",
        "| SMILES             | Protein Sequence         | Y |\n",
        "|--------------------|--------------------------|---|\n",
        "| Fc1ccc(C2(COC\u2026)    | MDNVLPVDSDLS\u2026            | 1 |\n",
        "| O=c1oc2c(O)c(\u2026)    | MMYSKLLTLTTL\u2026            | 0 |\n",
        "| CC(C)Oc1cc(N\u2026)     | MGMACLTMTEME\u2026            | 1 |\n",
        "\n",
        "Each row of the dataset contains three key pieces of information:\n",
        "\n",
        "**Drugs**:  \n",
        "Drugs are often written as SMILES strings, which are like chemical formulas in text format (for example, `\"CC(=O)OC1=CC=CC=C1C(=O)O\"` is aspirin).  \n",
        "\n",
        "\n",
        "**Protein Sequence**  \n",
        "This is a string of letters where each letter stands for an amino acid, the building blocks of proteins. For example, `MGYTSLLT...` is a short protein sequence.\n",
        "\n",
        "\n",
        "**Y (Labels)**:  \n",
        "Each drug\u2013protein pair is given a label:\n",
        "- `1` if they interact\n",
        "- `0` if they do not\n",
        "\n",
        "\n",
        "Each row shows one drug\u2013protein pair. The goal of our machine learning model is to predict the last column (**Y**) \u2014 whether or not the drug and protein interact."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "You can load CSV files into Python using tools like `pandas`."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataFolder = os.path.join(\n",
        "    f\"data/drug-target-interaction/{cfg.DATA.DATASET}\", str(cfg.DATA.SPLIT)\n",
        ")\n",
        "\n",
        "df_train_source = pd.read_csv(os.path.join(dataFolder, \"source_train.csv\"))\n",
        "df_train_target = pd.read_csv(os.path.join(dataFolder, \"target_train.csv\"))\n",
        "df_test_target = pd.read_csv(os.path.join(dataFolder, \"target_test.csv\"))"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "We convert drug SMILES strings into molecular graphs using `kale.loaddata.molecular_datasets.smiles_to_graph`, encoding atom-level features as node attributes and bond types as edges.\n",
        "\n",
        "\n",
        "Protein sequences are transformed into fixed-length integer arrays using `kale.prepdata.chem_transform.integer_label_protein`, with each amino acid mapped to an integer and sequences padded or truncated to a uniform length.\n",
        "\n",
        "Finally, the `kale.loaddata.molecular_datasets.DTIDataset` class packages drugs, proteins, and labels into a PyTorch-ready dataset."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "**Note:** If you encounter an error related to requiring numpy `<2.0`, simply ignore it and re-run this block until it completes successfully."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "from kale.loaddata.molecular_datasets import DTIDataset\n",
        "\n",
        "# Create preprocessed datasets\n",
        "train_dataset = DTIDataset(df_train_source.index.values, df_train_source)\n",
        "train_target_dataset = DTIDataset(df_train_target.index.values, df_train_target)\n",
        "test_target_dataset = DTIDataset(df_test_target.index.values, df_test_target)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "We load data in small, manageable pieces called batches to save memory and speed up training. We use `kale.loaddata.sampler.MultiDataLoader` from PyKale to load one batch from the source domain and one from the target domain at each training step."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "First, we specify a few DataLoader parameters:\n",
        "- Batch size: Number of samples per batch\n",
        "- Shuffle: Randomly shuffle data\n",
        "- Number of workers: Parallel data loading\n",
        "- Drop last: Discard the last incomplete batch for consistent batch sizes\n",
        "- Collate function: Use graph_collate_func to batch variable-sized molecular graphs"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from kale.loaddata.molecular_datasets import graph_collate_func\n",
        "from kale.loaddata.sampler import MultiDataLoader\n",
        "\n",
        "params = {\n",
        "    \"batch_size\": cfg.SOLVER.BATCH_SIZE,\n",
        "    \"shuffle\": True,\n",
        "    \"num_workers\": cfg.SOLVER.NUM_WORKERS,\n",
        "    \"drop_last\": True,\n",
        "    \"collate_fn\": graph_collate_func,\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Then, we create a DataLoader from both the source and target datasets for training."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "if not cfg.DA.USE:\n",
        "    training_generator = DataLoader(train_dataset, **params)\n",
        "else:\n",
        "    source_generator = DataLoader(train_dataset, **params)\n",
        "    target_generator = DataLoader(train_target_dataset, **params)\n",
        "\n",
        "    # Get the number of batches in the longer dataset to align both\n",
        "    n_batches = max(len(source_generator), len(target_generator))\n",
        "\n",
        "    # Combine the source and target data loaders using MultiDataLoader\n",
        "    training_generator = MultiDataLoader(\n",
        "        dataloaders=[source_generator, target_generator], n_batches=n_batches\n",
        "    )"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Lastly, we set up DataLoaders for validation and testing. Since we don\u2019t want to shuffle or drop any samples, we adjust the parameters accordingly."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Update parameters for validation/testing (no shuffling, keep all data)\n",
        "params.update({\"shuffle\": False, \"drop_last\": False})\n",
        "\n",
        "# Create validation and test data loaders\n",
        "valid_generator = DataLoader(test_target_dataset, **params)\n",
        "test_generator = DataLoader(test_target_dataset, **params)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Exercise: Dataset Inspection\n",
        "\n",
        "Once the dataset is ready, let\u2019s inspect one sample from the training data to check the input graph, protein sequence, and label format."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Get the first batch (contains one batch from source and one from target)\n",
        "first_batch = next(iter(training_generator))\n",
        "\n",
        "# Unpack source and target batches\n",
        "source_batch, target_batch = first_batch\n",
        "\n",
        "# Inspect the first sample from the source batch\n",
        "print(\"First sample from source batch:\")\n",
        "print(\"Drug graph:\", source_batch[0][0])\n",
        "print(\"Protein sequence:\", source_batch[1][0])\n",
        "print(\"Label:\", source_batch[2][0])"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "This sample is a tuple with three parts:\n",
        "\n",
        "1. **Drug Graph**\n",
        "- `x=[290, 7]`: Feature matrix with 290 atoms (nodes) and 7 features per atom.\n",
        "- `edge_index=[2, 58]`: Shows 146 edges, with source and target node indices.\n",
        "- `edge_attr=[58, 1]`: Each edge has 1 bond feature, such as bond type.\n",
        "- `num_nodes=290`: Confirms the graph has 290 nodes.\n",
        "\n",
        "2. **Protein Features (array)**\n",
        "- Example values: `[11.,  1., 18., ...,  0.,  0.,  0.]`: A fixed-length numeric array representing the protein sequence. Each position holds an integer-encoded amino acid, with zeros for padding.\n",
        "\n",
        "3. **Label (float)**\n",
        "- `0.0`; The ground-truth interaction label indicating no interaction."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Step 2: Model Definition"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Embed\n",
        "\n",
        "DrugBAN consists of three main components: a Graph Convolutional Network (GCN) for extracting structural features from drug molecular graphs, a Convolutional Neural Network (CNN) for encoding protein sequences, and a Bilinear Attention Network (BAN) for fusing drug and protein features. The fused representation is then passed through a Multi-Layer Perceptron (MLP) classifier to predict interaction scores.\n",
        "\n",
        "We define the DrugBAN class in `kale.embed.ban`."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "from kale.embed.ban import DrugBAN\n",
        "\n",
        "model = DrugBAN(**cfg)\n",
        "print(model)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Predict\n",
        "We use the training class `kale.pipeline.drugban_trainer`, which handles model training, domain adaptation, and evaluation for DrugBAN."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "from kale.pipeline.drugban_trainer import DrugbanTrainer\n",
        "\n",
        "drugban_trainer = DrugbanTrainer(\n",
        "    model=DrugBAN(**cfg),\n",
        "    solver_lr=cfg[\"SOLVER\"][\"LEARNING_RATE\"],\n",
        "    num_classes=cfg[\"DECODER\"][\"BINARY\"],\n",
        "    batch_size=cfg[\"SOLVER\"][\"BATCH_SIZE\"],\n",
        "    is_da=cfg[\"DA\"][\"USE\"],\n",
        "    solver_da_lr=cfg[\"SOLVER\"][\"DA_LEARNING_RATE\"],\n",
        "    da_init_epoch=cfg[\"DA\"][\"INIT_EPOCH\"],\n",
        "    da_method=cfg[\"DA\"][\"METHOD\"],\n",
        "    original_random=cfg[\"DA\"][\"ORIGINAL_RANDOM\"],\n",
        "    use_da_entropy=cfg[\"DA\"][\"USE_ENTROPY\"],\n",
        "    da_random_layer=cfg[\"DA\"][\"RANDOM_LAYER\"],\n",
        "    da_random_dim=cfg[\"DA\"][\"RANDOM_DIM\"],\n",
        "    decoder_in_dim=cfg[\"DECODER\"][\"IN_DIM\"],\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "We want to save the best model during training so we can reuse it later without needing to retrain. PyTorch Lightning\u2019s `ModelCheckpoint` does this by automatically saving the model whenever it achieves a new best validation AUROC score."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filename=\"{epoch}-{step}-{val_BinaryAUROC:.4f}\",\n",
        "    monitor=\"val_BinaryAUROC\",\n",
        "    mode=\"max\",\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "We now create the `Trainer`."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "import torch\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    callbacks=[checkpoint_callback],\n",
        "    devices=\"auto\",\n",
        "    accelerator=\"auto\",\n",
        "    max_epochs=cfg[\"SOLVER\"][\"MAX_EPOCH\"],\n",
        "    deterministic=True,\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 3: Model Training"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Train\n",
        "\n",
        "After setting up the model and data loaders, we now start training the full DrugBAN model using the PyTorch Lightning Trainer via calling `trainer.fit()`.\n",
        "\n",
        "#### What Happens Here?\n",
        "- The model receives batches of drug-protein pairs from the training data loader.\n",
        "\n",
        "- During each step, the GCN, CNN, BAN layer, and MLP classifier are updated to improve interaction prediction.\n",
        "\n",
        "- Validation is automatically run at the end of each epoch to track performance and save the best model based on AUROC.\n",
        "\n",
        "\n",
        "This code block takes approximately 5 minutes to complete."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "trainer.fit(\n",
        "    drugban_trainer,\n",
        "    train_dataloaders=training_generator,\n",
        "    val_dataloaders=valid_generator,\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 4: Evaluation\n",
        "\n",
        "Once training is complete, we evaluate the model on the test set using `trainer.test()`.\n",
        "\n",
        "### What is included in this step?\n",
        "- The best model checkpoint (based on validation AUROC) is automatically loaded.\n",
        "\n",
        "- The model runs on the test data to generate predictions.\n",
        "\n",
        "- Final classification metrics, including AUROC, F1 score, accuracy, sensitivity, and specificity, are calculated and logged."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "trainer.test(drugban_trainer, dataloaders=test_generator, ckpt_path=\"best\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Performance comparison\n",
        "\n",
        "The earlier example was a simple demonstration. To properly evaluate DrugBAN against baseline models, we train it for 100 epochs across multiple random seeds.\n",
        "\n",
        "The figure below shows the performance of different models on the BioSNAP and BindingDB datasets:\n",
        "- Left plot: AUROC (Area Under the ROC Curve)\n",
        "- Right plot: AUPRC (Area Under the Precision\u2013Recall Curve)\n",
        "\n",
        "![](https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs42256-022-00605-1/MediaObjects/42256_2022_605_Fig3_HTML.png?as=webp)\n",
        "\n",
        "The box plots show the median as the centre lines and the mean as green triangles. The minima and lower percentile represent the worst and second-worst scores. The maxima and upper percentile indicate the best and second-best scores. Supplementary Table 2 provides the data statistics of the BindingDB and BioSNAP datasets."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Step 5: Interpretation\n",
        "\n",
        "Although we don\u2019t perform this step in the tutorial, for your information, it is possible to explore how DrugBAN internally represents drugs and proteins by extracting intermediate embeddings.\n",
        "\n",
        "The model first processes drug graphs and protein sequences through separate modules, then fuses them using bilinear attention to create a joint representation. These embeddings\u2014drug embedding, protein embedding, and joint interaction embedding\u2014help reveal what structural and sequence features the model has learned and how it encodes drug-protein interactions.\n",
        "\n",
        "This is typically done during the evaluation phase to avoid affecting the model\u2019s weights or training behaviour."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Extension Tasks"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Task 1\n",
        "\n",
        "To use the BindingDB dataset, modify the relevant line in the Configuration section of Step 0 as shown below.\n",
        "\n",
        "```python\n",
        "cfg.DATA.DATASET = \"bindingdb\"\n",
        "```\n",
        "\n",
        "Reload the dataset and re-run training and testing.\n",
        "\n",
        "> Tip: See if the model struggles more or less with the new dataset. It can reveal how generalisable DrugBAN is.\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Task 2\n",
        "\n",
        "Turn off domain adaptation by updating the config file and re-running training and testing.\n",
        "\n",
        "Replace `configs/DA_cross_domain.yaml` with `configs/non_DA_cross_domain.yaml` in the Configuration section of Step 0 as shown below.\n",
        "\n",
        "```python\n",
        "cfg.merge_from_file(\"configs/non_DA_cross_domain.yaml\")\n",
        "```\n",
        ">Tip: Compare the results with and without domain adaptation to see how it affects model performance."
      ],
      "cell_type": "markdown"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mmai-drug-tutorial",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
