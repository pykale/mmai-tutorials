{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {},
      "source": [
        "# Multiomics Cancer Classification\n",
        "\n",
        "![](https://github.com/pykale/mmai-tutorials/blob/main/tutorials/multiomics-cancer-classification/images/mogonet-pykale-api.png?raw=1)"
      ],
      "cell_type": "markdown",
      "id": "dbd2571f"
    },
    {
      "metadata": {},
      "source": [
        "In this tutorial, we will use a [**M**ulti-**O**mics **G**raph c**O**nvolutional **NET**works (MOGONET) by **Wang et al. (Nature Communication, 2021)**](https://www.nature.com/articles/s41467-021-23774-w) [1] pipeline implemented in `PyKale` [2] to integrate **patient multiomics data** for **cancer subtypes classification**.\n",
        "\n",
        "We will work with multiomics data from two datasets: [**BRCA** of TCGA](https://www.cancerimagingarchive.net/collection/tcga-brca/) [3] and [**ROSMAP**](https://www.synapse.org/Synapse:syn3219045) [4,5]. The BRCA dataset has five subtypes, while the ROSMAP dataset has only two. Three omics modalities will be used: mRNA expression, DNA methylation, and miRNA expression.\n",
        "\n",
        "The multimodal approach used in this tutorial involves **interaction**, where a cross-omics tensor is constructed for the probability interaction across three omics modalities.\n",
        "\n",
        "The main tasks of this tutorial are:\n",
        "\n",
        "- Load BRCA or ROSMAP dataset.\n",
        "- Define a MOGONET model.\n",
        "- Train and evaluate the MOGONET model on the multiomics data.\n",
        "- Obtain the feature importance and visualize the interpretation of the model."
      ],
      "cell_type": "markdown",
      "id": "e0825580"
    },
    {
      "metadata": {},
      "source": [
        "## Step 0: Environment Preparation\n",
        "\n",
        "As a starting point, we will install the required packages and load a set of helper functions to assist throughout this tutorial. To keep the output clean and focused on interpretation, we will also suppress warnings.\n",
        "\n",
        "To prepare the helper functions and necessary materials, we download them from the GitHub repository."
      ],
      "cell_type": "markdown",
      "id": "b419011e"
    },
    {
      "metadata": {},
      "source": [
        "import os\n",
        "\n",
        "!rm -rf /content/mmai-tutorials\n",
        "!git clone https://github.com/pykale/mmai-tutorials.git\n",
        "\n",
        "%cd /content/mmai-tutorials/tutorials/multiomics-cancer-classification\n",
        "\n",
        "print(\"Changed working directory to:\", os.getcwd())"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'mmai-tutorials' already exists and is not an empty directory.\n",
            "/content/mmai-tutorials/tutorials/multiomics-cancer-classification\n",
            "Changed working directory to: /content/mmai-tutorials/tutorials/multiomics-cancer-classification\n"
          ]
        }
      ],
      "id": "551867b5",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Package Installation"
      ],
      "cell_type": "markdown",
      "id": "e014d91d"
    },
    {
      "metadata": {},
      "source": [
        "The main package required for this tutorial is `PyKale`.\n",
        "\n",
        "`PyKale` is an open-source interdisciplinary machine learning library developed at the University of Sheffield, with a focus on applications in biomedical and scientific domains.\n",
        "\n",
        "Then, we install `PyG` (PyTorch Geometric) and related packages.\n",
        "\n",
        "[**WARNING**] Please **do not** re-run this session after installation completed. Runing this installation multiple times will trigger issues related to `PyG`. If you want to re-run this installation, please click the `Runtime` on the top menu and choose `Disconnect and delete runtime` before installing.\n",
        "\n",
        "[Estimated running time] 3 mins"
      ],
      "cell_type": "markdown",
      "id": "41ce5cef"
    },
    {
      "metadata": {},
      "source": [
        "%pip install --quiet \\\n",
        "    \"pykale[example]@git+https://github.com/pykale/pykale@main\" \\\n",
        "    gdown==5.2.0 torch-geometric==2.6.0 torch_sparse torch_scatter \\\n",
        "    -f https://data.pyg.org/whl/torch-2.6.0+cu124.html \\\n",
        "    && echo \"pykale, gdown, nilearn, and yacs installed successfully \u2705\" \\\n",
        "    || echo \"Failed to install pykale, gdown, nilearn, and yacs \u274c\""
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "pykale, gdown, nilearn, and yacs installed successfully \u2705\n"
          ]
        }
      ],
      "id": "6050d5b4",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "We then hide the warnings messages to get a clear output."
      ],
      "cell_type": "markdown",
      "id": "2027e726"
    },
    {
      "metadata": {},
      "source": [
        "import os\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
      ],
      "cell_type": "code",
      "outputs": [],
      "id": "1c9c4856",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Configuration\n",
        "\n",
        "To minimize the footprint of the notebook when specifying configurations, we provide a [`config.py`](https://github.com/pykale/mmai-tutorial/blob/main/tutorials/multiomics-cancer-classification/config.py) file that defines default parameters. These can be customized by supplying a `.yaml` configuration file, such as [`configs/BRCA.yaml`](https://github.com/pykale/mmai-tutorial/blob/main/tutorials/multiomics-cancer-classification/configs/BRCA.yaml) as an example.\n",
        "\n",
        "First, we load the configuration from [`configs/BRCA.yaml`](https://github.com/pykale/mmai-tutorial/blob/main/tutorials/multiomics-cancer-classification/configs/BRCA.yaml)."
      ],
      "cell_type": "markdown",
      "id": "6b32af98"
    },
    {
      "metadata": {},
      "source": [
        "from config import get_cfg_defaults\n",
        "\n",
        "cfg = get_cfg_defaults()\n",
        "cfg.merge_from_file(\"configs/BRCA.yaml\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "id": "20700eaf",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Besides, we also provide a configuration file for another dataset **ROSMAP**, named [`configs/ROSMAP.yaml`](https://github.com/pykale/embc-mmai25/blob/main/tutorials/multiomics-cancer-classification/configs/ROSMAP.yaml). Users can try with this dataset later."
      ],
      "cell_type": "markdown",
      "id": "71add965"
    },
    {
      "metadata": {},
      "source": [
        "In this tutorial, we list the hyperparameters we would like users to play with outside the `.yaml` file:\n",
        "- `cfg.SOLVER.MAX_EPOCHS_PRETRAIN`: Number of epochs in pre-training stage.\n",
        "- `cfg.SOLVER.MAX_EPOCHS`: Number of epochs in training stage.\n",
        "- `cfg.DATASET.NUM_MODALITIES`: Number of modalities in the pipeline.\n",
        "  - `1`: mRNA expression.\n",
        "  - `2`: mRNA expression + DNA methylation.\n",
        "  - `3`: mRNA expression + DNA methylation + miRNA expression.\n",
        "\n",
        "[**NOTE**] Because this tutorial aims to demonmstrate `PyKale` pipeline, we only set `cfg.SOLVER.MAX_EPOCHS_PRETRAIN=100` and `cfg.SOLVER.MAX_EPOCHS=500` to reduce the training time.\n",
        "If users are interested, please increase them to get more accurate predictions."
      ],
      "cell_type": "markdown",
      "id": "66a1eb4b"
    },
    {
      "metadata": {},
      "source": [
        "cfg.SOLVER.MAX_EPOCHS_PRETRAIN = 100\n",
        "cfg.SOLVER.MAX_EPOCHS = 500\n",
        "cfg.DATASET.NUM_MODALITIES = 3"
      ],
      "cell_type": "code",
      "outputs": [],
      "id": "f1f8bb7c",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Print hyperparameters:"
      ],
      "cell_type": "markdown",
      "id": "3bdf97a1"
    },
    {
      "metadata": {},
      "source": [
        "print(cfg)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATASET:\n",
            "  NAME: TCGA_BRCA\n",
            "  NUM_CLASSES: 5\n",
            "  NUM_MODALITIES: 3\n",
            "  RANDOM_SPLIT: False\n",
            "  ROOT: dataset/\n",
            "  URL: https://github.com/pykale/data/raw/main/multiomics/TCGA_BRCA.zip\n",
            "MODEL:\n",
            "  EDGE_PER_NODE: 10\n",
            "  EQUAL_WEIGHT: False\n",
            "  GCN_DROPOUT_RATE: 0.5\n",
            "  GCN_HIDDEN_DIM: [400, 400, 200]\n",
            "  GCN_LR: 0.0005\n",
            "  GCN_LR_PRETRAIN: 0.001\n",
            "  VCDN_LR: 0.001\n",
            "OUTPUT:\n",
            "  OUT_DIR: ./outputs\n",
            "SOLVER:\n",
            "  MAX_EPOCHS: 500\n",
            "  MAX_EPOCHS_PRETRAIN: 100\n",
            "  SEED: 2023\n"
          ]
        }
      ],
      "id": "f85914b1",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 1: Data Loading and Preparation\n",
        "\n",
        "We use two multiomics benchmarks in this tutorial, BRCA and ROSMAP, which have been provided by the authors of MOGONET paper in [their repository](https://github.com/txWang/MOGONET).\n",
        "\n",
        "If users are interested in more details regarding **data organization, downloading, loading, and pre-processing**, please refer to the [Data page](https://pykale.github.io/mmai-tutorials/tutorials/multiomics-cancer-classification/extend-reading/data.html) of the tutorial."
      ],
      "cell_type": "markdown",
      "id": "317fcb9b"
    },
    {
      "metadata": {},
      "source": [
        "Delete the potential existing data and download new version:"
      ],
      "cell_type": "markdown",
      "id": "8bf5c0c0"
    },
    {
      "metadata": {},
      "source": [
        "!rm -rf dataset/"
      ],
      "cell_type": "code",
      "outputs": [],
      "id": "2ecd6082",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "To load data, we first define a list the names of data files:"
      ],
      "cell_type": "markdown",
      "id": "868bcf23"
    },
    {
      "metadata": {},
      "source": [
        "file_names = []\n",
        "for modality in range(1, cfg.DATASET.NUM_MODALITIES + 1):\n",
        "    file_names.append(f\"{modality}_tr.csv\")\n",
        "    file_names.append(f\"{modality}_lbl_tr.csv\")\n",
        "    file_names.append(f\"{modality}_te.csv\")\n",
        "    file_names.append(f\"{modality}_lbl_te.csv\")\n",
        "    file_names.append(f\"{modality}_feat_name.csv\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "id": "1352ea41",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Then, we download, load, and pre-process the data by `PyKale`.\n",
        "\n",
        "[Estimated running time] 20s"
      ],
      "cell_type": "markdown",
      "id": "ef417d0c"
    },
    {
      "metadata": {},
      "source": [
        "import torch\n",
        "from kale.loaddata.multiomics_datasets import SparseMultiomicsDataset\n",
        "from kale.prepdata.tabular_transform import ToOneHotEncoding, ToTensor\n",
        "\n",
        "multiomics_data = SparseMultiomicsDataset(\n",
        "    root=cfg.DATASET.ROOT,\n",
        "    raw_file_names=file_names,\n",
        "    num_modalities=cfg.DATASET.NUM_MODALITIES,\n",
        "    num_classes=cfg.DATASET.NUM_CLASSES,\n",
        "    edge_per_node=cfg.MODEL.EDGE_PER_NODE,\n",
        "    url=cfg.DATASET.URL,\n",
        "    random_split=cfg.DATASET.RANDOM_SPLIT,\n",
        "    equal_weight=cfg.MODEL.EQUAL_WEIGHT,\n",
        "    pre_transform=ToTensor(dtype=torch.float),\n",
        "    target_pre_transform=ToOneHotEncoding(dtype=torch.float),\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [],
      "id": "9041fabd",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Inspect the dataset:"
      ],
      "cell_type": "markdown",
      "id": "c8819b69"
    },
    {
      "metadata": {},
      "source": [
        "print(multiomics_data)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset info:\n",
            "   number of modalities: 3\n",
            "   number of classes: 5\n",
            "\n",
            "   modality | total samples | num train | num test  | num features\n",
            "   -----------------------------------------------------------------\n",
            "   1        | 875           | 612       | 263       | 1000        \n",
            "   2        | 875           | 612       | 263       | 1000        \n",
            "   3        | 875           | 612       | 263       | 503         \n",
            "   -----------------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "id": "676ebd93",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 2: Model Definition"
      ],
      "cell_type": "markdown",
      "id": "910ca35a"
    },
    {
      "metadata": {},
      "source": [
        "If users are interested in more details regarding the model, please refer to the [Helper Function & Model Definition](https://pykale.github.io/mmai-tutorials/tutorials/multiomics-cancer-classification/extend-reading/helper-functions.html) of the tutorial.\n",
        "\n",
        "To initialize the model, we firstly call `MogonetModel` from [`model.py`](https://github.com/pykale/mmai-tutorials/blob/main/tutorials/multiomics-cancer-classification/model.py)."
      ],
      "cell_type": "markdown",
      "id": "007e4533"
    },
    {
      "metadata": {},
      "source": [
        "from model import MogonetModel\n",
        "\n",
        "mogonet_model = MogonetModel(cfg, dataset=multiomics_data)"
      ],
      "cell_type": "code",
      "outputs": [],
      "id": "1537ce26",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Visualize the model architecture:"
      ],
      "cell_type": "markdown",
      "id": "3bcb4126"
    },
    {
      "metadata": {},
      "source": [
        "print(mogonet_model)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model info:\n",
            "   Unimodal encoder:\n",
            "    (1) MogonetGCN(\n",
            "  (conv1): MogonetGCNConv(1000, 400)\n",
            "  (conv2): MogonetGCNConv(400, 400)\n",
            "  (conv3): MogonetGCNConv(400, 200)\n",
            ")    (2) MogonetGCN(\n",
            "  (conv1): MogonetGCNConv(1000, 400)\n",
            "  (conv2): MogonetGCNConv(400, 400)\n",
            "  (conv3): MogonetGCNConv(400, 200)\n",
            ")    (3) MogonetGCN(\n",
            "  (conv1): MogonetGCNConv(503, 400)\n",
            "  (conv2): MogonetGCNConv(400, 400)\n",
            "  (conv3): MogonetGCNConv(400, 200)\n",
            ")\n",
            "\n",
            "  Unimodal decoder:\n",
            "    (1) LinearClassifier(\n",
            "  (fc): Linear(in_features=200, out_features=5, bias=True)\n",
            ")    (2) LinearClassifier(\n",
            "  (fc): Linear(in_features=200, out_features=5, bias=True)\n",
            ")    (3) LinearClassifier(\n",
            "  (fc): Linear(in_features=200, out_features=5, bias=True)\n",
            ")\n",
            "\n",
            "  Multimodal decoder:\n",
            "    VCDN(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=125, out_features=125, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.25)\n",
            "    (2): Linear(in_features=125, out_features=5, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "id": "da221bd6",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 3: Model Training"
      ],
      "cell_type": "markdown",
      "id": "38d9195c"
    },
    {
      "metadata": {},
      "source": [
        "### Pretrain Unimodal Encoders\n",
        "\n",
        "Before training the multiomics model, we first pretrain encoders for each modality independently. This step helps each GCN encoder learn a good representation of its respective modality before integration.\n",
        "\n",
        "We can define the trainer of pretraining stage by:"
      ],
      "cell_type": "markdown",
      "id": "a7f6ad5c"
    },
    {
      "metadata": {},
      "source": [
        "import pytorch_lightning as pl\n",
        "\n",
        "network = mogonet_model.get_model(pretrain=True)\n",
        "trainer_pretrain = pl.Trainer(\n",
        "    max_epochs=cfg.SOLVER.MAX_EPOCHS_PRETRAIN,\n",
        "    default_root_dir=cfg.OUTPUT.OUT_DIR,\n",
        "    accelerator=\"auto\",\n",
        "    devices=\"auto\",\n",
        "    enable_model_summary=False,\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:\ud83d\udca1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "id": "7383c5c1",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "We pretrain the model by:\n",
        "\n",
        "\n",
        "[Estimated running time] 15s for 100 epochs"
      ],
      "cell_type": "markdown",
      "id": "b0c71889"
    },
    {
      "metadata": {},
      "source": [
        "trainer_pretrain.fit(network)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69bed99b2d194cdd9c32a523820d8579"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=100` reached.\n"
          ]
        }
      ],
      "id": "2b42b719",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Train the Multimodal Model\n",
        "After pretraining the unimodal pathways, we now train the full MOGONET model by enabling the VCDN. In this stage, all modality-specific encoders and VCDN are trained.\n",
        "\n",
        "We define the trainer of multimodal training by:"
      ],
      "cell_type": "markdown",
      "id": "0b03d93e"
    },
    {
      "metadata": {},
      "source": [
        "network = mogonet_model.get_model(pretrain=False)\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=cfg.SOLVER.MAX_EPOCHS,\n",
        "    default_root_dir=cfg.OUTPUT.OUT_DIR,\n",
        "    accelerator=\"auto\",\n",
        "    devices=\"auto\",\n",
        "    enable_model_summary=False,\n",
        "    log_every_n_steps=1,\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:\ud83d\udca1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "id": "e94b710d",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "We start the multimodal training by:\n",
        "\n",
        "\n",
        "[Estimated running time] 1 min for 500 epochs"
      ],
      "cell_type": "markdown",
      "id": "31b76385"
    },
    {
      "metadata": {},
      "source": [
        "trainer.fit(network)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "305496c13a134426ab2261926a17c518"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=500` reached.\n"
          ]
        }
      ],
      "id": "b3e66c8f",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 4: Evaluation\n",
        "Once training is complete, we evaluate the model on the test set using `trainer.test()`."
      ],
      "cell_type": "markdown",
      "id": "d41dc02a"
    },
    {
      "metadata": {},
      "source": [
        "trainer.test(network)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ebbf6fd784944a39d374b60e4c53024"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
              "\u2503\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\u2503\n",
              "\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n",
              "\u2502\u001b[36m \u001b[0m\u001b[36m        Accuracy         \u001b[0m\u001b[36m \u001b[0m\u2502\u001b[35m \u001b[0m\u001b[35m   0.8019999861717224    \u001b[0m\u001b[35m \u001b[0m\u2502\n",
              "\u2502\u001b[36m \u001b[0m\u001b[36m        F1 macro         \u001b[0m\u001b[36m \u001b[0m\u2502\u001b[35m \u001b[0m\u001b[35m   0.6880000233650208    \u001b[0m\u001b[35m \u001b[0m\u2502\n",
              "\u2502\u001b[36m \u001b[0m\u001b[36m       F1 weighted       \u001b[0m\u001b[36m \u001b[0m\u2502\u001b[35m \u001b[0m\u001b[35m   0.7699999809265137    \u001b[0m\u001b[35m \u001b[0m\u2502\n",
              "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
              "\u2503<span style=\"font-weight: bold\">        Test metric        </span>\u2503<span style=\"font-weight: bold\">       DataLoader 0        </span>\u2503\n",
              "\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n",
              "\u2502<span style=\"color: #008080; text-decoration-color: #008080\">         Accuracy          </span>\u2502<span style=\"color: #800080; text-decoration-color: #800080\">    0.8019999861717224     </span>\u2502\n",
              "\u2502<span style=\"color: #008080; text-decoration-color: #008080\">         F1 macro          </span>\u2502<span style=\"color: #800080; text-decoration-color: #800080\">    0.6880000233650208     </span>\u2502\n",
              "\u2502<span style=\"color: #008080; text-decoration-color: #008080\">        F1 weighted        </span>\u2502<span style=\"color: #800080; text-decoration-color: #800080\">    0.7699999809265137     </span>\u2502\n",
              "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Accuracy': 0.8019999861717224,\n",
              "  'F1 weighted': 0.7699999809265137,\n",
              "  'F1 macro': 0.6880000233650208}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "id": "019e2e7b",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 5: Interpretation Study\n",
        "We use `kale.interpret` to perform interpretation, where a function that systematically masks input features and observes the effect on performance\u2014highlighting which features are most important for classification is provided. Please refer to [Interpret Study page](https://pykale.github.io/mmai-tutorials/tutorials/multiomics-cancer-classification/extend-reading/interpretation-study.html) for more details.\n",
        "\n",
        "Because the interpretation study needs us to mask one feature and observe the performance drop, we firstly define the trainer for the interpretation experiments.\n",
        "\n",
        "[**NOTE**] The final results may be different from what they should be because we only train the model for a few epochs to reduce waiting time in this tutorial."
      ],
      "cell_type": "markdown",
      "id": "719c655c"
    },
    {
      "metadata": {},
      "source": [
        "from kale.interpret.model_weights import select_top_features_by_masking\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "trainer_biomarker = pl.Trainer(\n",
        "    max_epochs=cfg.SOLVER.MAX_EPOCHS,\n",
        "    accelerator=\"auto\",\n",
        "    devices=\"auto\",\n",
        "    enable_progress_bar=False,\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:\ud83d\udca1 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "id": "f061dd93",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Then, we start the experiment."
      ],
      "cell_type": "markdown",
      "id": "38a31ccf"
    },
    {
      "metadata": {},
      "source": [
        "To supress the verbose messages in the following experiments:"
      ],
      "cell_type": "markdown",
      "id": "4a754a08"
    },
    {
      "metadata": {},
      "source": [
        "import logging\n",
        "\n",
        "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)"
      ],
      "cell_type": "code",
      "outputs": [],
      "id": "e428229c",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Run the interpretation experiments:\n",
        "\n",
        "[Estimated running time] Because the following block will train the model for 2,503 times for BRCA dataset, the following block may take about 6 minutes."
      ],
      "cell_type": "markdown",
      "id": "8565e576"
    },
    {
      "metadata": {},
      "source": [
        "f1_key = \"F1\" if multiomics_data.num_classes == 2 else \"F1 macro\"\n",
        "df_featimp_top = select_top_features_by_masking(\n",
        "    trainer=trainer_biomarker,\n",
        "    model=network,\n",
        "    dataset=multiomics_data,\n",
        "    metric=f1_key,\n",
        "    num_top_feats=30,\n",
        "    verbose=False,\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ],
      "id": "2dd9e5e3",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Print the most important features:"
      ],
      "cell_type": "markdown",
      "id": "964300ae"
    },
    {
      "metadata": {},
      "source": [
        "print(\"{:>4}\\t{:<20}\\t{:>5}\\t{}\".format(\"Rank\", \"Feature name\", \"Omics\", \"Importance\"))\n",
        "for rank, row in enumerate(df_featimp_top.itertuples(index=False), 1):\n",
        "    print(f\"{rank:>4}\\t{row.feat_name:<20}\\t{row.omics:>5}\\t{row.imp:.4f}\")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank\tFeature name        \tOmics\tImportance\n",
            "   1\tMSLN|10232          \t    0\t21.0000\n",
            "   2\thsa-mir-9-2         \t    2\t17.6050\n",
            "   3\thsa-mir-9-1         \t    2\t16.0960\n",
            "   4\thsa-mir-203         \t    2\t15.0900\n",
            "   5\tABCC11|85320        \t    0\t13.0000\n",
            "   6\tTMEM207             \t    1\t13.0000\n",
            "   7\tHOXD11              \t    1\t13.0000\n",
            "   8\tKRTAP3-1            \t    1\t13.0000\n",
            "   9\tOR1J4               \t    1\t13.0000\n",
            "  10\tGPR37L1             \t    1\t13.0000\n",
            "  11\thsa-mir-2115        \t    2\t11.5690\n",
            "  12\thsa-mir-187         \t    2\t11.5690\n",
            "  13\thsa-let-7a-3        \t    2\t9.5570\n",
            "  14\thsa-let-7f-2        \t    2\t9.0540\n",
            "  15\thsa-mir-205         \t    2\t8.5510\n",
            "  16\thsa-mir-551b        \t    2\t8.5510\n",
            "  17\tANKRD45|339416      \t    0\t8.0000\n",
            "  18\tNOTCH1|4851         \t    0\t8.0000\n",
            "  19\tMDGA2|161357        \t    0\t8.0000\n",
            "  20\tARHGEF4|50649       \t    0\t8.0000\n",
            "  21\tCRHR1|1394          \t    0\t8.0000\n",
            "  22\tCXCL3|2921          \t    0\t8.0000\n",
            "  23\tCSDA|8531           \t    0\t8.0000\n",
            "  24\tPI3|5266            \t    0\t8.0000\n",
            "  25\tSLC43A3|29015       \t    0\t8.0000\n",
            "  26\tTRIML2|205860       \t    0\t8.0000\n",
            "  27\tRDH10|157506        \t    0\t8.0000\n",
            "  28\tIFFO2|126917        \t    0\t8.0000\n",
            "  29\tISL2|64843          \t    0\t8.0000\n",
            "  30\tFGFBP1|9982         \t    0\t8.0000\n"
          ]
        }
      ],
      "id": "c984bdb1",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## References\n",
        "\n",
        "[1] Wang, T., Shao, W., Huang, Z., Tang, H., Zhang, J., Ding, Z., & Huang, K. (2021). MOGONET integrates multi-omics data using graph convolutional networks allowing patient classification and biomarker identification. Nature communications, 12(1), 3445.\n",
        "\n",
        "[2] Lu, H., Liu, X., Zhou, S., Turner, R., Bai, P., Koot, R. E., ... & Xu, H. (2022, October). PyKale: Knowledge-aware machine learning from multiple sources in Python. In _Proceedings of the 31st ACM International Conference on Information & Knowledge Management_ (pp. 4274-4278).\n",
        "\n",
        "[3] Lingle, W., Erickson, B. J., Zuley, M. L., Jarosz, R., Bonaccio, E., Filippini, J., Net, J. M., Levi, L., Morris, E. A., Figler, G. G., Elnajjar, P., Kirk, S., Lee, Y., Giger, M., & Gruszauskas, N. (2016). The Cancer Genome Atlas Breast Invasive Carcinoma Collection (TCGA-BRCA) (Version 3) [Data set]. The Cancer Imaging Archive.\n",
        "\n",
        "<!-- Brigham & Women\u2019s Hospital & Harvard Medical School Chin Lynda 9 11 Park Peter J. 12 Kucherlapati Raju 13, Genome data analysis: Baylor College of Medicine Creighton Chad J. 22 23 Donehower Lawrence A. 22 23 24 25, Institute for Systems Biology Reynolds Sheila 31 Kreisberg Richard B. 31 Bernard Brady 31 Bressler Ryan 31 Erkkila Timo 32 Lin Jake 31 Thorsson Vesteinn 31 Zhang Wei 33 Shmulevich Ilya 31, Oregon Health & Science University Anur Pavana 37 Spellman Paul T. 37, NCI Yan Chunhua 44 Hu Ying 44 Meerzaman Daoud 44, Tissue source sites: ABS-IUPUI Tarvin Katie 48 Saller Charles 49 Sandusky George 50 Mitchell Colleen 50, ... & National Human Genome Research Institute Ozenberger Bradley A. 91 Guyer Mark S. 91 Sofia Heidi J. 91 Palchik Jacqueline D. 91. (2012). Comprehensive molecular portraits of human breast tumours. Nature, 490(7418), 61-70. -->\n",
        "\n",
        "[4] Bennett, D. A., Buchman, A. S., Boyle, P. A., Barnes, L. L., Wilson, R. S., & Schneider, J. A. (2018). Religious orders study and rush memory and aging project. Journal of Alzheimer\u2019s disease, 64(s1), S161-S189.\n",
        "\n",
        "[5] De Jager, P.L.; Ma, Y.; McCabe, C.; Xu, J.; Vardarajan, B.N.; Felsky, D.; Klein, H.U.; White, C.C.; Peters, M.A.; Lodgson, B.; et al. (2018). A multi-omic atlas of the human frontal cortex for aging and Alzheimer\u2019s disease research. Scientific Data 5, 1-13"
      ],
      "cell_type": "markdown",
      "id": "1da8fd92"
    }
  ]
}
