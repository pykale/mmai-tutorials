
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Brain Disorder Diagnosis &#8212; PyKale</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tutorials/brain-disorder-diagnosis/tutorial-brain';</script>
    <link rel="icon" href="../../_static/icon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Extended Exploration" href="extend-reading/extension-tasks.html" />
    <link rel="prev" title="Tutorial 0 - Environment Setup and Configuration" href="../setup-config/tutorial-0.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../overview.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/BioMedMMAI_logo.png" class="logo__image only-light" alt="PyKale - Home"/>
    <script>document.write(`<img src="../../_static/BioMedMMAI_logo.png" class="logo__image only-dark" alt="PyKale - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../overview.html">
                    Overview
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Workshop</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../workshop/intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../workshop/schedule.html">Program</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../setup-config/tutorial-0.html">Setup &amp; Configuration</a></li>
<li class="toctree-l1 current active has-children"><a class="current reference internal" href="#">Brain Disorder Diagnosis</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="extend-reading/extension-tasks.html">Extension Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="extend-reading/data-config.html">Data &amp; Config (optional)</a></li>
<li class="toctree-l2"><a class="reference internal" href="extend-reading/helper-functions.html">Helper Functions (optional)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cardiac-hemodynamics-assessment/tutorial-heart.html">Cardiothoracic Abnormality Assessment</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../cardiac-hemodynamics-assessment/extend-reading/extension-tasks.html">Extension Tasks</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../drug-target-interaction/tutorial-drug.html">Drug–Target Interaction Prediction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../multiomics-cancer-classification/tutorial-cancer.html">Multiomics Cancer Classification</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../multiomics-cancer-classification/extend-reading/extension-tasks.html">Extension Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../multiomics-cancer-classification/extend-reading/data.html">Data (optional)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../multiomics-cancer-classification/extend-reading/helper-functions.html">Helper Functions &amp; Model Details (optional)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../multiomics-cancer-classification/extend-reading/interpretation-study.html">Interpretation Study (optional)</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/pykale/mmai-tutorials/blob/main/tutorials/brain-disorder-diagnosis/tutorial-brain.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pykale/mmai-tutorials" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pykale/mmai-tutorials/issues/new?title=Issue%20on%20page%20%2Ftutorials/brain-disorder-diagnosis/tutorial-brain.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/tutorials/brain-disorder-diagnosis/tutorial-brain.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Brain Disorder Diagnosis</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-0-environment-preparation">Step 0: Environment Preparation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#install-required-packages">Install Required Packages</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#configuration">Configuration</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-data-loading-and-preparation">Step 1: Data Loading and Preparation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-loading">Data Loading</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preprocessing">Data Preprocessing</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-model-definition">Step 2: Model Definition</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation-split">Cross-Validation Split</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#embedding-extraction">Embedding Extraction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prediction-methods">Prediction Methods</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#baseline-and-proposed-model">Baseline and Proposed Model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-model-training">Step 3: Model Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-evaluation">Step 4: Evaluation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-interpretation">Step 5: Interpretation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="brain-disorder-diagnosis">
<h1>Brain Disorder Diagnosis<a class="headerlink" href="#brain-disorder-diagnosis" title="Link to this heading">#</a></h1>
<figure class="align-default" id="id1">
<img alt="../../_images/flowchart.png" src="../../_images/flowchart.png" />
<figcaption>
<p><span class="caption-number">Fig. 1 </span><span class="caption-text">Machine learning pipeline to predict ASD vs control subjects.</span><a class="headerlink" href="#id1" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>In this tutorial, we will use <code class="docutils literal notranslate"><span class="pre">PyKale</span></code> [1] to train models that classify individuals with Autism Spectrum Disorder (ASD) and healthy controls based on two data modalities: functional magnetic resonance imaging (fMRI) and phenotypic features.</p>
<p>We will work with preprocessed data from the <a class="reference external" href="https://fcon_1000.projects.nitrc.org/indi/abide/">Autism Brain Imaging Data Exchange (ABIDE)</a> [2], which includes fMRI and phenotypic information for over 1,000 subjects, contributed by 17 research centers worldwide.</p>
<p>The multimodal approach used in this tutorial involves <strong>regularization</strong>, where phenotypic features are incorporated into the regularization term to learn imaging feature embedding and improve classification performance.</p>
<p>The main tasks of the tutorial are as follows:</p>
<ul class="simple">
<li><p>Load fMRI and phenotypic data</p></li>
<li><p>Train and evaluate AI models for ASD classification using both data modalities</p>
<ul>
<li><p>Explore different cross-validation strategies: random stratified k-fold vs. leave-one-site-out</p></li>
<li><p>Apply the method from the TMI paper <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/9874890/">Kunda et al. (2022)</a> [3], which improves classification performance by reducing data heterogeneity through incorporating phenotypic data into the regularisation of imaging feature embeddings</p></li>
</ul>
</li>
<li><p>Visualize the highly weighted features based on model weights for interpretation</p></li>
</ul>
<!-- :::{figure} images/abide.png
Autism Brain Imaging Data Exchange
::: --><section id="step-0-environment-preparation">
<h2>Step 0: Environment Preparation<a class="headerlink" href="#step-0-environment-preparation" title="Link to this heading">#</a></h2>
<p><strong>GPU is not required</strong> for this tutorial, you can run the following code cells without changing the runtime type.</p>
<p>To get started, we will install the necessary packages and load a set of helper functions to support the tutorial workflow. Run the cell below to copy all tutorial-related materials to your Google Colab runtime directory. To keep the output clean and focused on interpretation, we will also suppress warnings.</p>
<div class="cell tag_hide-input docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">site</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;PYTHONWARNINGS&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;ignore&quot;</span>

<span class="k">if</span> <span class="s2">&quot;google.colab&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">get_ipython</span><span class="p">()):</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">site</span><span class="o">.</span><span class="n">getusersitepackages</span><span class="p">())</span>
    <span class="err">!</span><span class="n">git</span> <span class="n">clone</span> <span class="o">--</span><span class="n">single</span><span class="o">-</span><span class="n">branch</span> <span class="o">-</span><span class="n">b</span> <span class="n">main</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">pykale</span><span class="o">/</span><span class="n">mmai</span><span class="o">-</span><span class="n">tutorials</span>
    <span class="o">%</span><span class="n">cp</span> <span class="o">-</span><span class="n">r</span> <span class="o">/</span><span class="n">content</span><span class="o">/</span><span class="n">mmai</span><span class="o">-</span><span class="n">tutorials</span><span class="o">/</span><span class="n">tutorials</span><span class="o">/</span><span class="n">brain</span><span class="o">-</span><span class="n">disorder</span><span class="o">-</span><span class="n">diagnosis</span><span class="o">/*</span> <span class="o">/</span><span class="n">content</span><span class="o">/</span>
    <span class="o">%</span><span class="n">rm</span> <span class="o">-</span><span class="n">r</span> <span class="o">/</span><span class="n">content</span><span class="o">/</span><span class="n">mmai</span><span class="o">-</span><span class="n">tutorials</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="tip admonition">
<p class="admonition-title">Optional</p>
<p>Learn more about the <a class="reference external" href="https://pykale.github.io/mmai-tutorials/tutorials/brain-disorder-diagnosis/extend-reading/helper-functions.html">helper functions</a> used in this tutorial.</p>
</div>
<section id="install-required-packages">
<h3>Install Required Packages<a class="headerlink" href="#install-required-packages" title="Link to this heading">#</a></h3>
<p>Run the cell below to install the required packages for this tutorial. <em><strong>Estimated Runtime in Google Colab</strong></em>: 3-5 minutes</p>
<p>The details for main packages required (excluding <code class="docutils literal notranslate"><span class="pre">PyKale</span></code>) for this tutorial are:</p>
<ul class="simple">
<li><p><strong>gdown</strong>: A utility package that simplifies downloading files and folders directly from Google Drive.</p></li>
<li><p><strong>nilearn</strong>: A Python library for neuroimaging analysis. It offers convenient tools for processing, analysing, and visualizing functional MRI (fMRI) data.</p></li>
<li><p><strong>yacs</strong>: A lightweight configuration management library used to store and organize experiment settings in a hierarchical and human-readable format.</p></li>
</ul>
<div class="cell tag_hide-input tag_hide-output docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">pip</span> <span class="n">install</span> <span class="o">--</span><span class="n">quiet</span> \
    <span class="n">git</span><span class="o">+</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">pykale</span><span class="o">/</span><span class="n">pykale</span><span class="nd">@main</span> \
    <span class="n">gdown</span><span class="o">==</span><span class="mf">5.2.0</span> <span class="n">nilearn</span><span class="o">==</span><span class="mf">0.12.0</span> <span class="n">yacs</span><span class="o">==</span><span class="mf">0.1.8</span> \
    <span class="n">torch</span><span class="o">-</span><span class="n">geometric</span><span class="o">==</span><span class="mf">2.6.0</span> <span class="n">torch_sparse</span> <span class="n">torch_scatter</span> \
    <span class="o">-</span><span class="n">f</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">data</span><span class="o">.</span><span class="n">pyg</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">whl</span><span class="o">/</span><span class="n">torch</span><span class="o">-</span><span class="mf">2.6.0</span><span class="o">+</span><span class="n">cpu</span><span class="o">.</span><span class="n">html</span> \
    <span class="o">&amp;&amp;</span> <span class="n">echo</span> <span class="s2">&quot;pykale, gdown, nilearn, and yacs installed successfully ✅&quot;</span> \
    <span class="o">||</span> <span class="n">echo</span> <span class="s2">&quot;Failed to install pykale, gdown, nilearn, and yacs ❌&quot;</span>
</pre></div>
</div>
</div>
</details>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>pykale, gdown, nilearn, and yacs installed successfully ✅
Note: you may need to restart the kernel to use updated packages.
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="configuration">
<h3>Configuration<a class="headerlink" href="#configuration" title="Link to this heading">#</a></h3>
<p>Please refer to the <a class="reference external" href="https://pykale.github.io/mmai-tutorials/tutorials/setup-config/tutorial-0.html#step-2-configuration-using-yml-files">configuration tutorial</a> for general configuration setup instructions for this workshop.</p>
<p>In this tutorial, <a class="reference external" href="https://github.com/pykale/embc-mmai25/blob/main/tutorials/brain-disorder-diagnosis/configs/lpgo/base.yml"><code class="docutils literal notranslate"><span class="pre">configs/lpgo/base.yml</span></code></a> provides a lightweight setup suitable for quick experimentation. <strong>Note</strong> that this configuration file is used to describe the outputs shown in this notebook.</p>
<p>Therefore, if a different configuration is used during execution, some of the descriptions or assumptions in the notebook may no longer apply and should be interpreted with caution, as they may become misleading.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">base.yml</span></code> configuration is designed to yield acceptable performance within 15–25 minutes using a free Google Colab runtime. However, the expected performance will be lower compared to the results reported in Kunda et al. (2022).</p>
<p>For more extensive experimentation, the default hyperparameter grid in <code class="docutils literal notranslate"><span class="pre">config.py</span></code> provides a broader search space, which may yield improved results at the cost of increased runtime.</p>
<p>If you wish to replicate the exact settings used in <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/9874890/">Kunda et al. (2022)</a>, the <a class="reference external" href="https://github.com/pykale/embc-mmai25/blob/main/tutorials/brain-disorder-diagnosis/configs/lpgo/tmi2022.yml"><code class="docutils literal notranslate"><span class="pre">configs/lpgo/tmi2022.yml</span></code></a> and <a class="reference external" href="https://github.com/pykale/embc-mmai25/blob/main/tutorials/brain-disorder-diagnosis/configs/skf/tmi2022.yml"><code class="docutils literal notranslate"><span class="pre">configs/skf/tmi2022.yml</span></code></a> files includes the hyperparameter grid taken directly from their <a class="reference external" href="https://github.com/kundaMwiza/fMRI-site-adaptation">original source code</a>.</p>
</div>
<p>A detailed description of each configurable option is provided as optional extended reading in the following sections.</p>
<div class="cell tag_hide-input tag_hide-output docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">config</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_cfg_defaults</span>

<span class="n">cfg</span> <span class="o">=</span> <span class="n">get_cfg_defaults</span><span class="p">()</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">merge_from_file</span><span class="p">(</span><span class="s2">&quot;configs/lpgo/base.yml&quot;</span><span class="p">)</span>

<span class="c1"># A subset of the configuration can be modified here for quick playtest.</span>
<span class="c1"># Uncomment the following lines if you are interested in quickly</span>
<span class="c1"># modifying the configuration without modifying or making new `yml` files.</span>

<span class="c1"># cfg.DATASET.ATLAS = &quot;hcp-ica&quot;</span>
<span class="c1"># cfg.DATASET.FC = &quot;tangent-pearson&quot;</span>
<span class="c1"># cfg.DATASET.TOP_K_SITES = 5</span>
<span class="c1"># cfg.CROSS_VALIDATION.SPLIT = &quot;skf&quot;</span>
<span class="c1"># cfg.CROSS_VALIDATION.NUM_FOLDS = 5</span>
<span class="c1"># cfg.CROSS_VALIDATION.NUM_REPEATS = 2</span>
<span class="c1"># cfg.MODEL.CLASSIFIER = &quot;lr&quot;</span>
<span class="c1"># cfg.MODEL.PARAM_GRID = None</span>
<span class="c1"># cfg.MODEL.NUM_SEARCH_ITER = 100</span>
<span class="c1"># cfg.MODEL.NUM_SOLVER_ITER = 100</span>

<span class="nb">print</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CROSS_VALIDATION:
  NUM_FOLDS: 1
  NUM_REPEATS: 5
  SPLIT: lpgo
DATASET:
  ATLAS: hcp-ica
  DATA_DIR: data
  FC: tangent-pearson
  TOP_K_SITES: 10
PHENOTYPE:
  STANDARDIZE: site
RANDOM_STATE: 0
TRAINER:
  CLASSIFIER: lr
  NONLINEAR: False
  NUM_SEARCH_ITER: 100
  NUM_SOLVER_ITER: 100
  N_JOBS: -2
  PARAM_GRID: None
  PRE_DISPATCH: 2*n_jobs
  REFIT: accuracy
  SCORING: [&#39;accuracy&#39;, &#39;roc_auc&#39;]
  SEARCH_STRATEGY: random
  VERBOSE: 0
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<section id="step-1-data-loading-and-preparation">
<h2>Step 1: Data Loading and Preparation<a class="headerlink" href="#step-1-data-loading-and-preparation" title="Link to this heading">#</a></h2>
<p>Typically, raw fMRI scans require extensive preprocessing before they can be used in a machine learning pipeline. However, the <strong>ABIDE</strong> dataset provides several preprocessed derivatives, which can be downloaded directly from the <a class="reference external" href="https://preprocessed-connectomes-project.org/abide/">Preprocessed Connectomes Project (PCP)</a>, eliminating the need for manual preprocessing.</p>
<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p>Given the long runtime required to compute functional connectivity (FC) embeddings from raw fMRI data, this notebook omits that step and instead provides <strong>pre-computed embeddings</strong> via the <code class="docutils literal notranslate"><span class="pre">load_data</span></code> function, along with the associated atlas.</p>
<p>For users interested in computing the ROI time series and FC embeddings from scratch, assuming preprocessed images are available, we recommend referring to the following tools and functions:</p>
<ul>
<li><p><a class="reference external" href="https://nilearn.github.io/stable/modules/generated/nilearn.maskers.NiftiLabelsMasker.html"><code class="docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code></a>: For use with <strong>deterministic (3D)</strong> atlases.</p></li>
<li><p><a class="reference external" href="https://nilearn.github.io/stable/modules/generated/nilearn.maskers.NiftiMapsMasker.html"><code class="docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a>: For use with <strong>probabilistic (4D)</strong> atlases.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">extract_functional_connectivity</span></code> function in <code class="docutils literal notranslate"><span class="pre">preprocess.py</span></code>: This function wraps <code class="docutils literal notranslate"><span class="pre">nilearn.connectome.ConnectivityMeasure</span></code> and supports composing multiple FC measures. For example, to compute a <strong>Tangent-Pearson</strong> embedding from a list of ROI time series, you can call:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">extract_functional_connectivity</span><span class="p">(</span><span class="n">time_series</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;tangent&quot;</span><span class="p">,</span> <span class="s2">&quot;pearson&quot;</span><span class="p">])</span>
</pre></div>
</div>
</li>
</ul>
</div>
<section id="data-loading">
<h3>Data Loading<a class="headerlink" href="#data-loading" title="Link to this heading">#</a></h3>
<p>As mentioned earlier, we provide a <code class="docutils literal notranslate"><span class="pre">load_data</span></code> function to load <strong>pre-computed functional connectivity (FC)</strong> embeddings along with associated phenotypic information.<br />
This function supports automated downloading via <a class="reference external" href="https://pypi.org/project/gdown/">gdown</a> by reading from manifest files if the data is not found locally.</p>
<div class="tip admonition">
<p class="admonition-title">Extended Reading (optional)</p>
<p>Learn more about the <a class="reference external" href="https://pykale.github.io/mmai-tutorials/tutorials/brain-disorder-diagnosis/extend-reading/data-config.html#configuration-arguments-for-data-loading">configuration arguments for data loading</a>.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">helpers.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_data</span>

<span class="c1"># A subset of the configuration can be modified here for quick playtest.</span>
<span class="c1"># Uncomment the following lines if you are interested in quickly</span>
<span class="c1"># modifying the configuration without modifying or making new `yml` files.</span>

<span class="c1"># cfg.DATASET.ATLAS = &quot;hcp-ica&quot;</span>
<span class="c1"># cfg.DATASET.FC = &quot;tangent-pearson&quot;</span>
<span class="c1"># cfg.DATASET.TOP_K_SITES = 5</span>

<span class="n">fc</span><span class="p">,</span> <span class="n">phenotypes</span><span class="p">,</span> <span class="n">rois</span><span class="p">,</span> <span class="n">coords</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span>
    <span class="n">cfg</span><span class="o">.</span><span class="n">DATASET</span><span class="o">.</span><span class="n">DATA_DIR</span><span class="p">,</span>
    <span class="n">cfg</span><span class="o">.</span><span class="n">DATASET</span><span class="o">.</span><span class="n">ATLAS</span><span class="p">,</span>
    <span class="n">cfg</span><span class="o">.</span><span class="n">DATASET</span><span class="o">.</span><span class="n">FC</span><span class="p">,</span>
    <span class="n">top_k_sites</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">DATASET</span><span class="o">.</span><span class="n">TOP_K_SITES</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>✔ File found: data/abide/fc/hcp-ica/tangent-pearson.npy
✔ File found: data/abide/phenotypes.csv
✔ Atlas folder found: data/atlas/deterministic/hcp-ica
</pre></div>
</div>
</div>
</div>
<p>The downloaded dataset will follow the structure:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>dataset_folder/
├──<span class="w"> </span>abide/<span class="w">                             </span>
│<span class="w">   </span>├──<span class="w"> </span>fc/<span class="w">                           </span>
│<span class="w">   </span>│<span class="w">   </span>└──<span class="w"> </span>atlas_name/<span class="w">              </span>
│<span class="w">   </span>│<span class="w">       </span>└──<span class="w"> </span>fc.npy<span class="w">               </span>
│<span class="w">   </span>└──<span class="w"> </span>phenotypes.csv<span class="w">               </span>
└──<span class="w"> </span>atlas/<span class="w">                           </span>
<span class="w">    </span>└──<span class="w"> </span>atlas_type/<span class="w">                   </span>
<span class="w">        </span>└──<span class="w"> </span>atlas_name/<span class="w">              </span>
<span class="w">            </span>├──<span class="w"> </span>atlas.nii.gz<span class="w">          </span>
<span class="w">            </span>├──<span class="w"> </span>coords.npy<span class="w">           </span>
<span class="w">            </span>└──<span class="w"> </span>labels.txt<span class="w">          </span>
</pre></div>
</div>
<p>Descriptions for each file are as follows:</p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">abide/fc/atlas_name/fc.npy</span></code></strong><br />
A NumPy array containing functional connectivity (FC) matrices for all subjects using a specific atlas. Each FC is typically a symmetric matrix of shape <code class="docutils literal notranslate"><span class="pre">(regions</span> <span class="pre">×</span> <span class="pre">regions)</span></code>.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">abide/phenotypes.csv</span></code></strong><br />
A CSV file with subject-level metadata, including attributes such as <code class="docutils literal notranslate"><span class="pre">age</span></code>, <code class="docutils literal notranslate"><span class="pre">sex</span></code>, <code class="docutils literal notranslate"><span class="pre">diagnosis</span> <span class="pre">group</span></code>, and <code class="docutils literal notranslate"><span class="pre">site</span></code>. This information is essential for downstream analyses like classification or covariate correction.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">atlas/atlas_type/atlas_name/atlas.nii.gz</span></code></strong><br />
A NIfTI file representing the brain parcellation. Each voxel value corresponds to a labeled brain region defined by the atlas.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">atlas/atlas_type/atlas_name/coords.npy</span></code></strong><br />
A NumPy array with shape <code class="docutils literal notranslate"><span class="pre">(N,</span> <span class="pre">3)</span></code> representing the MNI coordinates of region centroids. These are often used in graph construction or spatial visualization.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">atlas/atlas_type/atlas_name/labels.txt</span></code></strong><br />
A plain text file listing the names of the brain regions defined in the atlas, with one region name per line.</p></li>
</ul>
<p>While we use <code class="docutils literal notranslate"><span class="pre">.npy</span></code> files for <code class="docutils literal notranslate"><span class="pre">fc</span></code> and <code class="docutils literal notranslate"><span class="pre">coords</span></code>, our pipeline does support different file formats like <code class="docutils literal notranslate"><span class="pre">.csv</span></code>, as long as the loaded data conforms to the expected format required by the corresponding functions or methods.</p>
<div class="exercise admonition" id="find-number-of-samples">

<p class="admonition-title"><span class="caption-number">Exercise 1 </span></p>
<section id="exercise-content">
<p>How many samples are found in the sub-sampled ABIDE dataset?</p>
<div class="dropdown admonition hint">
<p class="admonition-title">Hint</p>
<ul class="simple">
<li><p>In Python, the length of arrays like lists and tuples can be
found using <code class="docutils literal notranslate"><span class="pre">len(array)</span></code>.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">phenotypes</span></code> variable is an array containing the phenotypes
describing the subjects.</p></li>
</ul>
</div>
</section>
</div>
<p>To get a more visual overview on what FC represents and which parts of it we use for the features, we visualize the FC below using a heatmap.</p>
<div class="cell tag_hide-input docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">helpers.visualization</span><span class="w"> </span><span class="kn">import</span> <span class="n">plot_connectivity_matrix</span>

<span class="n">sub_idx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">sub_id</span> <span class="o">=</span> <span class="n">phenotypes</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">sub_idx</span><span class="p">][</span><span class="s2">&quot;SUB_ID&quot;</span><span class="p">]</span>

<span class="n">title</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Tangent-Pearson Connectivity for Subject </span><span class="si">{</span><span class="n">sub_id</span><span class="si">}</span><span class="s2">&quot;</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_connectivity_matrix</span><span class="p">(</span>
    <span class="n">fc</span><span class="p">[</span><span class="n">sub_idx</span><span class="p">],</span> <span class="n">rois</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">annotate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;bwr&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">title</span>
<span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">warn</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/bbfc07ed0d6bc98aacecb5dddf4dc9da53e6a00f5f3e4e4fa43a03dd8d6ba743.png" src="../../_images/bbfc07ed0d6bc98aacecb5dddf4dc9da53e6a00f5f3e4e4fa43a03dd8d6ba743.png" />
</div>
</div>
<p>The heatmap above displays the <strong>functional connectivity (FC) matrix</strong> for <strong>Subject 50003</strong>, computed using the <strong>Tangent-Pearson</strong> method. The matrix represents pairwise relationships between different brain regions of interest (ROIs) based on their time-series similarity.</p>
<ul class="simple">
<li><p><strong>Left panel – Full Connectivity Matrix</strong>:<br />
A symmetric matrix where each entry represents the strength and direction of FC between two ROIs.</p>
<ul>
<li><p><strong>Red values</strong> indicate positive connectivity.</p></li>
<li><p><strong>Blue values</strong> indicate negative connectivity.</p></li>
<li><p>The matrix is symmetric because the connectivity from region A to B is equal to that from B to A.</p></li>
</ul>
</li>
<li><p><strong>Right panel – Upper Triangle of the Matrix</strong>:<br />
To avoid redundancy due to symmetry, only the <strong>upper triangular portion</strong> of the matrix (excluding the diagonal) is shown.<br />
This representation is commonly used in machine learning pipelines to <strong>vectorize the FC matrix</strong> for classification or regression tasks, significantly reducing the number of features from <code class="docutils literal notranslate"><span class="pre">n*n</span></code> to <code class="docutils literal notranslate"><span class="pre">n*(n-1)/2</span></code>, where <code class="docutils literal notranslate"><span class="pre">n</span></code> is the number of ROIs. However, the feature size increase will remain <code class="docutils literal notranslate"><span class="pre">O(n^2)</span></code> as the number of ROIs increases.</p></li>
<li><p><strong>Colorbar</strong>:<br />
Indicates the range of connectivity values, with stronger connections lying at the extremes of red and blue.</p></li>
</ul>
<p>This representation is widely used in neuroimaging studies for subject-level modeling, feature extraction, and biomarker discovery.</p>
<div class="exercise admonition" id="find-roi-count">

<p class="admonition-title"><span class="caption-number">Exercise 2 </span></p>
<section id="exercise-content">
<p>How many ROIs are defined in the FC matrix?</p>
<div class="dropdown admonition hint">
<p class="admonition-title">Hint</p>
<ul class="simple">
<li><p>In Python, the length of arrays like lists and tuples can be
found using <code class="docutils literal notranslate"><span class="pre">len(array)</span></code>.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">rois</span></code> variable is an array containing the label for each
available ROI.</p></li>
</ul>
</div>
</section>
</div>
<p>Next, we want to inspect the phenotypic information provided in <strong>ABIDE dataset</strong>.</p>
<div class="cell tag_hide-input docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">phenotypes</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">RANDOM_STATE</span><span class="p">))</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SUB_ID</th>
      <th>X</th>
      <th>subject</th>
      <th>SITE_ID</th>
      <th>FILE_ID</th>
      <th>DX_GROUP</th>
      <th>DSM_IV_TR</th>
      <th>AGE_AT_SCAN</th>
      <th>SEX</th>
      <th>HANDEDNESS_CATEGORY</th>
      <th>...</th>
      <th>qc_notes_rater_1</th>
      <th>qc_anat_rater_2</th>
      <th>qc_anat_notes_rater_2</th>
      <th>qc_func_rater_2</th>
      <th>qc_func_notes_rater_2</th>
      <th>qc_anat_rater_3</th>
      <th>qc_anat_notes_rater_3</th>
      <th>qc_func_rater_3</th>
      <th>qc_func_notes_rater_3</th>
      <th>SUB_IN_SMP</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>218</th>
      <td>50302</td>
      <td>226</td>
      <td>50302</td>
      <td>UM_1</td>
      <td>UM_1_0050302</td>
      <td>1</td>
      <td>-9999</td>
      <td>10.4000</td>
      <td>2</td>
      <td>R</td>
      <td>...</td>
      <td>NaN</td>
      <td>OK</td>
      <td>NaN</td>
      <td>OK</td>
      <td>NaN</td>
      <td>OK</td>
      <td>NaN</td>
      <td>OK</td>
      <td>NaN</td>
      <td>0</td>
    </tr>
    <tr>
      <th>373</th>
      <td>50501</td>
      <td>410</td>
      <td>50501</td>
      <td>USM</td>
      <td>USM_0050501</td>
      <td>1</td>
      <td>1</td>
      <td>17.7057</td>
      <td>1</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>OK</td>
      <td>NaN</td>
      <td>OK</td>
      <td>NaN</td>
      <td>OK</td>
      <td>NaN</td>
      <td>OK</td>
      <td>NaN</td>
      <td>1</td>
    </tr>
    <tr>
      <th>594</th>
      <td>50954</td>
      <td>646</td>
      <td>50954</td>
      <td>NYU</td>
      <td>NYU_0050954</td>
      <td>1</td>
      <td>1</td>
      <td>14.7500</td>
      <td>2</td>
      <td>NaN</td>
      <td>...</td>
      <td>NaN</td>
      <td>OK</td>
      <td>NaN</td>
      <td>OK</td>
      <td>NaN</td>
      <td>OK</td>
      <td>NaN</td>
      <td>OK</td>
      <td>NaN</td>
      <td>0</td>
    </tr>
    <tr>
      <th>931</th>
      <td>51333</td>
      <td>1003</td>
      <td>51333</td>
      <td>MAX_MUN</td>
      <td>MaxMun_c_0051333</td>
      <td>2</td>
      <td>0</td>
      <td>24.0000</td>
      <td>1</td>
      <td>R</td>
      <td>...</td>
      <td>NaN</td>
      <td>OK</td>
      <td>NaN</td>
      <td>maybe</td>
      <td>ic-cerebellum</td>
      <td>OK</td>
      <td>NaN</td>
      <td>OK</td>
      <td>NaN</td>
      <td>1</td>
    </tr>
    <tr>
      <th>14</th>
      <td>50017</td>
      <td>16</td>
      <td>50017</td>
      <td>PITT</td>
      <td>Pitt_0050017</td>
      <td>1</td>
      <td>1</td>
      <td>22.7000</td>
      <td>1</td>
      <td>R</td>
      <td>...</td>
      <td>NaN</td>
      <td>maybe</td>
      <td>skull-striping fail</td>
      <td>maybe</td>
      <td>ic-cerebellum_temporal_lob</td>
      <td>fail</td>
      <td>noise</td>
      <td>OK</td>
      <td>NaN</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 104 columns</p>
</div></div></div>
</div>
<p>As we can see, there is a wide range of phenotypic information available for each subject ranging from patient descriptors such as site (<code class="docutils literal notranslate"><span class="pre">SITE_ID</span></code>), diagnostic group (<code class="docutils literal notranslate"><span class="pre">DX_GROUP</span></code>), and age at scan (<code class="docutils literal notranslate"><span class="pre">AGE_AT_SCAN</span></code>), to quality control metrics for individual scans (e.g., columns starting with <code class="docutils literal notranslate"><span class="pre">qc</span></code>).</p>
<div class="exercise admonition" id="find-number-of-phenotypes">

<p class="admonition-title"><span class="caption-number">Exercise 3 </span></p>
<section id="exercise-content">
<p>How many phenotypic variables are available in the ABIDE dataset?</p>
</section>
</div>
<p>We also want to know how the phenotypes are distributed, we can visualize it with count and histogram plot for categorical and continuous variable respectively. Following Kunda et al. (2022), we mainly focused on the distribution of site, gender, handedness, eye status, age, and FIQ.</p>
<div class="cell tag_hide-input docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">helpers.visualization</span><span class="w"> </span><span class="kn">import</span> <span class="n">plot_phenotypic_distribution</span>

<span class="c1"># Prepare phenotypic values for plotting</span>
<span class="n">values</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;Site&quot;</span><span class="p">,</span> <span class="n">phenotypes</span><span class="p">[</span><span class="s2">&quot;SITE_ID&quot;</span><span class="p">],</span> <span class="s2">&quot;category&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Gender&quot;</span><span class="p">,</span> <span class="n">phenotypes</span><span class="p">[</span><span class="s2">&quot;SEX&quot;</span><span class="p">],</span> <span class="s2">&quot;category&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Handedness&quot;</span><span class="p">,</span> <span class="n">phenotypes</span><span class="p">[</span><span class="s2">&quot;HANDEDNESS_CATEGORY&quot;</span><span class="p">],</span> <span class="s2">&quot;category&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Eye Status&quot;</span><span class="p">,</span> <span class="n">phenotypes</span><span class="p">[</span><span class="s2">&quot;EYE_STATUS_AT_SCAN&quot;</span><span class="p">],</span> <span class="s2">&quot;category&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Age&quot;</span><span class="p">,</span> <span class="n">phenotypes</span><span class="p">[</span><span class="s2">&quot;AGE_AT_SCAN&quot;</span><span class="p">],</span> <span class="s2">&quot;double&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;FIQ&quot;</span><span class="p">,</span> <span class="n">phenotypes</span><span class="p">[</span><span class="s2">&quot;FIQ&quot;</span><span class="p">],</span> <span class="s2">&quot;double&quot;</span><span class="p">),</span>
<span class="p">]</span>

<span class="c1"># Plot phenotypic distribution</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">plot_phenotypic_distribution</span><span class="p">(</span>
    <span class="o">*</span><span class="n">values</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Phenotypic Distribution Before Preprocessing&quot;</span><span class="p">,</span>
    <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">warn</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/7f025fc074b03904cd9f8edb720c07dda0cd6818e5d0b11cdda4166ebe0b4d9b.png" src="../../_images/7f025fc074b03904cd9f8edb720c07dda0cd6818e5d0b11cdda4166ebe0b4d9b.png" />
</div>
</div>
<p>Several important observations can be made:</p>
<ul class="simple">
<li><p><strong>Site Distribution</strong>: The majority of subjects were collected at <strong>NYU</strong>, followed by <strong>UM_1</strong> and <strong>UCLA_1</strong>. Other sites like <strong>USM</strong>, <strong>PITT</strong>, and <strong>YALE</strong> have relatively fewer samples. This imbalance in sample size could bias model performance toward larger sites if not properly addressed through <strong>harmonization</strong> or <strong>site-stratified validation</strong>.</p></li>
<li><p><strong>Gender Distribution</strong>: Across nearly all sites, the dataset is <strong>male-dominated</strong> (<code class="docutils literal notranslate"><span class="pre">1</span></code> = male, <code class="docutils literal notranslate"><span class="pre">2</span></code> = female), a known characteristic of ABIDE. The <strong>underrepresentation of females</strong> could limit the generalizability of sex-related findings.</p></li>
<li><p><strong>Handedness Distribution</strong>: Most subjects are <strong>right-handed (<code class="docutils literal notranslate"><span class="pre">R</span></code>)</strong>, with smaller proportions of <strong>left-handed (<code class="docutils literal notranslate"><span class="pre">L</span></code>)</strong>, <strong>ambidextrous (<code class="docutils literal notranslate"><span class="pre">Ambi</span></code>)</strong>, and <strong>mixed</strong>. Notably, there is a <strong>substantial number of <code class="docutils literal notranslate"><span class="pre">-9999</span></code> entries</strong>, indicating <strong>missing or invalid data</strong>. This missingness is uneven across sites, potentially introducing site-specific biases.</p></li>
<li><p><strong>Eye Status Distribution</strong>: Most scans were recorded with subjects’ <strong>eyes open (<code class="docutils literal notranslate"><span class="pre">1</span></code>)</strong>, though a non-negligible number had <strong>eyes closed (<code class="docutils literal notranslate"><span class="pre">2</span></code>)</strong>. The distribution is generally consistent across sites, with minimal missing data.</p></li>
<li><p><strong>Age Distribution</strong>: The age of participants ranges from around <strong>5 to 55 years</strong>, with a strong skew toward younger subjects, especially between <strong>7 and 18 years old</strong>. This is typical of developmental neuroimaging datasets and emphasizes the need to <strong>control for age</strong> in modeling or analysis.</p></li>
<li><p><strong>FIQ (Full-Scale IQ) Distribution</strong>: The FIQ distribution is <strong>severely distorted</strong> by missing or placeholder values (e.g., <strong><code class="docutils literal notranslate"><span class="pre">-9999</span></code></strong>). These dominate the histogram and create an artificial spike around zero. Valid FIQ values span a wide range but are sparsely distributed. <strong>Imputation or exclusion</strong> of these invalid entries is essential for any analysis involving IQ.</p></li>
</ul>
</section>
<section id="data-preprocessing">
<h3>Data Preprocessing<a class="headerlink" href="#data-preprocessing" title="Link to this heading">#</a></h3>
<p>Before modeling, we need to preprocess the phenotypic variables to ensure they are in a usable format. This includes handling missing values, encoding categorical variables, and optionally standardizing continuous ones.</p>
<div class="tip admonition">
<p class="admonition-title">Optional</p>
<p>Learn more about the <a class="reference external" href="https://pykale.github.io/mmai-tutorials/tutorials/brain-disorder-diagnosis/extend-reading/data-config.html#categorical-variables-from-phenotypic-data">categorical variables from phenotypic data</a> used in this tutorial.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">helpers.preprocess</span><span class="w"> </span><span class="kn">import</span> <span class="n">preprocess_phenotypic_data</span>

<span class="c1"># A subset of the configuration can be modified here for quick playtest.</span>
<span class="c1"># Uncomment the following lines if you are interested in quickly</span>
<span class="c1"># modifying the configuration without modifying or making new `yml` files.</span>

<span class="c1"># cfg.PHENOTYPE.STANDARDIZE = &quot;site&quot;</span>

<span class="n">labels</span><span class="p">,</span> <span class="n">sites</span><span class="p">,</span> <span class="n">phenotypes</span> <span class="o">=</span> <span class="n">preprocess_phenotypic_data</span><span class="p">(</span>
    <span class="n">phenotypes</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">PHENOTYPE</span><span class="o">.</span><span class="n">STANDARDIZE</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>After preprocessing, we want to observe how the encoding, imputation, and standardization affected the phenotypes.</p>
<div class="cell tag_hide-input docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">phenotypes</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">RANDOM_STATE</span><span class="p">))</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AGE_AT_SCAN</th>
      <th>FIQ</th>
      <th>SITE_ID_KKI</th>
      <th>SITE_ID_MAX_MUN</th>
      <th>SITE_ID_NYU</th>
      <th>SITE_ID_PITT</th>
      <th>SITE_ID_STANFORD</th>
      <th>SITE_ID_TRINITY</th>
      <th>SITE_ID_UCLA_1</th>
      <th>SITE_ID_UM_1</th>
      <th>SITE_ID_USM</th>
      <th>SITE_ID_YALE</th>
      <th>SEX_FEMALE</th>
      <th>SEX_MALE</th>
      <th>HANDEDNESS_CATEGORY_AMBIDEXTROUS</th>
      <th>HANDEDNESS_CATEGORY_LEFT</th>
      <th>HANDEDNESS_CATEGORY_RIGHT</th>
      <th>EYE_STATUS_AT_SCAN_CLOSED</th>
      <th>EYE_STATUS_AT_SCAN_OPEN</th>
    </tr>
    <tr>
      <th>SUB_ID</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>50302</th>
      <td>-1.046379</td>
      <td>-0.566951</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>50501</th>
      <td>-0.602117</td>
      <td>-1.553855</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>50954</th>
      <td>-0.078069</td>
      <td>-2.174853</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>51333</th>
      <td>-0.111109</td>
      <td>-0.991772</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>50017</th>
      <td>0.546855</td>
      <td>-1.911015</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now we can see that the number of phenotypes are now reduced, the continuous and categorical variables are now standardized and one-hot encoded respectively.</p>
<div class="exercise admonition" id="find-number-of-phenotypes-after-preprocess">

<p class="admonition-title"><span class="caption-number">Exercise 4 </span></p>
<section id="exercise-content">
<p>How many phenotypes are there once we have preprocessed the phenotypes?</p>
<div class="dropdown admonition hint">
<p class="admonition-title">Hint</p>
<ul class="simple">
<li><p>In <code class="docutils literal notranslate"><span class="pre">pandas</span></code>, executing <code class="docutils literal notranslate"><span class="pre">pd.DataFrame.shape</span></code> outputs a <code class="docutils literal notranslate"><span class="pre">tuple</span></code> containing
<code class="docutils literal notranslate"><span class="pre">(num_rows,</span> <span class="pre">num_columns)</span></code>.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">phenotypes</span></code> variable is a <code class="docutils literal notranslate"><span class="pre">pd.DataFrame</span></code> type.</p></li>
</ul>
</div>
</section>
</div>
<div class="exercise admonition" id="understanding-one-hot-encoding">

<p class="admonition-title"><span class="caption-number">Exercise 5 </span></p>
<section id="exercise-content">
<p>We have seen the preprocessed phenotypes and noted that the categorical
variables have been one-hot-encoded.</p>
<p>Given your observation, what does one-hot encoding do to the categorical variables?</p>
</section>
</div>
<p>We also want to check how the phenotypes are distributed after we preprocess it.</p>
<div class="cell tag_hide-input docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell source</p>
<p class="expanded admonition-title">Hide code cell source</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">helpers.visualization</span><span class="w"> </span><span class="kn">import</span> <span class="n">plot_phenotypic_distribution</span>


<span class="c1"># Mapping from column names to readable labels</span>
<span class="n">MAPPING</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;SEX&quot;</span><span class="p">:</span> <span class="s2">&quot;Gender&quot;</span><span class="p">,</span>
    <span class="s2">&quot;HANDEDNESS_CATEGORY&quot;</span><span class="p">:</span> <span class="s2">&quot;Handedness&quot;</span><span class="p">,</span>
    <span class="s2">&quot;EYE_STATUS_AT_SCAN&quot;</span><span class="p">:</span> <span class="s2">&quot;Eye Status&quot;</span><span class="p">,</span>
    <span class="s2">&quot;SITE_ID&quot;</span><span class="p">:</span> <span class="s2">&quot;Site&quot;</span><span class="p">,</span>
    <span class="s2">&quot;AGE_AT_SCAN&quot;</span><span class="p">:</span> <span class="s2">&quot;Age&quot;</span><span class="p">,</span>
    <span class="s2">&quot;FIQ&quot;</span><span class="p">:</span> <span class="s2">&quot;FIQ&quot;</span><span class="p">,</span>
<span class="p">}</span>

<span class="c1"># Initialize list with site information</span>
<span class="n">values</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&quot;Site&quot;</span><span class="p">,</span> <span class="n">sites</span><span class="p">,</span> <span class="s2">&quot;category&quot;</span><span class="p">)]</span>

<span class="c1"># Iterate over relevant phenotype variables</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">MAPPING</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;SITE_ID&quot;</span><span class="p">:</span>
        <span class="k">continue</span>

    <span class="c1"># Direct numeric columns</span>
    <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;AGE_AT_SCAN&quot;</span><span class="p">,</span> <span class="s2">&quot;FIQ&quot;</span><span class="p">]:</span>
        <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">label</span><span class="p">,</span> <span class="n">phenotypes</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="s2">&quot;double&quot;</span><span class="p">))</span>
        <span class="k">continue</span>

    <span class="c1"># One-hot encoded categorical variables</span>
    <span class="n">one_hot_cols</span> <span class="o">=</span> <span class="n">phenotypes</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">like</span><span class="o">=</span><span class="n">key</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">one_hot_cols</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
        <span class="k">continue</span>

    <span class="c1"># Decode one-hot encoding by extracting the max value index</span>
    <span class="n">decoded</span> <span class="o">=</span> <span class="n">one_hot_cols</span><span class="o">.</span><span class="n">idxmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">_&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">label</span><span class="p">,</span> <span class="n">decoded</span><span class="p">,</span> <span class="s2">&quot;category&quot;</span><span class="p">))</span>

<span class="c1"># Plot the distributions</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">plot_phenotypic_distribution</span><span class="p">(</span>
    <span class="o">*</span><span class="n">values</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Phenotypic Distribution After Preprocessing&quot;</span><span class="p">,</span>
    <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">warn</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../../_images/c43b5db465672793ce10931a70ce3175bccb2bed491188e94b0839b7d3404252.png" src="../../_images/c43b5db465672793ce10931a70ce3175bccb2bed491188e94b0839b7d3404252.png" />
</div>
</div>
<p>We can see that we can interpret the phenotypes much clearer now, as we can infer that:</p>
<ul class="simple">
<li><p><strong>Site Distribution</strong>: The overall site imbalance remains, with <strong>NYU</strong> contributing the largest number of subjects, followed by <strong>UM_1</strong> and <strong>UCLA_1</strong>. This is expected given no missing values for the site label.</p></li>
<li><p><strong>Gender Distribution</strong>: The gender imbalance persists post-preprocessing, with <strong>male subjects still forming the majority</strong> at each site. Like site, its distribution remains the same as there are no missing values.</p></li>
<li><p><strong>Handedness Distribution</strong>: The preprocessing step appears to have <strong>removed most invalid or missing values</strong>, particularly entries like <code class="docutils literal notranslate"><span class="pre">-9999</span></code>. The dataset now primarily includes <strong>right-handed</strong> subjects, with a small proportion of <strong>left-handed</strong> and <strong>ambidextrous</strong> individuals. This results in a cleaner handedness distribution, thus also reducing the dimension size of one-hot encoded handedness.</p></li>
<li><p><strong>Eye Status Distribution</strong>: The <strong>eye status remains consistent</strong>, with most subjects scanned with <strong>eyes open</strong>. Very few entries are labeled with <strong>eyes closed</strong>, and no missing values are apparent, suggesting good data completeness for this variable.</p></li>
<li><p><strong>Age Distribution</strong>: Age values have been <strong>normalized</strong>, and the distribution now appears centered around zero (z-scored). The skew toward younger participants is still present, but more subtle. This normalization facilitates fair comparison across sites and removes scale bias in modeling.</p></li>
<li><p><strong>FIQ (Full-Scale IQ) Distribution</strong>: Similar to age, FIQ has been <strong>standardized</strong>, producing a roughly normal distribution across sites. The spike of invalid values (<code class="docutils literal notranslate"><span class="pre">-9999</span></code>) observed in the raw data has been eliminated, indicating effective handling of missing or outlier values during preprocessing. This cleaner distribution is more suitable for downstream statistical analysis and machine learning models.</p></li>
</ul>
</section>
</section>
<section id="step-2-model-definition">
<h2>Step 2: Model Definition<a class="headerlink" href="#step-2-model-definition" title="Link to this heading">#</a></h2>
<p><strong>PyKale</strong> provides flexible pipelines for modelling interdisciplinary problems. In our case, the primary objective is to develop a <strong>robust yet interpretable model</strong> capable of effectively integrating multi-site data.</p>
<p>We leverage the <code class="docutils literal notranslate"><span class="pre">kale.pipeline.multi_domain_adapter.AutoMIDAClassificationTrainer</span></code> (or simply <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>), which encapsulates the domain adaptation method <a class="reference external" href="https://ieeexplore.ieee.org/document/7815350"><strong>Maximum Independence Domain Adaptation (MIDA)</strong></a> [4]. This trainer integrates domain adaptation with classification by allowing the user to specify any <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>-compatible linear classifier for prediction, offering a convenient way to construct powerful and flexible pipelines.</p>
<p>In the following sections, we first describe the <strong>cross-validation split</strong> strategy used in this tutorial, followed by an explanation of the <strong>embedding extraction</strong> and <strong>prediction</strong> methods.</p>
<section id="cross-validation-split">
<h3>Cross-Validation Split<a class="headerlink" href="#cross-validation-split" title="Link to this heading">#</a></h3>
<p>The choice of cross-validation strategy can significantly impact how can we evaluate of a model’s robustness and generalizability, especially when dealing with multi-site or grouped data.</p>
<figure class="align-default" id="id2">
<img alt="../../_images/cross-validation.png" src="../../_images/cross-validation.png" />
<figcaption>
<p><span class="caption-number">Fig. 2 </span><span class="caption-text">Illustrative comparison between random k-fold and leave-one-site-out [5].</span><a class="headerlink" href="#id2" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>The figure above compares two different cross-validation strategies which we will consider for this tutorial:</p>
<ul class="simple">
<li><p><strong>n-Repeated Stratified k-Fold (SKF)</strong>:<br />
This method ensures that each fold maintains the original label distribution (e.g., equal proportion of <code class="docutils literal notranslate"><span class="pre">+</span></code> and <code class="docutils literal notranslate"><span class="pre">−</span></code> classes). However, it does <strong>not</strong> guarantee that data from the same group (e.g., site, subject, scanner) are kept together, potentially leading to data leakage if the same group appears in both train and test splits.</p></li>
<li><p><strong>Leave-One-Site-Out or Leave p-Groups Out (LPGO)</strong>:
This method preserves the <strong>group structure</strong> by leaving out entire groups during each iteration. It is particularly suited for evaluating generalization to unseen sites or subjects, as it avoids group leakage. However, it may result in imbalanced label distributions in each fold.</p></li>
</ul>
<p>Each method serves a different purpose: stratified k-fold is ideal when label balance is critical, while leave-p-groups-out is better for assessing model robustness under domain shift or site variability. Realistically, LPGO is preferable given real data will most likely not have the same distribution as a model’s training data.</p>
<div class="exercise admonition" id="find-total-models-produced">

<p class="admonition-title"><span class="caption-number">Exercise 6 </span></p>
<section id="exercise-content">
<p>Consider we evaluate a model using SKF with two repetition and five folds or LPGO with ten groups with one group left out for testing, we will need to train a total of ten models. If we evaluate a model using:</p>
<ul class="simple">
<li><p>SKF with five repetition and ten folds</p></li>
<li><p>LPGO with five groups and two groups left out for testing</p></li>
</ul>
<p>How many models we have to train for each cases?</p>
<div class="dropdown admonition hint">
<p class="admonition-title">Hint</p>
<p>For LPGO, given <code class="docutils literal notranslate"><span class="pre">m</span></code> total groups and <code class="docutils literal notranslate"><span class="pre">p</span></code> left out groups, consider it as a combinatorial problem.</p>
</div>
</section>
</div>
<div class="tip admonition">
<p class="admonition-title">Optional</p>
<p>Learn more about the <a class="reference external" href="https://pykale.github.io/mmai-tutorials/tutorials/brain-disorder-diagnosis/extend-reading/data-config.html#configuration-arguments-for-cross-validation">configuration arguments for cross-validation</a> used in this tutorial.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">LeavePGroupsOut</span><span class="p">,</span> <span class="n">RepeatedStratifiedKFold</span>

<span class="c1"># A subset of the configuration can be modified here for quick playtest.</span>
<span class="c1"># Uncomment the following lines if you are interested in quickly</span>
<span class="c1"># modifying the configuration without modifying or making new `yml` files.</span>

<span class="c1"># cfg.CROSS_VALIDATION.SPLIT = &quot;skf&quot;</span>
<span class="c1"># cfg.CROSS_VALIDATION.NUM_FOLDS = 5</span>
<span class="c1"># cfg.CROSS_VALIDATION.NUM_REPEATS = 2</span>

<span class="c1"># Define the default cross-validation strategy:</span>
<span class="c1"># Repeated stratified k-fold maintains class distribution across folds and supports multiple repetitions</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">RepeatedStratifiedKFold</span><span class="p">(</span>
    <span class="c1"># Number of stratified folds</span>
    <span class="n">n_splits</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">CROSS_VALIDATION</span><span class="o">.</span><span class="n">NUM_FOLDS</span><span class="p">,</span>
    <span class="c1"># Number of repeat rounds</span>
    <span class="n">n_repeats</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">CROSS_VALIDATION</span><span class="o">.</span><span class="n">NUM_REPEATS</span><span class="p">,</span>
    <span class="c1"># Ensures reproducibility, intentionally set to the seed to have the same splits across runs</span>
    <span class="n">random_state</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">RANDOM_STATE</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Override with leave-p-proups-out if specified</span>
<span class="c1"># This strategy holds out `p` unique groups (e.g., sites) per fold, enabling group-level generalization</span>
<span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">CROSS_VALIDATION</span><span class="o">.</span><span class="n">SPLIT</span> <span class="o">==</span> <span class="s2">&quot;lpgo&quot;</span><span class="p">:</span>
    <span class="c1"># Use group-based CV for domain adaptation or site bias evaluation</span>
    <span class="n">cv</span> <span class="o">=</span> <span class="n">LeavePGroupsOut</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">CROSS_VALIDATION</span><span class="o">.</span><span class="n">NUM_FOLDS</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="embedding-extraction">
<h3>Embedding Extraction<a class="headerlink" href="#embedding-extraction" title="Link to this heading">#</a></h3>
<p><strong>Domain adaptation</strong> aims to reduce distributional discrepancies between datasets collected under different conditions (e.g., sites, scanners, protocols). This helps ensure that the learned representations generalize across domains.</p>
<p><strong>MIDA</strong> was originally proposed by <a class="reference external" href="https://ieeexplore.ieee.org/document/7815350">Yan et al. (2017)</a> [4] in <em>IEEE Transactions on Cybernetics</em> to reduce time-varying drift in sensors, using domain features such as device label and acquisition time.</p>
<p>Kunda et al. (2022) extended MIDA for neuroimaging studies, enabling multi-domain adaptation for <strong>multi-site data integration</strong>.</p>
<p>PyKale includes a <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>-style implementation of MIDA in <code class="docutils literal notranslate"><span class="pre">kale.embed.factorization.MIDA</span></code>, adopting a similar interface to <code class="docutils literal notranslate"><span class="pre">KernelPCA</span></code> to ensure interoperability, extensive customization, and ease of use.</p>
</section>
<section id="prediction-methods">
<h3>Prediction Methods<a class="headerlink" href="#prediction-methods" title="Link to this heading">#</a></h3>
<p>To maintain compatibility and user-friendliness, PyKale supports <strong>linear classifiers</strong> from <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>, including:</p>
<ul class="simple">
<li><p><strong>Logistic Regression (LR)</strong></p></li>
<li><p><strong>Support Vector Machines (SVM)</strong></p></li>
<li><p><strong>Ridge Classifier (Ridge)</strong></p></li>
</ul>
<p>These models can be selected easily by passing the appropriate string identifier, streamlining experimentation with different classifiers.</p>
<p>Linear classifiers are particularly suitable in this context due to their <strong>inherent interpretability</strong>. Its coefficients can be directly inspected to understand the contribution of each feature to the prediction.</p>
</section>
<section id="baseline-and-proposed-model">
<h3>Baseline and Proposed Model<a class="headerlink" href="#baseline-and-proposed-model" title="Link to this heading">#</a></h3>
<p>We define several model configurations used for classification. Each model shares the same base classifier but differs in how domain adaptation is applied:</p>
<ul class="simple">
<li><p><strong>Baseline</strong>: A standard model trained directly on functional connectivity features without domain adaptation.</p></li>
<li><p><strong>Site Only</strong>: A domain-adapted model that uses site labels as the adaptation factor to reduce site-specific bias.</p></li>
<li><p><strong>All Phenotypes</strong>: An extended domain-adapted model that incorporates multiple phenotypic variables (e.g., age, sex, handedness) to further reduce inter-site variability.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Optional</p>
<p>Learn more about the <a class="reference external" href="https://pykale.github.io/mmai-tutorials/tutorials/brain-disorder-diagnosis/extend-reading/data-config.html#hyperparameter-grid">hyperparameter grid</a> used in this tutorial.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">clone</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kale.pipeline.multi_domain_adapter</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoMIDAClassificationTrainer</span> <span class="k">as</span> <span class="n">Trainer</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">helpers.parsing</span><span class="w"> </span><span class="kn">import</span> <span class="n">parse_param_grid</span>

<span class="c1"># A subset of the configuration can be modified here for quick playtest.</span>
<span class="c1"># Uncomment the following lines if you are interested in quickly</span>
<span class="c1"># modifying the configuration without modifying or making new `yml` files.</span>

<span class="c1"># cfg.MODEL.CLASSIFIER = &quot;lr&quot;</span>
<span class="c1"># cfg.MODEL.PARAM_GRID = None</span>
<span class="c1"># cfg.MODEL.NUM_SEARCH_ITER = 100</span>
<span class="c1"># cfg.MODEL.NUM_SOLVER_ITER = 100</span>

<span class="c1"># Configuration with cv and random_state/seed included</span>
<span class="n">trainer_cfg</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">cfg</span><span class="o">.</span><span class="n">TRAINER</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="s2">&quot;PARAM_GRID&quot;</span><span class="p">}</span>
<span class="n">trainer_cfg</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">trainer_cfg</span><span class="p">,</span> <span class="s2">&quot;cv&quot;</span><span class="p">:</span> <span class="n">cv</span><span class="p">,</span> <span class="s2">&quot;random_state&quot;</span><span class="p">:</span> <span class="n">cfg</span><span class="o">.</span><span class="n">RANDOM_STATE</span><span class="p">}</span>

<span class="c1"># Initialize dictionary for different trainers</span>
<span class="n">trainers</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># Create a baseline trainer without domain adaptation (MIDA disabled)</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="n">parse_param_grid</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">TRAINER</span><span class="o">.</span><span class="n">PARAM_GRID</span><span class="p">,</span> <span class="s2">&quot;domain_adapter&quot;</span><span class="p">)</span>
<span class="n">trainers</span><span class="p">[</span><span class="s2">&quot;baseline&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">use_mida</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span> <span class="o">**</span><span class="n">trainer_cfg</span><span class="p">)</span>

<span class="c1"># Create a trainer with MIDA enabled, using site labels as domain adaptation factors</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="n">parse_param_grid</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">TRAINER</span><span class="o">.</span><span class="n">PARAM_GRID</span><span class="p">)</span>
<span class="n">trainers</span><span class="p">[</span><span class="s2">&quot;site_only&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">use_mida</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">trainer_cfg</span><span class="p">)</span>

<span class="c1"># Clone the &#39;site_only&#39; trainer to create &#39;all_phenotypes&#39; trainer</span>
<span class="c1"># This enables reusing the same training configuration, while modifying only the input domain factors</span>
<span class="n">trainers</span><span class="p">[</span><span class="s2">&quot;all_phenotypes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">trainers</span><span class="p">[</span><span class="s2">&quot;site_only&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="step-3-model-training">
<h2>Step 3: Model Training<a class="headerlink" href="#step-3-model-training" title="Link to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> automatically handles model training and hyperparameter tuning based on the specified cross-validation strategy. To initiate training, simply call the <code class="docutils literal notranslate"><span class="pre">fit(...)</span></code> method, which accepts the following arguments:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">x</span></code>: The input features used for training and tuning the model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">y</span></code>: The target labels corresponding to each sample.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">groups</span></code>: Group identifiers for each sample, used specifically in group-aware cross-validation methods such as Leave-p-Groups-Out (LPGO).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">group_labels</span></code>: Additional metadata or domain features describing each sample (e.g., phenotypes, one-hot encoded site indicators) used by the domain adaptation method.</p></li>
</ul>
<p>This interface allows seamless integration of domain information and supports robust validation across multi-site datasets.</p>
<p>As noted earlier, we evaluate three model variants:</p>
<ul class="simple">
<li><p>For the <strong>baseline</strong> model, no additional <code class="docutils literal notranslate"><span class="pre">group_labels</span></code> are required, as domain adaptation is not applied.</p></li>
<li><p>The <strong>site only</strong> and <strong>all phenotypes</strong> models <strong>do require</strong> <code class="docutils literal notranslate"><span class="pre">group_labels</span></code> to be specified in order to enable domain adaptation using site or phenotypic information.</p></li>
</ul>
<p>Given that we have already preprocessed the phenotypic data and extracted site labels, we can pass the appropriate <code class="docutils literal notranslate"><span class="pre">group_labels</span></code> during training:</p>
<ul class="simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">sites</span></code> for the <strong>site only</strong> model.</p></li>
<li><p>Use the full <code class="docutils literal notranslate"><span class="pre">phenotypes</span></code> data (including one-hot encoded site and demographic features) for the <strong>all phenotypes</strong> model.</p></li>
</ul>
<p>This demonstrates that the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> provides flexible control over the use of <strong>MIDA</strong>, allowing users to choose whether or not to incorporate domain adaptation based on the available metadata and the specific goals of their analysis.</p>
<p><em><strong>Estimated Runtime in Google Colab</strong></em>: 18-25 minutes</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>

<span class="c1"># Define common training arguments for all models: features (X), labels (y), and group info (sites)</span>
<span class="n">fit_args</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">fc</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">labels</span><span class="p">,</span> <span class="s2">&quot;groups&quot;</span><span class="p">:</span> <span class="n">sites</span><span class="p">}</span>

<span class="n">cv_results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="p">(</span><span class="n">pbar</span> <span class="o">:=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">trainers</span><span class="p">)):</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">fit_args</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">&quot;site_only&quot;</span><span class="p">:</span>
        <span class="n">args</span><span class="p">[</span><span class="s2">&quot;group_labels&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sites</span>
    <span class="k">if</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">&quot;all_phenotypes&quot;</span><span class="p">:</span>
        <span class="n">args</span><span class="p">[</span><span class="s2">&quot;group_labels&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">phenotypes</span>

    <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fitting </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s2"> model&quot;</span><span class="p">)</span>
    <span class="n">trainers</span><span class="p">[</span><span class="n">model</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="o">**</span><span class="n">args</span><span class="p">)</span>
    <span class="n">cv_results</span><span class="p">[</span><span class="n">model</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">trainers</span><span class="p">[</span><span class="n">model</span><span class="p">]</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting all_phenotypes model: 100%|██████████| 3/3 [00:59&lt;00:00, 19.98s/it]
</pre></div>
</div>
</div>
</div>
<p>Once the models are simultaneously trained and tuned, the cross-validation results are stored in the <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> attribute. These results are automatically sorted according to the metric specified in the <code class="docutils literal notranslate"><span class="pre">refit</span></code> argument.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> object contains comprehensive information, including:</p>
<ul class="simple">
<li><p>The hyperparameter configurations explored during tuning.</p></li>
<li><p>Performance scores for each split.</p></li>
<li><p>Aggregated statistics such as the mean and standard deviation across folds.</p></li>
</ul>
<p>This allows for detailed inspection and comparison of model performance across different hyperparameter settings.</p>
<p>If we are only interested in a single evaluation metric, we can use the <code class="docutils literal notranslate"><span class="pre">best_score_</span></code> attribute to retrieve the best average performance across all splits based on that metric.</p>
<p>To facilitate comparison across models, we aggregate each model’s <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> into a <code class="docutils literal notranslate"><span class="pre">dict</span></code> of <code class="docutils literal notranslate"><span class="pre">pd.DataFrame</span></code> objects. These can then be compiled into a summary table that highlights the best-tuned performance for each of the three evaluated models.</p>
<div class="exercise admonition" id="find-the-aggregate-in-cv-results">

<p class="admonition-title"><span class="caption-number">Exercise 7 </span></p>
<section id="exercise-content">
<p>Can you mention what are the available aggregates for each metrics found in <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code>?</p>
<div class="dropdown admonition hint">
<p class="admonition-title">Hint</p>
<p>You can inspect <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> or <code class="docutils literal notranslate"><span class="pre">cv_results[model]</span></code> just like <code class="docutils literal notranslate"><span class="pre">phenotypes</span></code>.</p>
</div>
</section>
</div>
</section>
<section id="step-4-evaluation">
<h2>Step 4: Evaluation<a class="headerlink" href="#step-4-evaluation" title="Link to this heading">#</a></h2>
<p>After training and tuning the models, we evaluate the performance of the three model configurations using <strong>accuracy</strong> as the primary metric for comparison.</p>
<p>We compile the top-performing scores from cross-validation for each model, allowing us to assess the effectiveness of different domain adaptation strategies. By comparing models with and without domain adaptation, we can examine the impact of incorporating <strong>site</strong> and <strong>phenotypic</strong> information on multi-site autism classification performance.</p>
<p>This can be done using the <code class="docutils literal notranslate"><span class="pre">compile_results</span></code> function, which summarizes cross-validation outputs into a clean and comparable format. The function accepts the following:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">cv_results</span></code>: A dictionary that maps model names (e.g., <code class="docutils literal notranslate"><span class="pre">&quot;Baseline&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;Site</span> <span class="pre">Only&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;All</span> <span class="pre">Phenotypes&quot;</span></code>) to their cross-validation results. These can either be <code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> objects or nested dictionaries with performance scores.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sort_by</span></code>: The metric used to select the best-performing configuration for each model. Supported metrics include <code class="docutils literal notranslate"><span class="pre">&quot;accuracy&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;precision&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;recall&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;f1&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;roc_auc&quot;</span></code>, and <code class="docutils literal notranslate"><span class="pre">&quot;matthews_corrcoef&quot;</span></code>.</p></li>
</ul>
<p>It returns a <code class="docutils literal notranslate"><span class="pre">pd.DataFrame</span></code> where each row corresponds to a model, and each column shows the formatted score (e.g., <code class="docutils literal notranslate"><span class="pre">mean</span> <span class="pre">±</span> <span class="pre">std</span></code>) for the selected metric.</p>
<p>This analysis highlights which configurations generalize best across heterogeneous imaging sites.</p>
<p>In addition, we report performance from an experiment using <strong>2-repeated stratified 5-fold cross-validation</strong>, which can be run by loading the configuration file at <code class="docutils literal notranslate"><span class="pre">experiments/skf/base.yml</span></code>. As expected, the performance differences are less pronounced in this setting. This is likely because blending data from different sites maintains label distribution but does <strong>not</strong> reflect a realistic evaluation of generalization under domain shift, a scenario encountered when deploying models to unseen sites.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Model</p></th>
<th class="head text-center"><p>Accuracy</p></th>
<th class="head text-center"><p>AUROC</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>Baseline</strong></p></td>
<td class="text-center"><p>0.6711 ± 0.0330</p></td>
<td class="text-center"><p>0.7295 ± 0.0238</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Site Only</strong></p></td>
<td class="text-center"><p>0.6877 ± 0.0357</p></td>
<td class="text-center"><p>0.7372 ± 0.0228</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>All Phenotypes</strong></p></td>
<td class="text-center"><p>0.6849 ± 0.0314</p></td>
<td class="text-center"><p>0.7396 ± 0.0215</p></td>
</tr>
</tbody>
</table>
</div>
<p>The key question now is: <strong>Does domain adaptation actually improve predictive performance under a leave-one-group-out setting, where generalization to unseen sites is critical?</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">helpers.parsing</span><span class="w"> </span><span class="kn">import</span> <span class="n">compile_results</span>

<span class="c1"># Compile the cross-validation results into a summary table,</span>
<span class="c1"># sorting by the model with the highest test accuracy across CV folds</span>
<span class="n">compiled_results</span> <span class="o">=</span> <span class="n">compile_results</span><span class="p">(</span><span class="n">cv_results</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>

<span class="c1"># Display the compiled results DataFrame (models as rows, metrics as formatted strings)</span>
<span class="n">display</span><span class="p">(</span><span class="n">compiled_results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Accuracy</th>
      <th>AUROC</th>
    </tr>
    <tr>
      <th>Model</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Baseline</th>
      <td>0.6678 ± 0.0982</td>
      <td>0.7152 ± 0.0883</td>
    </tr>
    <tr>
      <th>Site Only</th>
      <td>0.6960 ± 0.0884</td>
      <td>0.7233 ± 0.0925</td>
    </tr>
    <tr>
      <th>All Phenotypes</th>
      <td>0.6902 ± 0.0948</td>
      <td>0.7241 ± 0.0884</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Turns out, domain adaptation indeed helps when evaluated under the <strong>leave-one-group-out</strong> setting.</p>
<p>We observe a consistent performance improvement when incorporating site and phenotypic information:</p>
<ul class="simple">
<li><p>The <strong>Site Only</strong> model achieves the highest accuracy, indicating that accounting for site differences is beneficial for generalization.</p></li>
<li><p>The <strong>All Phenotypes</strong> model also outperforms the <strong>Baseline</strong>, suggesting that additional phenotypic features contribute useful domain information, although the performance difference over site alone is marginal given the accuracy and AUROC.</p></li>
<li><p>The <strong>Baseline</strong> model, which does not use domain adaptation, performs worst, highlighting the challenge of multi-site variability when no adaptation is applied.</p></li>
</ul>
<p>These results demonstrate the effectiveness of domain adaptation in improving model generalization across imaging sites, especially in scenarios where each site may exhibit different data distributions.</p>
</section>
<section id="step-5-interpretation">
<h2>Step 5: Interpretation<a class="headerlink" href="#step-5-interpretation" title="Link to this heading">#</a></h2>
<p>We interpret the trained models by analyzing the learned weights associated with functional connectivity features. Specifically, we extract the top-weighted ROI pairs that contribute most to the classification decision.</p>
<p>These weights are visualized using a <strong>connectome plot</strong>, which helps reveal the brain region interactions that are most informative for distinguishing individuals with autism from neurotypical controls. This enhances the <strong>interpretability</strong> of the model and may offer insights into <strong>neurobiological patterns</strong> relevant to autism.</p>
<p>To support this, <strong>PyKale</strong> extends <code class="docutils literal notranslate"><span class="pre">nilearn</span></code>’s <code class="docutils literal notranslate"><span class="pre">plot_connectome</span></code> through the utility <code class="docutils literal notranslate"><span class="pre">kale.interpret.visualize.visualize_connectome</span></code>. This enhanced version improves interpretability by:</p>
<ul class="simple">
<li><p>Adding annotations for each ROI.</p></li>
<li><p>Visualizing only the top-weighted connections between regions, making the plot more focused and informative.</p></li>
</ul>
<p>This visualization aids both in model transparency and in deriving neuroscientific interpretations from machine learning outputs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kale.interpret.visualize</span><span class="w"> </span><span class="kn">import</span> <span class="n">visualize_connectome</span>

<span class="c1"># Fetch model with best performance</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">cv_results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">m</span><span class="p">:</span> <span class="n">trainers</span><span class="p">[</span><span class="n">m</span><span class="p">]</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
<span class="c1"># Fetch coefficients to visualize feature importance</span>
<span class="n">coef</span> <span class="o">=</span> <span class="n">trainers</span><span class="p">[</span><span class="n">best_model</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="c1"># check if coef != features, assumes augmented features with phenotypes/sites</span>
<span class="k">if</span> <span class="n">coef</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">fc</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
    <span class="n">coef</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">coef</span><span class="p">,</span> <span class="p">[</span><span class="n">fc</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>

<span class="c1"># Visualize the coefficients as a connectome plot</span>
<span class="n">proj</span> <span class="o">=</span> <span class="n">visualize_connectome</span><span class="p">(</span>
    <span class="n">coef</span><span class="p">,</span>
    <span class="n">rois</span><span class="p">,</span>
    <span class="n">coords</span><span class="p">,</span>
    <span class="mf">1.5</span> <span class="o">/</span> <span class="mi">100</span><span class="p">,</span>  <span class="c1"># Take top 1.5% of connections</span>
    <span class="n">legend_params</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;bbox_to_anchor&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mf">3.75</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4</span><span class="p">),</span>  <span class="c1"># Align legend outside the plot</span>
        <span class="s2">&quot;ncol&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="c1"># Display the resulting connectome plot</span>
<span class="n">display</span><span class="p">(</span><span class="n">proj</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;nilearn.plotting.displays._projectors.OrthoProjector at 0x7d009f7d2770&gt;
</pre></div>
</div>
<img alt="../../_images/8f90cd524b453221b5f44bd75ee74e1d41c032b0de749fc0577af87b7295a02c.png" src="../../_images/8f90cd524b453221b5f44bd75ee74e1d41c032b0de749fc0577af87b7295a02c.png" />
</div>
</div>
<p>The figure illustrates the <strong>most discriminative ROI-to-ROI functional connections</strong> that differentiate <strong>Autism Spectrum Disorder (ASD)</strong> participants from <strong>Controls</strong>, based on group-level functional connectivity analysis.</p>
<ul class="simple">
<li><p><strong>Blue edges</strong> indicate <strong>stronger functional connectivity in Control</strong> participants.</p></li>
<li><p><strong>Red edges</strong> (not present in this figure) would indicate <strong>stronger connectivity in ASD</strong>.</p></li>
<li><p>The <strong>color saturation</strong> and <strong>thickness of the edges</strong> represent the <strong>magnitude of discriminative contribution</strong> of each connection.</p></li>
</ul>
<hr class="docutils" />
<p><strong>Key Observations</strong></p>
<ul class="simple">
<li><p><strong>Default Mode Network (DMN)</strong></p>
<ul>
<li><p>Includes: <em>DefaultMode.MPFC</em>, <em>DefaultMode.PCC</em>, <em>DefaultMode.LP (L/R)</em></p></li>
<li><p>Several intra-DMN and interhemispheric connections appear weaker in ASD, aligning with known disruptions in <strong>self-referential thinking</strong> and <strong>social cognition</strong>.</p></li>
</ul>
</li>
<li><p><strong>Fronto-Parietal Network</strong></p>
<ul>
<li><p>Includes: <em>FrontoParietal.LPFC (L)</em>, <em>FrontoParietal.PPC (L)</em></p></li>
<li><p>Weaker connectivity in this network may indicate impaired <strong>executive function</strong> and <strong>cognitive control</strong>, both commonly reported in ASD.</p></li>
</ul>
</li>
<li><p><strong>Language Network</strong></p>
<ul>
<li><p>Includes: <em>Language.IFG (R)</em>, <em>Language.pSTG (L)</em></p></li>
<li><p>Reduced connections involving language-related areas suggest <strong>communication challenges</strong> in ASD.</p></li>
</ul>
</li>
<li><p><strong>Salience and Sensorimotor Networks</strong></p>
<ul>
<li><p>Includes: <em>Salience.AInsula (L)</em>, <em>SensoriMotor.Lateral (L/R)</em></p></li>
<li><p>Altered connectivity in these regions may reflect atypical <strong>sensory integration</strong> and <strong>interoception</strong>, frequently observed in autistic individuals.</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<p><strong>Interpretation Considerations</strong></p>
<p>While these patterns provide evidence for disrupted <strong>large-scale network integration</strong> in ASD, caution is warranted:</p>
<ul class="simple">
<li><p>Regions such as <strong>sensorimotor cortex</strong> are known to be <strong>susceptible to head motion</strong> and <strong>site-related variability</strong>.</p></li>
<li><p>The presence of domain adaptation and harmonization in the modeling pipeline reduces, but does not fully eliminate these confounds.</p></li>
<li><p>Therefore, while findings involving <strong>DMN</strong> and <strong>language networks</strong> are likely robust, sensorimotor findings should be interpreted with care.</p></li>
</ul>
<hr class="docutils" />
<p><strong>Summary</strong></p>
<p>This figure underscores a consistent pattern of <strong>reduced functional connectivity</strong> across the <strong>Default Mode</strong>, <strong>Language</strong>, <strong>Fronto-Parietal</strong>, and <strong>Sensorimotor</strong> networks in ASD. These disruptions support the theory of altered <strong>network-level integration</strong> in autism and bolster the potential of <strong>connectivity-based biomarkers</strong> for diagnostic classification.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<p>[1] Lu, H., Liu, X., Zhou, S., Turner, R., Bai, P., Koot, R. E., … &amp; Xu, H. (2022, October). PyKale: Knowledge-aware machine learning from multiple sources in Python. In <em>Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management</em> (pp. 4274-4278).</p>
<p>[2] Craddock, C., Benhajali, Y., Chu, C., Chouinard, F., Evans, A., Jakab, A., … &amp; Bellec, P. (2013). The neuro bureau preprocessing initiative: open sharing of preprocessed neuroimaging data and derivatives. <em>Frontiers in Neuroinformatics</em>, 7(27), 5.</p>
<p>[3] Kunda, M., Zhou, S., Gong, G., &amp; Lu, H. (2022). Improving multi-site autism classification via site-dependence minimization and second-order functional connectivity. <em>IEEE Transactions on Medical Imaging</em>, 42(1), 55-65.</p>
<p>[4] Yan, K., Kou, L., &amp; Zhang, D. (2017). Learning domain-invariant subspace using domain features and independence maximization. <em>IEEE transactions on cybernetics</em>, 48(1), 288-299.</p>
<p>[5] Abraham, A., Milham, M. P., Di Martino, A., Craddock, R. C., Samaras, D., Thirion, B., &amp; Varoquaux, G. (2017). Deriving reproducible biomarkers from multi-site resting-state data: An Autism-based example. <em>NeuroImage</em>, 147, 736-745.</p>
</section>
<div class="toctree-wrapper compound">
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./tutorials/brain-disorder-diagnosis"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../setup-config/tutorial-0.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Tutorial 0 - Environment Setup and Configuration</p>
      </div>
    </a>
    <a class="right-next"
       href="extend-reading/extension-tasks.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Extended Exploration</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-0-environment-preparation">Step 0: Environment Preparation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#install-required-packages">Install Required Packages</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#configuration">Configuration</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-data-loading-and-preparation">Step 1: Data Loading and Preparation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-loading">Data Loading</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preprocessing">Data Preprocessing</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-model-definition">Step 2: Model Definition</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation-split">Cross-Validation Split</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#embedding-extraction">Embedding Extraction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prediction-methods">Prediction Methods</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#baseline-and-proposed-model">Baseline and Proposed Model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-model-training">Step 3: Model Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-evaluation">Step 4: Evaluation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-interpretation">Step 5: Interpretation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By PyKale Contributors
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>